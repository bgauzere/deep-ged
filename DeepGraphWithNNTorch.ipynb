{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gklearn.utils.graphfiles import loadDataset\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge max label 3\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "def label_to_color(label):\n",
    "    if label == 'C':\n",
    "        return 0.1\n",
    "    elif label == 'O':\n",
    "        return 0.8\n",
    "    \n",
    "def nodes_to_color_sequence(G):\n",
    "    return [label_to_color(c[1]['label'][0]) for c in G.nodes(data=True)]\n",
    "\n",
    "Gs,y = loadDataset('/home/ines/Documents/M2/Stage/stage_ged/Ines/DeepGED/MAO/dataset.ds')\n",
    "#for e in Gs[13].edges():\n",
    "#    print(Gs[13][e[0]][e[1]]['bond_type'])\n",
    "print('edge max label',max(max([[G[e[0]][e[1]]['bond_type'] for e in G.edges()] for G in Gs])))\n",
    "G1 = Gs[1]\n",
    "G2 = Gs[9]\n",
    "print(y[1],y[9])\n",
    "\n",
    "'''\n",
    "plt.figure(0)\n",
    "nx.draw_networkx(G1,with_labels=True,node_color = nodes_to_color_sequence(G1),cmap='autumn')\n",
    "\n",
    "plt.figure(1)\n",
    "nx.draw_networkx(G2,with_labels=True,node_color = nodes_to_color_sequence(G2),cmap='autumn')\n",
    "\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "import extended_label\n",
    "for g in Gs:\n",
    "    extended_label.compute_extended_labels(g)\n",
    "#for v in Gs[10].nodes():\n",
    "#        print(Gs[10].nodes[v])\n",
    "\n",
    "#print(nx.to_dict_of_lists(Gs[13]))\n",
    "\n",
    "\n",
    "\n",
    "#dict={'C':0,'N':1,'O':2}\n",
    "#A,labels=from_networkx_to_tensor2(Gs[13],dict)\n",
    "#print(A)\n",
    "#A1=(A==torch.ones(13,13)).int()\n",
    "#A2=(A==2*torch.ones(13,13)).int()\n",
    "#print(A1)\n",
    "#print(A2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gs= 68\n",
      "['C_1C', 'C_1C1C1N', 'C_1C1C2C', 'C_1C1N', 'C_1C1N2C', 'C_1C1O', 'C_1C1O2C', 'C_1C2C', 'C_1C3C', 'C_1N', 'C_1O', 'C_2C', 'C_2C2C', 'C_3C', 'N_1C', 'N_1C1C', 'N_1C1C1C', 'O_1C', 'O_1C1C']\n",
      "{'C_1C': 0, 'C_1C1C1N': 1, 'C_1C1C2C': 2, 'C_1C1N': 3, 'C_1C1N2C': 4, 'C_1C1O': 5, 'C_1C1O2C': 6, 'C_1C2C': 7, 'C_1C3C': 8, 'C_1N': 9, 'C_1O': 10, 'C_2C': 11, 'C_2C2C': 12, 'C_3C': 13, 'N_1C': 14, 'N_1C1C': 15, 'N_1C1C1C': 16, 'O_1C': 17, 'O_1C1C': 18} 19\n",
      "3\n",
      "torch.Size([68, 729])\n",
      "adjacency matrices tensor([[         0,          1,          0,  ..., 1634951028, 1180660590,\n",
      "          745416791],\n",
      "        [         0,          1,          0,  ..., 1697411956, 1600481124,\n",
      "         1953722211],\n",
      "        [         0,          1,          0,  ..., 1735289202, 1953068832,\n",
      "         1818304616],\n",
      "        ...,\n",
      "        [         0,          1,          0,  ...,  778593138,  745827945,\n",
      "         1769366884],\n",
      "        [         0,          1,          0,  ..., 1685024351, 1868783461,\n",
      "          539784307],\n",
      "        [         0,          1,          0,  ..., 1701062444, 1701013878,\n",
      "         1932273466]], dtype=torch.int32)\n",
      "node labels tensor([[        15,          4,          7,  ...,         17, 1847164161,\n",
      "           10914464],\n",
      "        [        15,          4,          7,  ...,         35,          6,\n",
      "         1677743901],\n",
      "        [        15,          4,          7,  ...,         35,         12,\n",
      "                 25],\n",
      "        ...,\n",
      "        [        16,          4,          7,  ...,          0,          0,\n",
      "                  0],\n",
      "        [        16,          4,          7,  ...,          0,          0,\n",
      "                  0],\n",
      "        [        16,          4,          7,  ...,          0,          0,\n",
      "                  0]], dtype=torch.int32)\n",
      "order of the graphs tensor([11, 12, 14, 14, 15, 17, 15, 16, 19, 15, 16, 19, 12, 13, 15, 18, 16, 16,\n",
      "        17, 16, 17, 17, 18, 19, 19, 18, 18, 22, 22, 15, 14, 13, 16, 17, 17, 21,\n",
      "        17, 18, 18, 21, 24, 25, 25, 14, 17, 18, 18, 22, 23, 23, 25, 27, 27, 15,\n",
      "        16, 23, 24, 24, 16, 17, 17, 20, 23, 24, 26, 16, 17, 21])\n",
      "2\n",
      "Parameter containing:\n",
      "tensor([0.0057, 0.0062, 0.0064, 0.0057, 0.0058, 0.0060, 0.0061, 0.0057, 0.0063,\n",
      "        0.0062, 0.0059, 0.0063, 0.0066, 0.0064, 0.0061, 0.0060, 0.0058, 0.0059,\n",
      "        0.0064, 0.0061, 0.0064, 0.0066, 0.0062, 0.0066, 0.0067, 0.0066, 0.0066,\n",
      "        0.0062, 0.0062, 0.0059, 0.0065, 0.0057, 0.0060, 0.0058, 0.0057, 0.0064,\n",
      "        0.0061, 0.0059, 0.0062, 0.0065, 0.0059, 0.0064, 0.0064, 0.0062, 0.0059,\n",
      "        0.0061, 0.0059, 0.0057, 0.0065, 0.0058, 0.0061, 0.0064, 0.0059, 0.0057,\n",
      "        0.0064, 0.0066, 0.0064, 0.0066, 0.0058, 0.0064, 0.0058, 0.0060, 0.0063,\n",
      "        0.0063, 0.0057, 0.0057, 0.0058, 0.0059, 0.0059, 0.0065, 0.0066, 0.0065,\n",
      "        0.0058, 0.0064, 0.0061, 0.0065, 0.0065, 0.0058, 0.0066, 0.0063, 0.0057,\n",
      "        0.0065, 0.0060, 0.0059, 0.0065, 0.0066, 0.0060, 0.0061, 0.0063, 0.0060,\n",
      "        0.0060, 0.0062, 0.0061, 0.0066, 0.0066, 0.0058, 0.0065, 0.0061, 0.0065,\n",
      "        0.0064, 0.0062, 0.0062, 0.0059, 0.0059, 0.0067, 0.0060, 0.0057, 0.0067,\n",
      "        0.0057, 0.0062, 0.0059, 0.0059, 0.0067, 0.0061, 0.0058, 0.0059, 0.0061,\n",
      "        0.0061, 0.0058, 0.0065, 0.0066, 0.0064, 0.0064, 0.0061, 0.0062, 0.0063,\n",
      "        0.0062, 0.0067, 0.0064, 0.0063, 0.0059, 0.0065, 0.0065, 0.0057, 0.0062,\n",
      "        0.0058, 0.0065, 0.0062, 0.0065, 0.0063, 0.0061, 0.0060, 0.0058, 0.0062,\n",
      "        0.0057, 0.0064, 0.0061, 0.0064, 0.0057, 0.0066, 0.0066, 0.0066, 0.0063,\n",
      "        0.0064, 0.0059, 0.0064, 0.0057, 0.0065, 0.0063, 0.0065, 0.0065, 0.0059,\n",
      "        0.0064, 0.0059, 0.0066, 0.0057, 0.0066, 0.0060, 0.0063, 0.0067, 0.0063,\n",
      "        0.0058], requires_grad=True)\n",
      "27 68\n",
      "toto\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import svd\n",
    "import rings\n",
    "from svd import iterated_power as compute_major_axis\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "        \n",
    "    def __init__(self,GraphList,normalize=False,node_label='label'):\n",
    "        super(Net, self).__init__()   \n",
    "        self.normalize=normalize\n",
    "        self.node_label=node_label\n",
    "        dict,self.nb_edge_labels=self.build_node_dictionnary(GraphList)\n",
    "        self.nb_labels=len(dict)\n",
    "        print(self.nb_edge_labels)\n",
    "        self.device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        nb_node_pair_label=self.nb_labels*(self.nb_labels-1)/2.0\n",
    "        nb_edge_pair_label=int(self.nb_edge_labels*(self.nb_edge_labels-1)/2)\n",
    "        \n",
    "        self.node_weighs=nn.Parameter(torch.tensor(1.0/(nb_node_pair_label+nb_edge_pair_label+2))+(1e-3)*torch.rand(int(self.nb_labels*(self.nb_labels-1)/2+1),requires_grad=True,device=self.device)) # all substitution costs+ nodeIns/Del. old version: 0 node subs, 1 nodeIns/Del, 2 : edgeSubs, 3 edgeIns/Del        \n",
    "        self.edge_weighs=nn.Parameter(torch.tensor(1.0/(nb_node_pair_label+nb_edge_pair_label+2))+(1e-3)*torch.rand(nb_edge_pair_label+1,requires_grad=True,device=self.device)) #edgeIns/Del\n",
    "        \n",
    "        self.card=torch.tensor([G.order() for G in GraphList]).to(self.device)\n",
    "        card_max=self.card.max()\n",
    "        self.A=torch.empty((len(GraphList),card_max*card_max),dtype=torch.int,device=self.device)\n",
    "        self.labels=torch.empty((len(GraphList),card_max),dtype=torch.int,device=self.device)\n",
    "        print(self.A.shape)\n",
    "        for k in range(len(GraphList)):\n",
    "            A,l=self.from_networkx_to_tensor(GraphList[k],dict)             \n",
    "            self.A[k,0:A.shape[1]]=A[0]\n",
    "            self.labels[k,0:l.shape[0]]=l\n",
    "        print('adjacency matrices',self.A)\n",
    "        print('node labels',self.labels)\n",
    "        print('order of the graphs',self.card)\n",
    "        \n",
    "    def forward(self, input):        \n",
    "        ged=torch.zeros(len(input)).to(self.device) \n",
    "        node_costs,nodeInsDel,edge_costs,edgeInsDel=self.from_weighs_to_costs()\n",
    "        \n",
    "            \n",
    "        \n",
    "        #print('weighs:',self.weighs.device,'device:',self.device,'card:',self.card.device,'A:',self.A.device,'labels:',self.labels.device)\n",
    "        for k in range(len(input)):            \n",
    "            g1=input[k][0]\n",
    "            g2=input[k][1]\n",
    "            n=self.card[g1]\n",
    "            m=self.card[g2]\n",
    "            \n",
    "            self.ring_g,self.ring_h = rings.build_rings(g1,edgeInsDel.size()), rings.build_rings(g2,edgeInsDel.size()) \n",
    "            \n",
    "            C=self.construct_cost_matrix(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)      \n",
    "            #S=self.mapping_from_similarity(C,n,m)\n",
    "            #S=self.mapping_from_cost(C,n,m)   \n",
    "            #S=self.new_mapping_from_cost(C,n,m,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "            S=self.mapping_from_cost_sans_FW(n,m,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "            \n",
    "            v=torch.flatten(S)\n",
    "            \n",
    "            normalize_factor=1.0\n",
    "            if self.normalize:\n",
    "                nb_edge1=(self.A[g1][0:n*n] != torch.zeros(n*n,device=self.device)).int().sum()\n",
    "                nb_edge2=(self.A[g2][0:m*m] != torch.zeros(m*m,device=self.device)).int().sum()\n",
    "                normalize_factor=nodeInsDel*(n+m)+edgeInsDel*(nb_edge1+nb_edge2)\n",
    "            c=torch.diag(C)\n",
    "            D=C-torch.eye(C.shape[0],device=self.device)*c\n",
    "            ged[k]=(.5*v.T@D@v+c.T@v)/normalize_factor\n",
    "        max=torch.max(ged)\n",
    "        min=torch.min(ged)\n",
    "        ged=(ged-min)/(max-min)\n",
    "        \n",
    "        return ged\n",
    "    \n",
    "    def from_weighs_to_costs(self):\n",
    "        \n",
    "        #cn=torch.exp(self.node_weighs)\n",
    "        #ce=torch.exp(self.edge_weighs)\n",
    "        cn=self.node_weighs*self.node_weighs\n",
    "        ce=self.edge_weighs*self.edge_weighs\n",
    "        total_cost=cn.sum()+ce.sum()\n",
    "        cn=cn/total_cost\n",
    "        ce=ce/total_cost\n",
    "        edgeInsDel=ce[-1]\n",
    "\n",
    "        node_costs=torch.zeros((self.nb_labels,self.nb_labels),device=self.device)\n",
    "        upper_part=torch.triu_indices(node_costs.shape[0],node_costs.shape[1],offset=1,device=self.device)        \n",
    "        node_costs[upper_part[0],upper_part[1]]=cn[0:-1]\n",
    "        node_costs=node_costs+node_costs.T\n",
    "\n",
    "        if self.nb_edge_labels>1:\n",
    "            edge_costs=torch.zeros((self.nb_edge_labels,self.nb_edge_labels),device=self.device)\n",
    "            upper_part=torch.triu_indices(edge_costs.shape[0],edge_costs.shape[1],offset=1,device=self.device)        \n",
    "            edge_costs[upper_part[0],upper_part[1]]=ce[0:-1]\n",
    "            edge_costs=edge_costs+edge_costs.T\n",
    "        else:\n",
    "            edge_costs=torch.zeros(0,device=self.device)\n",
    "        \n",
    "        return node_costs,cn[-1],edge_costs,edgeInsDel\n",
    "    \n",
    "    def build_node_dictionnary(self,GraphList):\n",
    "        #extraction de tous les labels d'atomes\n",
    "        node_labels=[]\n",
    "        for G in Gs:\n",
    "            for v in nx.nodes(G):\n",
    "                if not G.nodes[v][self.node_label][0] in node_labels:\n",
    "                    node_labels.append(G.nodes[v][self.node_label][0])\n",
    "        node_labels.sort()\n",
    "        #extraction d'un dictionnaire permettant de numéroter chaque label par un numéro.\n",
    "        dict={}\n",
    "        k=0\n",
    "        for label in node_labels:\n",
    "            dict[label]=k\n",
    "            k=k+1\n",
    "        print(node_labels)\n",
    "        print(dict,len(dict))\n",
    "    \n",
    "        return dict,max(max([[int(G[e[0]][e[1]]['bond_type']) for e in G.edges()] for G in GraphList]))\n",
    "    \n",
    "    def from_networkx_to_tensor(self,G,dict):    \n",
    "        A=torch.tensor(nx.to_scipy_sparse_matrix(G,dtype=int,weight='bond_type').todense(),dtype=torch.int)        \n",
    "        lab=[dict[G.nodes[v][self.node_label][0]] for v in nx.nodes(G)]\n",
    "   \n",
    "        return (A.view(1,A.shape[0]*A.shape[1]),torch.tensor(lab))\n",
    "\n",
    "    def construct_cost_matrix(self,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel):\n",
    "        n = self.card[g1].item()\n",
    "        m = self.card[g2].item()\n",
    "        \n",
    "        A1=torch.zeros((n+1,n+1),dtype=torch.int,device=self.device)\n",
    "        A1[0:n,0:n]=self.A[g1][0:n*n].view(n,n)\n",
    "        A2=torch.zeros((m+1,m+1),dtype=torch.int,device=self.device)\n",
    "        A2[0:m,0:m]=self.A[g2][0:m*m].view(m,m)\n",
    "        \n",
    "        \n",
    "         # costs: 0 node subs, 1 nodeIns/Del, 2 : edgeSubs, 3 edgeIns/Del\n",
    "        \n",
    "        #C=cost[3]*torch.cat([torch.cat([C12[l][k] for k in range(n+1)],1) for l in range(n+1)])\n",
    "        #Pas bien sur mais cela semble fonctionner.\n",
    "        C=edgeInsDel*self.matrix_edgeInsDel(A1,A2)\n",
    "        if self.nb_edge_labels>1:\n",
    "            for k in range(self.nb_edge_labels):\n",
    "                for l in range(self.nb_edge_labels):\n",
    "                    if k != l:\n",
    "#                    C.add_(self.matrix_edgeSubst(A1,A2,k+1,l+1),alpha=edge_costs[k][l])\n",
    "                        C=C+edge_costs[k][l]*self.matrix_edgeSubst(A1,A2,k+1,l+1)\n",
    "        #C=cost[3]*torch.tensor(np.array([ [  k!=l and A1[k//(m+1),l//(m+1)]^A2[k%(m+1),l%(m+1)] for k in range((n+1)*(m+1))] for l in range((n+1)*(m+1))]),device=self.device)        \n",
    "\n",
    "        l1=self.labels[g1][0:n]\n",
    "        l2=self.labels[g2][0:m]\n",
    "        D=torch.zeros((n+1)*(m+1),device=self.device)\n",
    "        D[n*(m+1):]=nodeInsDel\n",
    "        D[n*(m+1)+m]=0\n",
    "        D[[i*(m+1)+m for i in range(n)]]=nodeInsDel\n",
    "        D[[k for k in range(n*(m+1)) if k%(m+1) != m]]=torch.tensor([node_costs[l1[k//(m+1)],l2[k%(m+1)]] for k in range(n*(m+1)) if k%(m+1) != m],device=self.device )\n",
    "        mask = torch.diag(torch.ones_like(D))\n",
    "        C=mask*torch.diag(D) + (1. - mask)*C\n",
    "        \n",
    "        #C[range(len(C)),range(len(C))]=D\n",
    "      \n",
    "        return C\n",
    "    def matrix_edgeInsDel(self,A1,A2):\n",
    "        Abin1=(A1!=torch.zeros((A1.shape[0],A1.shape[1]),device=self.device))\n",
    "        Abin2=(A2!=torch.zeros((A2.shape[0],A2.shape[1]),device=self.device))\n",
    "        C1=torch.einsum('ij,kl->ijkl',torch.logical_not(Abin1),Abin2)\n",
    "        C2=torch.einsum('ij,kl->ijkl',Abin1,torch.logical_not(Abin2))\n",
    "        C12=torch.logical_or(C1,C2).int()\n",
    "    \n",
    "        return torch.cat(torch.unbind(torch.cat(torch.unbind(C12,1),1),0),1)\n",
    "\n",
    "    def matrix_edgeSubst(self,A1,A2,lab1,lab2):\n",
    "        Abin1=(A1==lab1*torch.ones((A1.shape[0],A1.shape[1]),device=self.device)).int()\n",
    "        Abin2=(A2==lab2*torch.ones((A2.shape[0],A2.shape[1]),device=self.device)).int()\n",
    "        C=torch.einsum('ij,kl->ijkl',Abin1,Abin2)\n",
    "        \n",
    "        return torch.cat(torch.unbind(torch.cat(torch.unbind(C,1),1),0),1)\n",
    "    \n",
    "    def similarity_from_cost(self,C):\n",
    "        N=C.shape[0]\n",
    "             \n",
    "        #return (torch.norm(C,p='fro')*torch.eye(N,device=self.device) -C)\n",
    "        return (C.max()*torch.eye(N,device=self.device) -C)\n",
    "    \n",
    "    def lsape_populate_instance(self,first_graph,second_graph,average_node_cost, average_edge_cost,alpha,lbda):       #ring_g, ring_h come from global ring with all graphs in so ring_g = rings['g'] and ring_h = rings['h']\n",
    "        g,h = Gs[first_graph], Gs[second_graph]\n",
    "        self.average_cost =[average_node_cost, average_edge_cost]\n",
    "        self.first_graph, self.second_graph = first_graph,second_graph\n",
    "        \n",
    "        node_costs,nodeInsDel,edge_costs,edgeInsDel=self.from_weighs_to_costs()\n",
    "\n",
    "        lsape_instance = [[0 for _ in range(len(g) + 1)] for __ in range(len(h) + 1)]\n",
    "        for g_node_index in range(len(g) + 1):\n",
    "            for h_node_index in range(len(h) + 1):\n",
    "                lsape_instance[h_node_index][g_node_index] = rings.compute_ring_distance(g,h,self.ring_g,self.ring_h,g_node_index,h_node_index,alpha,lbda,node_costs,nodeInsDel,edge_costs,edgeInsDel,first_graph,second_graph)\n",
    "        for i in lsape_instance :\n",
    "            i = torch.as_tensor(i)\n",
    "        lsape_instance = torch.as_tensor(lsape_instance)\n",
    "        #print(type(lsape_instance))\n",
    "        return lsape_instance\n",
    "    \n",
    "  \n",
    "    def mapping_from_cost_sans_FW(self,n,m,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel): \n",
    "        c_0 =self.lsape_populate_instance(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "        x0=svd.eps_assigment_from_mapping(torch.exp(-c_0),10).view((n+1)*(m+1),1)\n",
    "        return x0\n",
    "    \n",
    "    def new_mapping_from_cost(self,C,n,m,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel): \n",
    "        c=torch.diag(C)       \n",
    "        c_0 =self.lsape_populate_instance(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "        D=C-torch.eye(C.shape[0],device=self.device)*c\n",
    "        x0=svd.eps_assigment_from_mapping(torch.exp(-c_0),10).view((n+1)*(m+1),1)\n",
    "        return svd.franck_wolfe(x0,D,c,5,15,n,m)\n",
    "    \n",
    "    \n",
    "    def mapping_from_cost(self,C,n,m):\n",
    "        c=torch.diag(C)\n",
    "        D=C-torch.eye(C.shape[0],device=self.device)*c\n",
    "        x0=svd.eps_assigment_from_mapping(torch.exp(-.5*c.view(n+1,m+1)),10).view((n+1)*(m+1),1)\n",
    "        x=svd.franck_wolfe(x0,D,c,5,10,n,m)\n",
    "        def print_grad(grad):\n",
    "            if(grad.norm()!= 0.0):\n",
    "                print(grad)\n",
    "        \n",
    "#        x.register_hook(print_grad)\n",
    "        return x\n",
    "\n",
    "print('Gs=',len(Gs))\n",
    "model = Net(Gs,normalize=True,node_label='extended_label')\n",
    "\n",
    "params = list(model.parameters())\n",
    "print(len(params))\n",
    "print(params[0])\n",
    "#print(model(input))\n",
    "print(max([G.order() for G in Gs]),len(Gs))\n",
    "print('toto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([19,  0, 22, 24,  2, 11,  8,  3, 11, 11, 27,  1])\n",
      "train graphs: tensor([19, 65, 26, 45, 66,  7, 18, 38, 14, 19, 19, 60,  5, 62, 52, 52, 29])\n",
      "couples= tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "          3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,\n",
      "          5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "          6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "          9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11,\n",
      "         12, 12, 12, 12, 13, 13, 13, 14, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,  2,  3,\n",
      "          4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,  3,  4,  5,  6,  7,\n",
      "          8,  9, 10, 11, 12, 13, 14, 15, 16,  4,  5,  6,  7,  8,  9, 10, 11, 12,\n",
      "         13, 14, 15, 16,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,  6,  7,\n",
      "          8,  9, 10, 11, 12, 13, 14, 15, 16,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
      "         16,  8,  9, 10, 11, 12, 13, 14, 15, 16,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "         10, 11, 12, 13, 14, 15, 16, 11, 12, 13, 14, 15, 16, 12, 13, 14, 15, 16,\n",
      "         13, 14, 15, 16, 14, 15, 16, 15, 16, 16]])\n",
      "nb_class1/nb_class2= 12 5\n",
      "couples restreints: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "          3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,\n",
      "          5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "          6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "          9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,  2,  3,\n",
      "          4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,  3,  4,  5,  6,  7,\n",
      "          8,  9, 10, 11, 12, 13, 14, 15, 16,  4,  5,  6,  7,  8,  9, 10, 11, 12,\n",
      "         13, 14, 15, 16,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,  6,  7,\n",
      "          8,  9, 10, 11, 12, 13, 14, 15, 16,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
      "         16,  8,  9, 10, 11, 12, 13, 14, 15, 16,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "         10, 11, 12, 13, 14, 15, 16, 11, 12, 13, 14, 15, 16, 12, 13, 14, 15, 16]])\n",
      "old_size, new size= 126 126.0\n",
      "126\n",
      "data= tensor([[19, 65],\n",
      "        [19, 26],\n",
      "        [19, 45],\n",
      "        [19, 66],\n",
      "        [19,  7],\n",
      "        [19, 18],\n",
      "        [19, 38],\n",
      "        [19, 14],\n",
      "        [19, 19],\n",
      "        [19, 19],\n",
      "        [19, 60],\n",
      "        [19,  5],\n",
      "        [19, 62],\n",
      "        [19, 52],\n",
      "        [19, 52],\n",
      "        [19, 29],\n",
      "        [65, 26],\n",
      "        [65, 45],\n",
      "        [65, 66],\n",
      "        [65,  7],\n",
      "        [65, 18],\n",
      "        [65, 38],\n",
      "        [65, 14],\n",
      "        [65, 19],\n",
      "        [65, 19],\n",
      "        [65, 60],\n",
      "        [65,  5],\n",
      "        [65, 62],\n",
      "        [65, 52],\n",
      "        [65, 52],\n",
      "        [65, 29],\n",
      "        [26, 45],\n",
      "        [26, 66],\n",
      "        [26,  7],\n",
      "        [26, 18],\n",
      "        [26, 38],\n",
      "        [26, 14],\n",
      "        [26, 19],\n",
      "        [26, 19],\n",
      "        [26, 60],\n",
      "        [26,  5],\n",
      "        [26, 62],\n",
      "        [26, 52],\n",
      "        [26, 52],\n",
      "        [26, 29],\n",
      "        [45, 66],\n",
      "        [45,  7],\n",
      "        [45, 18],\n",
      "        [45, 38],\n",
      "        [45, 14],\n",
      "        [45, 19],\n",
      "        [45, 19],\n",
      "        [45, 60],\n",
      "        [45,  5],\n",
      "        [45, 62],\n",
      "        [45, 52],\n",
      "        [45, 52],\n",
      "        [45, 29],\n",
      "        [66,  7],\n",
      "        [66, 18],\n",
      "        [66, 38],\n",
      "        [66, 14],\n",
      "        [66, 19],\n",
      "        [66, 19],\n",
      "        [66, 60],\n",
      "        [66,  5],\n",
      "        [66, 62],\n",
      "        [66, 52],\n",
      "        [66, 52],\n",
      "        [66, 29],\n",
      "        [ 7, 18],\n",
      "        [ 7, 38],\n",
      "        [ 7, 14],\n",
      "        [ 7, 19],\n",
      "        [ 7, 19],\n",
      "        [ 7, 60],\n",
      "        [ 7,  5],\n",
      "        [ 7, 62],\n",
      "        [ 7, 52],\n",
      "        [ 7, 52],\n",
      "        [ 7, 29],\n",
      "        [18, 38],\n",
      "        [18, 14],\n",
      "        [18, 19],\n",
      "        [18, 19],\n",
      "        [18, 60],\n",
      "        [18,  5],\n",
      "        [18, 62],\n",
      "        [18, 52],\n",
      "        [18, 52],\n",
      "        [18, 29],\n",
      "        [38, 14],\n",
      "        [38, 19],\n",
      "        [38, 19],\n",
      "        [38, 60],\n",
      "        [38,  5],\n",
      "        [38, 62],\n",
      "        [38, 52],\n",
      "        [38, 52],\n",
      "        [38, 29],\n",
      "        [14, 19],\n",
      "        [14, 19],\n",
      "        [14, 60],\n",
      "        [14,  5],\n",
      "        [14, 62],\n",
      "        [14, 52],\n",
      "        [14, 52],\n",
      "        [14, 29],\n",
      "        [19, 19],\n",
      "        [19, 60],\n",
      "        [19,  5],\n",
      "        [19, 62],\n",
      "        [19, 52],\n",
      "        [19, 52],\n",
      "        [19, 29],\n",
      "        [19, 60],\n",
      "        [19,  5],\n",
      "        [19, 62],\n",
      "        [19, 52],\n",
      "        [19, 52],\n",
      "        [19, 29],\n",
      "        [60,  5],\n",
      "        [60, 62],\n",
      "        [60, 52],\n",
      "        [60, 52],\n",
      "        [60, 29]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "nb=len(Gs)\n",
    "class1=torch.tensor([k for k in range(len(y)) if y[k]==1])\n",
    "class2=torch.tensor([k for k in range(len(y)) if y[k]==0])\n",
    "\n",
    "nb_class1=12\n",
    "nb_class2=int((nb_class1-1)/2)\n",
    "train_size=nb_class1+nb_class2\n",
    "#train_size=20\n",
    "\n",
    "#if train_size % 2 == 0:\n",
    "#    nb_class1=int(train_size/2)\n",
    "#    nb_class2=int(train_size/2)\n",
    "#else:\n",
    "#    nb_class1=int(train_size/2)+1\n",
    "#    nb_class2=int(train_size/2)\n",
    "    \n",
    "print((torch.abs(10000*torch.randn(nb_class1)).int()%class1.size()[0]).long())\n",
    "random_class1=class1[(torch.abs(10000*torch.randn(nb_class1)).int()%class1.size()[0]).long()]\n",
    "random_class2=class2[(torch.abs(10000*torch.randn(nb_class2)).int()%class2.size()[0]).long()]\n",
    "train_graphs=torch.cat((random_class1,random_class2),0)\n",
    "print('train graphs:',train_graphs)\n",
    "\n",
    "\n",
    "couples=torch.triu_indices(train_size,train_size,offset=1)\n",
    "print('couples=',couples)\n",
    "print('nb_class1/nb_class2=',nb_class1,nb_class2)\n",
    "#combinations=itertools.combinations(range(nb),2)\n",
    "\n",
    "nb_elt=int(nb_class1*(nb_class1+2*nb_class2-1)/2)\n",
    "print('couples restreints:',couples[:,0:nb_elt])\n",
    "\n",
    "#nb_elt=int(train_size*(train_size-1)/2)\n",
    "data=torch.empty((nb_elt,2),dtype=torch.int)\n",
    "yt=torch.ones(nb_elt)\n",
    "print('old_size, new size=',nb_elt,.5*nb_class1*(nb_class1+2*nb_class2-1))\n",
    "data[0:nb_elt,0]=train_graphs[couples[0,0:nb_elt]]\n",
    "data[0:nb_elt,1]=train_graphs[couples[1,0:nb_elt]]\n",
    "\n",
    "\n",
    "#data[0:nb_elt,0]=train_graphs[couples[0]]\n",
    "#data[0:nb_elt,1]=train_graphs[couples[1]]\n",
    "print(nb_elt)\n",
    "#couples=[]\n",
    "for k in range(nb_elt):\n",
    "    if (y[data[k][0]]!=y[data[k][1]]):\n",
    "        yt[k]=-1.0        \n",
    "\n",
    "print('data=',data)\n",
    "\n",
    "#print(couples[1:2])\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")          # a CUDA device object    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 32\n",
      "5 4\n",
      "i :  tensor([[26, 45],\n",
      "        [45, 19],\n",
      "        [19, 52],\n",
      "        [38, 52],\n",
      "        [ 7, 29],\n",
      "        [19, 18],\n",
      "        [ 7, 52],\n",
      "        [65, 62]], dtype=torch.int32) \n",
      " j :  tensor([ 1.,  1., -1., -1., -1.,  1., -1., -1.])\n",
      "i :  tensor([[45,  7],\n",
      "        [45, 18],\n",
      "        [65, 66],\n",
      "        [66, 52],\n",
      "        [65, 60],\n",
      "        [66, 52],\n",
      "        [45, 66],\n",
      "        [19, 52]], dtype=torch.int32) \n",
      " j :  tensor([ 1.,  1.,  1., -1.,  1., -1.,  1., -1.])\n",
      "i :  tensor([[ 7, 52],\n",
      "        [19, 19],\n",
      "        [19, 26],\n",
      "        [ 7, 38],\n",
      "        [ 7, 60],\n",
      "        [ 7, 19],\n",
      "        [65, 26],\n",
      "        [18, 38]], dtype=torch.int32) \n",
      " j :  tensor([-1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "i :  tensor([[26, 52],\n",
      "        [45, 29],\n",
      "        [18, 29],\n",
      "        [14, 29],\n",
      "        [60, 62],\n",
      "        [65, 29],\n",
      "        [65,  5],\n",
      "        [18,  5]], dtype=torch.int32) \n",
      " j :  tensor([-1., -1., -1., -1., -1., -1., -1., -1.])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "\n",
    "[train_D, valid_D,train_L,valid_L]= train_test_split(data,yt, test_size=0.25,train_size=0.75, shuffle=True) #, stratify=yt)\n",
    "#print(train_D)   \n",
    "    \n",
    "DatasetTrain = TensorDataset(train_D, train_L)\n",
    "\n",
    "DatasetValid=TensorDataset(valid_D, valid_L)\n",
    "\n",
    "trainloader=torch.utils.data.DataLoader(DatasetTrain,batch_size=16,shuffle=True,drop_last=True, num_workers=0)\n",
    "#len(train_D) #31\n",
    "validationloader=torch.utils.data.DataLoader(DatasetValid, batch_size=8, drop_last=True,num_workers=0)\n",
    "\n",
    "print(len(train_D), len(valid_D))\n",
    "print(len(trainloader),len(validationloader))\n",
    "for i,j in validationloader:\n",
    "    print('i : ',i,'\\n j : ',j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if torch.cuda.device_count() > 1:\n",
    "#  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "#  model = nn.DataParallel(model)\n",
    "from triangular_losses import TriangularConstraint as triangular_constraint\n",
    "\n",
    "model.to(device)\n",
    "def classification(model,data,yt,nb_iter):\n",
    "\n",
    "    criterion = torch.nn.HingeEmbeddingLoss(margin=1.0,reduction='mean')\n",
    "    criterionTri=triangular_constraint()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    #print(device)\n",
    "\n",
    "    #torch.cat((same_class[0:20],diff_class[0:20]),0).to(device)\n",
    "    whole_input=data.to(device)\n",
    "    target=yt.to(device) \n",
    "    #torch.ones(40,device=device)\n",
    "    #target[20:]=-1.0\n",
    "    #target=(yt[0:20]).to(device)\n",
    "    InsDel=np.empty((nb_iter,2))\n",
    "    node_costs,nodeInsDel,edge_costs,edgeInsDel=model.from_weighs_to_costs()\n",
    "    nodeSub=np.empty((nb_iter,int(node_costs.shape[0]*(node_costs.shape[0]-1)/2)))\n",
    "    edgeSub=np.empty((nb_iter,int(edge_costs.shape[0]*(edge_costs.shape[0]-1)/2)))\n",
    "    loss_plt=np.empty(nb_iter)\n",
    "    loss_train_plt=np.empty(nb_iter)\n",
    "    loss_valid_plt=np.empty(nb_iter)\n",
    "    min_valid_loss = np.inf\n",
    "    iter_min_valid_loss = 0\n",
    "    \n",
    "    for t in range(nb_iter):    \n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        tmp=np.inf\n",
    "        for train_data,train_labels in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            inputt=train_data.to(device)\n",
    "            \n",
    "            # Forward pass: Compute predicted y by passing data to the model\n",
    "            y_pred = model(whole_input).to(device)\n",
    "\n",
    "            # Compute and print loss\n",
    "            loss = criterion(y_pred, target).to(device)\n",
    "            node_costs,nodeInsDel,edge_costs,edgeInsDel=model.from_weighs_to_costs()\n",
    "            triangularInq=criterionTri(node_costs,nodeInsDel,edge_costs,edgeInsDel)\n",
    "            loss=loss*(1+triangularInq)\n",
    "            loss.to(device)\n",
    "            # Zero gradients, perform a backward pass, and update the weights.\n",
    "            #optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print('loss.item of the train = ', t, loss.item())\n",
    "            train_loss =+ loss.item() #* train_data.size(0) \n",
    "            if (loss.item()<tmp): tmp=loss.item()\n",
    "        loss_plt[t]=loss.item()  \n",
    "        loss_train_plt[t]=train_loss /len(trainloader)\n",
    "        #loss_plt[t]=tmp\n",
    "            \n",
    "        if t % 100 == 99 or t==0:   \n",
    "            print('ged=',y_pred*target)  #train_labels\n",
    "            print('Distances: ',y_pred)\n",
    "            print('Loss Triangular:',triangularInq.item())\n",
    "            print('node_costs :')\n",
    "            print(node_costs)\n",
    "            print('nodeInsDel:',nodeInsDel.item())\n",
    "            print('edge_costs :')\n",
    "            print(edge_costs)\n",
    "            print('edgeInsDel:',edgeInsDel.item())\n",
    "            \n",
    "            \n",
    "            \n",
    "        for valid_data,valid_labels in validationloader:\n",
    "            \n",
    "            inputt=valid_data.to(device)\n",
    "            y_pred = model(inputt).to(device)\n",
    "            # Compute and print loss\n",
    "            loss = criterion(y_pred, valid_labels).to(device)    \n",
    "            loss.to(device)\n",
    "            \n",
    "            print('loss.item of the valid = ', t, loss.item())  \n",
    "            valid_loss = valid_loss + loss.item() #* valid_data.size(0)\n",
    "            \n",
    "        loss_valid_plt[t]=valid_loss / len(validationloader)   \n",
    "        \n",
    "        InsDel[t][0]=nodeInsDel.item()\n",
    "        InsDel[t][1]=edgeInsDel.item()\n",
    "        \n",
    "        \n",
    "        k=0\n",
    "        for p in range(node_costs.shape[0]):\n",
    "            for q in range(p+1,node_costs.shape[0]):\n",
    "                nodeSub[t][k]=node_costs[p][q]\n",
    "                k=k+1\n",
    "        k=0\n",
    "        for p in range(edge_costs.shape[0]):\n",
    "            for q in range(p+1,edge_costs.shape[0]):\n",
    "                edgeSub[t][k]=edge_costs[p][q]\n",
    "                k=k+1\n",
    "        \n",
    "            \n",
    "        print(f'Iteration {t+1} \\t\\t Training Loss: {\\\n",
    "        train_loss / len(trainloader)} \\t\\t Validation Loss: {\\\n",
    "        valid_loss / len(validationloader)}')\n",
    "        if min_valid_loss > valid_loss:\n",
    "            print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f})')\n",
    "            min_valid_loss = valid_loss\n",
    "            iter_min_valid_loss = t\n",
    "    print('iter and min_valid_loss = ',iter_min_valid_loss, min_valid_loss)\n",
    "    nodeInsDel_min = InsDel[iter_min_valid_loss][0]\n",
    "    edgeInsDel_min = InsDel[iter_min_valid_loss][1]\n",
    "    nodeSub_min = nodeSub[iter_min_valid_loss]\n",
    "    edgeSub_min = edgeSub[iter_min_valid_loss]\n",
    "    print(' Min cost for nodeInsDel = ', nodeInsDel_min)\n",
    "    print(' Min cost for edgeInsDel = ', edgeInsDel_min)\n",
    "    print(' Min cost for nodeSub = ', nodeSub_min)\n",
    "    print(' Min cost for edgeSub = ', edgeSub_min)\n",
    "    torch.save(nodeInsDel_min, 'nodeInsDel_min', pickle_module=pkl) \n",
    "    torch.save(edgeInsDel_min, 'edgeInsDel_min', pickle_module=pkl) \n",
    "    torch.save(nodeSub_min, 'nodeSub_min', pickle_module=pkl) \n",
    "    torch.save(edgeSub_min, 'edgeSub_min', pickle_module=pkl)\n",
    "    return InsDel,nodeSub,edgeSub,loss_plt,loss_valid_plt,loss_train_plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item of the train =  0 0.3097071647644043\n",
      "loss.item of the train =  0 0.31613248586654663\n",
      "loss.item of the train =  0 0.308906227350235\n",
      "loss.item of the train =  0 0.31278249621391296\n",
      "loss.item of the train =  0 0.31432560086250305\n",
      "ged= tensor([ 0.0168,  0.2172,  0.2269,  0.1500,  0.0104,  0.1547,  0.2311,  0.1206,\n",
      "         0.0000,  0.0000,  0.1567, -0.1671, -0.5288, -0.9551, -0.9551, -0.1480,\n",
      "         0.2269,  0.2344,  0.1686,  0.0200,  0.1708,  0.2407,  0.1448,  0.0168,\n",
      "         0.0168,  0.1753, -0.1833, -0.5459, -0.9480, -0.9480, -0.1605,  0.0184,\n",
      "         0.1471,  0.1699,  0.1439,  0.0142,  0.1905,  0.1641,  0.1641,  0.1488,\n",
      "        -0.1491, -0.3409, -0.6603, -0.6603, -0.2110,  0.1406,  0.1672,  0.1245,\n",
      "         0.0184,  0.1911,  0.1654,  0.1654,  0.1422, -0.1426, -0.3355, -0.6721,\n",
      "        -0.6721, -0.2171,  0.1434,  0.0132,  0.1702,  0.1489,  0.1334,  0.1334,\n",
      "         0.0101, -0.0170, -0.3603, -0.7564, -0.7564, -0.1766,  0.1551,  0.2350,\n",
      "         0.1298,  0.0104,  0.0104,  0.1680, -0.1699, -0.5440, -1.0000, -1.0000,\n",
      "        -0.1593,  0.1706,  0.1372,  0.1242,  0.1242,  0.0132, -0.0112, -0.3552,\n",
      "        -0.7623, -0.7623, -0.1693,  0.1958,  0.1651,  0.1651,  0.1396, -0.1545,\n",
      "        -0.3418, -0.6828, -0.6828, -0.2168,  0.1641,  0.1641,  0.2241, -0.1713,\n",
      "        -0.5808, -0.9298, -0.9298, -0.0257,  0.0000,  0.1567, -0.1671, -0.5288,\n",
      "        -0.9551, -0.9551, -0.1480,  0.1567, -0.1671, -0.5288, -0.9551, -0.9551,\n",
      "        -0.1480, -0.0170, -0.3620, -0.7740, -0.7740, -0.1803],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Distances:  tensor([0.0168, 0.2172, 0.2269, 0.1500, 0.0104, 0.1547, 0.2311, 0.1206, 0.0000,\n",
      "        0.0000, 0.1567, 0.1671, 0.5288, 0.9551, 0.9551, 0.1480, 0.2269, 0.2344,\n",
      "        0.1686, 0.0200, 0.1708, 0.2407, 0.1448, 0.0168, 0.0168, 0.1753, 0.1833,\n",
      "        0.5459, 0.9480, 0.9480, 0.1605, 0.0184, 0.1471, 0.1699, 0.1439, 0.0142,\n",
      "        0.1905, 0.1641, 0.1641, 0.1488, 0.1491, 0.3409, 0.6603, 0.6603, 0.2110,\n",
      "        0.1406, 0.1672, 0.1245, 0.0184, 0.1911, 0.1654, 0.1654, 0.1422, 0.1426,\n",
      "        0.3355, 0.6721, 0.6721, 0.2171, 0.1434, 0.0132, 0.1702, 0.1489, 0.1334,\n",
      "        0.1334, 0.0101, 0.0170, 0.3603, 0.7564, 0.7564, 0.1766, 0.1551, 0.2350,\n",
      "        0.1298, 0.0104, 0.0104, 0.1680, 0.1699, 0.5440, 1.0000, 1.0000, 0.1593,\n",
      "        0.1706, 0.1372, 0.1242, 0.1242, 0.0132, 0.0112, 0.3552, 0.7623, 0.7623,\n",
      "        0.1693, 0.1958, 0.1651, 0.1651, 0.1396, 0.1545, 0.3418, 0.6828, 0.6828,\n",
      "        0.2168, 0.1641, 0.1641, 0.2241, 0.1713, 0.5808, 0.9298, 0.9298, 0.0257,\n",
      "        0.0000, 0.1567, 0.1671, 0.5288, 0.9551, 0.9551, 0.1480, 0.1567, 0.1671,\n",
      "        0.5288, 0.9551, 0.9551, 0.1480, 0.0170, 0.3620, 0.7740, 0.7740, 0.1803],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Loss Triangular: 0.0\n",
      "node_costs :\n",
      "tensor([[0.0000, 0.0047, 0.0057, 0.0060, 0.0047, 0.0048, 0.0053, 0.0056, 0.0047,\n",
      "         0.0060, 0.0056, 0.0050, 0.0059, 0.0065, 0.0062, 0.0055, 0.0053, 0.0049,\n",
      "         0.0051],\n",
      "        [0.0047, 0.0000, 0.0061, 0.0054, 0.0061, 0.0066, 0.0057, 0.0065, 0.0067,\n",
      "         0.0066, 0.0066, 0.0056, 0.0057, 0.0050, 0.0064, 0.0046, 0.0052, 0.0049,\n",
      "         0.0046],\n",
      "        [0.0057, 0.0061, 0.0000, 0.0062, 0.0055, 0.0051, 0.0057, 0.0064, 0.0050,\n",
      "         0.0062, 0.0062, 0.0057, 0.0051, 0.0056, 0.0050, 0.0047, 0.0064, 0.0049,\n",
      "         0.0054],\n",
      "        [0.0060, 0.0054, 0.0062, 0.0000, 0.0062, 0.0050, 0.0047, 0.0062, 0.0065,\n",
      "         0.0061, 0.0066, 0.0049, 0.0060, 0.0048, 0.0052, 0.0058, 0.0060, 0.0046,\n",
      "         0.0047],\n",
      "        [0.0047, 0.0061, 0.0055, 0.0062, 0.0000, 0.0049, 0.0051, 0.0050, 0.0063,\n",
      "         0.0066, 0.0064, 0.0048, 0.0062, 0.0055, 0.0063, 0.0063, 0.0048, 0.0067,\n",
      "         0.0059],\n",
      "        [0.0048, 0.0066, 0.0051, 0.0050, 0.0049, 0.0000, 0.0047, 0.0063, 0.0052,\n",
      "         0.0050, 0.0064, 0.0066, 0.0052, 0.0055, 0.0060, 0.0052, 0.0053, 0.0057,\n",
      "         0.0055],\n",
      "        [0.0053, 0.0057, 0.0057, 0.0047, 0.0051, 0.0047, 0.0000, 0.0065, 0.0066,\n",
      "         0.0049, 0.0063, 0.0054, 0.0064, 0.0062, 0.0058, 0.0057, 0.0051, 0.0050,\n",
      "         0.0068],\n",
      "        [0.0056, 0.0065, 0.0064, 0.0062, 0.0050, 0.0063, 0.0065, 0.0000, 0.0052,\n",
      "         0.0046, 0.0068, 0.0047, 0.0057, 0.0051, 0.0050, 0.0068, 0.0054, 0.0048,\n",
      "         0.0050],\n",
      "        [0.0047, 0.0067, 0.0050, 0.0065, 0.0063, 0.0052, 0.0066, 0.0052, 0.0000,\n",
      "         0.0056, 0.0054, 0.0048, 0.0063, 0.0066, 0.0062, 0.0061, 0.0054, 0.0058,\n",
      "         0.0060],\n",
      "        [0.0060, 0.0066, 0.0062, 0.0061, 0.0066, 0.0050, 0.0049, 0.0046, 0.0056,\n",
      "         0.0000, 0.0057, 0.0067, 0.0061, 0.0060, 0.0051, 0.0064, 0.0063, 0.0047,\n",
      "         0.0056],\n",
      "        [0.0056, 0.0066, 0.0062, 0.0066, 0.0064, 0.0064, 0.0063, 0.0068, 0.0054,\n",
      "         0.0057, 0.0000, 0.0048, 0.0064, 0.0058, 0.0064, 0.0058, 0.0054, 0.0053,\n",
      "         0.0049],\n",
      "        [0.0050, 0.0056, 0.0057, 0.0049, 0.0048, 0.0066, 0.0054, 0.0047, 0.0048,\n",
      "         0.0067, 0.0048, 0.0000, 0.0057, 0.0047, 0.0062, 0.0054, 0.0061, 0.0047,\n",
      "         0.0065],\n",
      "        [0.0059, 0.0057, 0.0051, 0.0060, 0.0062, 0.0052, 0.0064, 0.0057, 0.0063,\n",
      "         0.0061, 0.0064, 0.0057, 0.0000, 0.0065, 0.0067, 0.0059, 0.0062, 0.0051,\n",
      "         0.0060],\n",
      "        [0.0065, 0.0050, 0.0056, 0.0048, 0.0055, 0.0055, 0.0062, 0.0051, 0.0066,\n",
      "         0.0060, 0.0058, 0.0047, 0.0065, 0.0000, 0.0047, 0.0064, 0.0059, 0.0064,\n",
      "         0.0063],\n",
      "        [0.0062, 0.0064, 0.0050, 0.0052, 0.0063, 0.0060, 0.0058, 0.0050, 0.0062,\n",
      "         0.0051, 0.0064, 0.0062, 0.0067, 0.0047, 0.0000, 0.0051, 0.0062, 0.0051,\n",
      "         0.0066],\n",
      "        [0.0055, 0.0046, 0.0047, 0.0058, 0.0063, 0.0052, 0.0057, 0.0068, 0.0061,\n",
      "         0.0064, 0.0058, 0.0054, 0.0059, 0.0064, 0.0051, 0.0000, 0.0047, 0.0067,\n",
      "         0.0052],\n",
      "        [0.0053, 0.0052, 0.0064, 0.0060, 0.0048, 0.0053, 0.0051, 0.0054, 0.0054,\n",
      "         0.0063, 0.0054, 0.0061, 0.0062, 0.0059, 0.0062, 0.0047, 0.0000, 0.0060,\n",
      "         0.0068],\n",
      "        [0.0049, 0.0049, 0.0049, 0.0046, 0.0067, 0.0057, 0.0050, 0.0048, 0.0058,\n",
      "         0.0047, 0.0053, 0.0047, 0.0051, 0.0064, 0.0051, 0.0067, 0.0060, 0.0000,\n",
      "         0.0059],\n",
      "        [0.0051, 0.0046, 0.0054, 0.0047, 0.0059, 0.0055, 0.0068, 0.0050, 0.0060,\n",
      "         0.0056, 0.0049, 0.0065, 0.0060, 0.0063, 0.0066, 0.0052, 0.0068, 0.0059,\n",
      "         0.0000]], grad_fn=<AddBackward0>)\n",
      "nodeInsDel: 0.01430431567132473\n",
      "edge_costs :\n",
      "tensor([[0.0000e+00, 2.9188e-03, 4.5667e-05],\n",
      "        [2.9188e-03, 0.0000e+00, 7.8113e-05],\n",
      "        [4.5667e-05, 7.8113e-05, 0.0000e+00]], grad_fn=<AddBackward0>)\n",
      "edgeInsDel: 0.01209157332777977\n",
      "loss.item of the valid =  0 0.24637195467948914\n",
      "loss.item of the valid =  0 0.08290764689445496\n",
      "loss.item of the valid =  0 0.1333867609500885\n",
      "loss.item of the valid =  0 0.6716434359550476\n",
      "Iteration 1 \t\t Training Loss: 0.06286512017250061 \t\t Validation Loss: 0.28357744961977005\n",
      "Validation Loss Decreased(inf--->1.134310)\n",
      "loss.item of the train =  1 0.3149144649505615\n",
      "loss.item of the train =  1 0.31499356031417847\n",
      "loss.item of the train =  1 0.31475013494491577\n",
      "loss.item of the train =  1 0.3142741024494171\n",
      "loss.item of the train =  1 0.31360986828804016\n",
      "loss.item of the valid =  1 0.2474249303340912\n",
      "loss.item of the valid =  1 0.08436498045921326\n",
      "loss.item of the valid =  1 0.11892977356910706\n",
      "loss.item of the valid =  1 0.6814572811126709\n",
      "Iteration 2 \t\t Training Loss: 0.06272197365760804 \t\t Validation Loss: 0.2830442413687706\n",
      "Validation Loss Decreased(1.134310--->1.132177)\n",
      "loss.item of the train =  2 0.3127725124359131\n",
      "loss.item of the train =  2 0.3123387396335602\n",
      "loss.item of the train =  2 0.3120485246181488\n",
      "loss.item of the train =  2 0.3116075098514557\n",
      "loss.item of the train =  2 0.3109985291957855\n",
      "loss.item of the valid =  2 0.25273597240448\n",
      "loss.item of the valid =  2 0.0859045758843422\n",
      "loss.item of the valid =  2 0.07224659621715546\n",
      "loss.item of the valid =  2 0.7045525908470154\n",
      "Iteration 3 \t\t Training Loss: 0.062199705839157106 \t\t Validation Loss: 0.27885993383824825\n",
      "Validation Loss Decreased(1.132177--->1.115440)\n",
      "loss.item of the train =  3 0.3101877272129059\n",
      "loss.item of the train =  3 0.30911341309547424\n",
      "loss.item of the train =  3 0.30766135454177856\n",
      "loss.item of the train =  3 0.3066081702709198\n",
      "loss.item of the train =  3 0.30592042207717896\n",
      "loss.item of the valid =  3 0.25718697905540466\n",
      "loss.item of the valid =  3 0.08572980761528015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item of the valid =  3 0.03640921786427498\n",
      "loss.item of the valid =  3 0.7240738272666931\n",
      "Iteration 4 \t\t Training Loss: 0.06118408441543579 \t\t Validation Loss: 0.2758499579504132\n",
      "Validation Loss Decreased(1.115440--->1.103400)\n",
      "loss.item of the train =  4 0.3072173595428467\n",
      "loss.item of the train =  4 0.30804747343063354\n",
      "loss.item of the train =  4 0.30842941999435425\n",
      "loss.item of the train =  4 0.30849331617355347\n",
      "loss.item of the train =  4 0.30829426646232605\n",
      "loss.item of the valid =  4 0.2532113492488861\n",
      "loss.item of the valid =  4 0.0833556205034256\n",
      "loss.item of the valid =  4 0.06887713074684143\n",
      "loss.item of the valid =  4 0.7063435912132263\n",
      "Iteration 5 \t\t Training Loss: 0.06165885329246521 \t\t Validation Loss: 0.27794692292809486\n",
      "loss.item of the train =  5 0.307842880487442\n",
      "loss.item of the train =  5 0.3071134090423584\n",
      "loss.item of the train =  5 0.3060375154018402\n",
      "loss.item of the train =  5 0.30447861552238464\n",
      "loss.item of the train =  5 0.3023642599582672\n",
      "loss.item of the valid =  5 0.2632416784763336\n",
      "loss.item of the valid =  5 0.08188708871603012\n",
      "loss.item of the valid =  5 0.033359069377183914\n",
      "loss.item of the valid =  5 0.7317538857460022\n",
      "Iteration 6 \t\t Training Loss: 0.06047285199165344 \t\t Validation Loss: 0.27756043057888746\n",
      "loss.item of the train =  6 0.3103232681751251\n",
      "loss.item of the train =  6 0.3053193986415863\n",
      "loss.item of the train =  6 0.3053349554538727\n",
      "loss.item of the train =  6 0.3083570599555969\n",
      "loss.item of the train =  6 0.3099680542945862\n",
      "loss.item of the valid =  6 0.24656683206558228\n",
      "loss.item of the valid =  6 0.07776166498661041\n",
      "loss.item of the valid =  6 0.11612452566623688\n",
      "loss.item of the valid =  6 0.6772094368934631\n",
      "Iteration 7 \t\t Training Loss: 0.061993610858917234 \t\t Validation Loss: 0.2794156149029732\n",
      "loss.item of the train =  7 0.31072545051574707\n",
      "loss.item of the train =  7 0.31087547540664673\n",
      "loss.item of the train =  7 0.3105260133743286\n",
      "loss.item of the train =  7 0.3097025156021118\n",
      "loss.item of the train =  7 0.30836135149002075\n",
      "loss.item of the valid =  7 0.2499573826789856\n",
      "loss.item of the valid =  7 0.07978168874979019\n",
      "loss.item of the valid =  7 0.08381220698356628\n",
      "loss.item of the valid =  7 0.6925131678581238\n",
      "Iteration 8 \t\t Training Loss: 0.06167227029800415 \t\t Validation Loss: 0.27651611156761646\n",
      "loss.item of the train =  8 0.30636587738990784\n",
      "loss.item of the train =  8 0.30405890941619873\n",
      "loss.item of the train =  8 0.30308815836906433\n",
      "loss.item of the train =  8 0.3021710515022278\n",
      "loss.item of the train =  8 0.3037397563457489\n",
      "loss.item of the valid =  8 0.25239673256874084\n",
      "loss.item of the valid =  8 0.0824788436293602\n",
      "loss.item of the valid =  8 0.06115350499749184\n",
      "loss.item of the valid =  8 0.7055254578590393\n",
      "Iteration 9 \t\t Training Loss: 0.06074795126914978 \t\t Validation Loss: 0.27538863476365805\n",
      "Validation Loss Decreased(1.103400--->1.101555)\n",
      "loss.item of the train =  9 0.3050970733165741\n",
      "loss.item of the train =  9 0.3057246804237366\n",
      "loss.item of the train =  9 0.30589616298675537\n",
      "loss.item of the train =  9 0.30573686957359314\n",
      "loss.item of the train =  9 0.30520859360694885\n",
      "loss.item of the valid =  9 0.2535415589809418\n",
      "loss.item of the valid =  9 0.08249575644731522\n",
      "loss.item of the valid =  9 0.05061759799718857\n",
      "loss.item of the valid =  9 0.7113415002822876\n",
      "Iteration 10 \t\t Training Loss: 0.06104171872138977 \t\t Validation Loss: 0.2744991034269333\n",
      "Validation Loss Decreased(1.101555--->1.097996)\n",
      "loss.item of the train =  10 0.3042724132537842\n",
      "loss.item of the train =  10 0.30281928181648254\n",
      "loss.item of the train =  10 0.3050271272659302\n",
      "loss.item of the train =  10 0.3028162121772766\n",
      "loss.item of the train =  10 0.3029894530773163\n",
      "loss.item of the valid =  10 0.2536284327507019\n",
      "loss.item of the valid =  10 0.08075305074453354\n",
      "loss.item of the valid =  10 0.0476267971098423\n",
      "loss.item of the valid =  10 0.7122585773468018\n",
      "Iteration 11 \t\t Training Loss: 0.06059789061546326 \t\t Validation Loss: 0.2735667144879699\n",
      "Validation Loss Decreased(1.097996--->1.094267)\n",
      "loss.item of the train =  11 0.30295124650001526\n",
      "loss.item of the train =  11 0.3027612268924713\n",
      "loss.item of the train =  11 0.3024206757545471\n",
      "loss.item of the train =  11 0.30429574847221375\n",
      "loss.item of the train =  11 0.3029140830039978\n",
      "loss.item of the valid =  11 0.25427526235580444\n",
      "loss.item of the valid =  11 0.08186512440443039\n",
      "loss.item of the valid =  11 0.04560866579413414\n",
      "loss.item of the valid =  11 0.7154194116592407\n",
      "Iteration 12 \t\t Training Loss: 0.06058281660079956 \t\t Validation Loss: 0.2742921160534024\n",
      "loss.item of the train =  12 0.30379098653793335\n",
      "loss.item of the train =  12 0.3040730059146881\n",
      "loss.item of the train =  12 0.3038775324821472\n",
      "loss.item of the train =  12 0.30324631929397583\n",
      "loss.item of the train =  12 0.3021758794784546\n",
      "loss.item of the valid =  12 0.2566763758659363\n",
      "loss.item of the valid =  12 0.08143298327922821\n",
      "loss.item of the valid =  12 0.03036513738334179\n",
      "loss.item of the valid =  12 0.726518988609314\n",
      "Iteration 13 \t\t Training Loss: 0.06043517589569092 \t\t Validation Loss: 0.27374837128445506\n",
      "loss.item of the train =  13 0.3043630123138428\n",
      "loss.item of the train =  13 0.3024786412715912\n",
      "loss.item of the train =  13 0.3031305968761444\n",
      "loss.item of the train =  13 0.30305585265159607\n",
      "loss.item of the train =  13 0.30267027020454407\n",
      "loss.item of the valid =  13 0.25568652153015137\n",
      "loss.item of the valid =  13 0.0811067670583725\n",
      "loss.item of the valid =  13 0.03015703521668911\n",
      "loss.item of the valid =  13 0.7228459715843201\n",
      "Iteration 14 \t\t Training Loss: 0.060534054040908815 \t\t Validation Loss: 0.27244907384738326\n",
      "Validation Loss Decreased(1.094267--->1.089796)\n",
      "loss.item of the train =  14 0.30239707231521606\n",
      "loss.item of the train =  14 0.30318382382392883\n",
      "loss.item of the train =  14 0.3039526343345642\n",
      "loss.item of the train =  14 0.3040791451931\n",
      "loss.item of the train =  14 0.30367952585220337\n",
      "loss.item of the valid =  14 0.2549160122871399\n",
      "loss.item of the valid =  14 0.08150476217269897\n",
      "loss.item of the valid =  14 0.03892750293016434\n",
      "loss.item of the valid =  14 0.7191334962844849\n",
      "Iteration 15 \t\t Training Loss: 0.060735905170440675 \t\t Validation Loss: 0.273620443418622\n",
      "loss.item of the train =  15 0.302966833114624\n",
      "loss.item of the train =  15 0.3028469681739807\n",
      "loss.item of the train =  15 0.3025411069393158\n",
      "loss.item of the train =  15 0.30286020040512085\n",
      "loss.item of the train =  15 0.30258849263191223\n",
      "loss.item of the valid =  15 0.25514134764671326\n",
      "loss.item of the valid =  15 0.08103416115045547\n",
      "loss.item of the valid =  15 0.034895095974206924\n",
      "loss.item of the valid =  15 0.7206183671951294\n",
      "Iteration 16 \t\t Training Loss: 0.060517698526382446 \t\t Validation Loss: 0.27292224299162626\n",
      "loss.item of the train =  16 0.3023824989795685\n",
      "loss.item of the train =  16 0.3023858964443207\n",
      "loss.item of the train =  16 0.3036792576313019\n",
      "loss.item of the train =  16 0.30464068055152893\n",
      "loss.item of the train =  16 0.3050796687602997\n",
      "loss.item of the valid =  16 0.2528642416000366\n",
      "loss.item of the valid =  16 0.08146780729293823\n",
      "loss.item of the valid =  16 0.05850823223590851\n",
      "loss.item of the valid =  16 0.7101010084152222\n",
      "Iteration 17 \t\t Training Loss: 0.061015933752059937 \t\t Validation Loss: 0.2757353223860264\n",
      "loss.item of the train =  17 0.3051213324069977\n",
      "loss.item of the train =  17 0.30486610531806946\n",
      "loss.item of the train =  17 0.3042047917842865\n",
      "loss.item of the train =  17 0.30308061838150024\n",
      "loss.item of the train =  17 0.3031426966190338\n",
      "loss.item of the valid =  17 0.25467991828918457\n",
      "loss.item of the valid =  17 0.0806533470749855\n",
      "loss.item of the valid =  17 0.037488266825675964\n",
      "loss.item of the valid =  17 0.7190979719161987\n",
      "Iteration 18 \t\t Training Loss: 0.06062853932380676 \t\t Validation Loss: 0.2729798760265112\n",
      "loss.item of the train =  18 0.3027745485305786\n",
      "loss.item of the train =  18 0.3027835488319397\n",
      "loss.item of the train =  18 0.3027496635913849\n",
      "loss.item of the train =  18 0.30253130197525024\n",
      "loss.item of the train =  18 0.30238160490989685\n",
      "loss.item of the valid =  18 0.25744497776031494\n",
      "loss.item of the valid =  18 0.08217686414718628\n",
      "loss.item of the valid =  18 0.033306390047073364\n",
      "loss.item of the valid =  18 0.7303609251976013\n",
      "Iteration 19 \t\t Training Loss: 0.06047632098197937 \t\t Validation Loss: 0.275822289288044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item of the train =  19 0.3042498528957367\n",
      "loss.item of the train =  19 0.30344799160957336\n",
      "loss.item of the train =  19 0.30432838201522827\n",
      "loss.item of the train =  19 0.3046741187572479\n",
      "loss.item of the train =  19 0.3045992851257324\n",
      "loss.item of the valid =  19 0.25428563356399536\n",
      "loss.item of the valid =  19 0.08179108798503876\n",
      "loss.item of the valid =  19 0.04483089968562126\n",
      "loss.item of the valid =  19 0.7169824242591858\n",
      "Iteration 20 \t\t Training Loss: 0.06091985702514648 \t\t Validation Loss: 0.2744725113734603\n",
      "loss.item of the train =  20 0.30413657426834106\n",
      "loss.item of the train =  20 0.3032567799091339\n",
      "loss.item of the train =  20 0.30262720584869385\n",
      "loss.item of the train =  20 0.3058396577835083\n",
      "loss.item of the train =  20 0.3030627369880676\n",
      "loss.item of the valid =  20 0.2535097599029541\n",
      "loss.item of the valid =  20 0.0803881585597992\n",
      "loss.item of the valid =  20 0.0466737300157547\n",
      "loss.item of the valid =  20 0.7147407531738281\n",
      "Iteration 21 \t\t Training Loss: 0.06061254739761353 \t\t Validation Loss: 0.27382810041308403\n",
      "loss.item of the train =  21 0.30311065912246704\n",
      "loss.item of the train =  21 0.3035070300102234\n",
      "loss.item of the train =  21 0.30329185724258423\n",
      "loss.item of the train =  21 0.3027905523777008\n",
      "loss.item of the train =  21 0.3026813864707947\n",
      "loss.item of the valid =  21 0.25731754302978516\n",
      "loss.item of the valid =  21 0.08210825175046921\n",
      "loss.item of the valid =  21 0.03377602994441986\n",
      "loss.item of the valid =  21 0.730687141418457\n",
      "Iteration 22 \t\t Training Loss: 0.06053627729415893 \t\t Validation Loss: 0.2759722415357828\n",
      "loss.item of the train =  22 0.3044138550758362\n",
      "loss.item of the train =  22 0.30348125100135803\n",
      "loss.item of the train =  22 0.30439305305480957\n",
      "loss.item of the train =  22 0.30476877093315125\n",
      "loss.item of the train =  22 0.3047259449958801\n",
      "loss.item of the valid =  22 0.25455352663993835\n",
      "loss.item of the valid =  22 0.08208771795034409\n",
      "loss.item of the valid =  22 0.042133234441280365\n",
      "loss.item of the valid =  22 0.7187202572822571\n",
      "Iteration 23 \t\t Training Loss: 0.060945188999176024 \t\t Validation Loss: 0.27437368407845497\n",
      "loss.item of the train =  23 0.30430036783218384\n",
      "loss.item of the train =  23 0.3034661114215851\n",
      "loss.item of the train =  23 0.30276355147361755\n",
      "loss.item of the train =  23 0.3061560094356537\n",
      "loss.item of the train =  23 0.3029596209526062\n",
      "loss.item of the valid =  23 0.2537720203399658\n",
      "loss.item of the valid =  23 0.08081087470054626\n",
      "loss.item of the valid =  23 0.044009797275066376\n",
      "loss.item of the valid =  23 0.716701090335846\n",
      "Iteration 24 \t\t Training Loss: 0.06059192419052124 \t\t Validation Loss: 0.2738234456628561\n",
      "loss.item of the train =  24 0.3031131327152252\n",
      "loss.item of the train =  24 0.3036205470561981\n",
      "loss.item of the train =  24 0.3035297095775604\n",
      "loss.item of the train =  24 0.30290594696998596\n",
      "loss.item of the train =  24 0.3031439185142517\n",
      "loss.item of the valid =  24 0.25603654980659485\n",
      "loss.item of the valid =  24 0.08100512623786926\n",
      "loss.item of the valid =  24 0.03202371671795845\n",
      "loss.item of the valid =  24 0.7277886867523193\n",
      "Iteration 25 \t\t Training Loss: 0.06062878370285034 \t\t Validation Loss: 0.2742135198786855\n",
      "loss.item of the train =  25 0.30487218499183655\n",
      "loss.item of the train =  25 0.30306926369667053\n",
      "loss.item of the train =  25 0.3035423159599304\n",
      "loss.item of the train =  25 0.3040933907032013\n",
      "loss.item of the train =  25 0.30412212014198303\n",
      "loss.item of the valid =  25 0.25340816378593445\n",
      "loss.item of the valid =  25 0.08100667595863342\n",
      "loss.item of the valid =  25 0.04804464429616928\n",
      "loss.item of the valid =  25 0.7150235772132874\n",
      "Iteration 26 \t\t Training Loss: 0.060824424028396606 \t\t Validation Loss: 0.2743707653135061\n",
      "loss.item of the train =  26 0.3037971556186676\n",
      "loss.item of the train =  26 0.303040087223053\n",
      "loss.item of the train =  26 0.30322641134262085\n",
      "loss.item of the train =  26 0.3056643307209015\n",
      "loss.item of the train =  26 0.30337774753570557\n",
      "loss.item of the valid =  26 0.2535654306411743\n",
      "loss.item of the valid =  26 0.08056091517210007\n",
      "loss.item of the valid =  26 0.04438003897666931\n",
      "loss.item of the valid =  26 0.7163835763931274\n",
      "Iteration 27 \t\t Training Loss: 0.060675549507141116 \t\t Validation Loss: 0.2737224902957678\n",
      "loss.item of the train =  27 0.30310139060020447\n",
      "loss.item of the train =  27 0.3040214776992798\n",
      "loss.item of the train =  27 0.30453965067863464\n",
      "loss.item of the train =  27 0.3046197295188904\n",
      "loss.item of the train =  27 0.3043117821216583\n",
      "loss.item of the valid =  27 0.2545625865459442\n",
      "loss.item of the valid =  27 0.08167330175638199\n",
      "loss.item of the valid =  27 0.038909077644348145\n",
      "loss.item of the valid =  27 0.7200114727020264\n",
      "Iteration 28 \t\t Training Loss: 0.060862356424331666 \t\t Validation Loss: 0.2737891096621752\n",
      "loss.item of the train =  28 0.3036043047904968\n",
      "loss.item of the train =  28 0.3029440939426422\n",
      "loss.item of the train =  28 0.30519670248031616\n",
      "loss.item of the train =  28 0.3029864728450775\n",
      "loss.item of the train =  28 0.30359551310539246\n",
      "loss.item of the valid =  28 0.25339800119400024\n",
      "loss.item of the valid =  28 0.08116240799427032\n",
      "loss.item of the valid =  28 0.04819400981068611\n",
      "loss.item of the valid =  28 0.7151681184768677\n",
      "Iteration 29 \t\t Training Loss: 0.06071910262107849 \t\t Validation Loss: 0.2744806343689561\n",
      "loss.item of the train =  29 0.3040411174297333\n",
      "loss.item of the train =  29 0.3040205240249634\n",
      "loss.item of the train =  29 0.30367061495780945\n",
      "loss.item of the train =  29 0.3033633828163147\n",
      "loss.item of the train =  29 0.3033316135406494\n",
      "loss.item of the valid =  29 0.25550001859664917\n",
      "loss.item of the valid =  29 0.08112102001905441\n",
      "loss.item of the valid =  29 0.030732890591025352\n",
      "loss.item of the valid =  29 0.7257717251777649\n",
      "Iteration 30 \t\t Training Loss: 0.06066632270812988 \t\t Validation Loss: 0.27328141359612346\n",
      "loss.item of the train =  30 0.3033219575881958\n",
      "loss.item of the train =  30 0.3048827648162842\n",
      "loss.item of the train =  30 0.30334287881851196\n",
      "loss.item of the train =  30 0.3042721152305603\n",
      "loss.item of the train =  30 0.3046596646308899\n",
      "loss.item of the valid =  30 0.2535843849182129\n",
      "loss.item of the valid =  30 0.08167937397956848\n",
      "loss.item of the valid =  30 0.0481448695063591\n",
      "loss.item of the valid =  30 0.7156572937965393\n",
      "Iteration 31 \t\t Training Loss: 0.060931932926177976 \t\t Validation Loss: 0.27476648055016994\n",
      "loss.item of the train =  31 0.30462774634361267\n",
      "loss.item of the train =  31 0.3042169213294983\n",
      "loss.item of the train =  31 0.30340805649757385\n",
      "loss.item of the train =  31 0.30344897508621216\n",
      "loss.item of the train =  31 0.3044471740722656\n",
      "loss.item of the valid =  31 0.25361940264701843\n",
      "loss.item of the valid =  31 0.08004610240459442\n",
      "loss.item of the valid =  31 0.039802223443984985\n",
      "loss.item of the valid =  31 0.7183510065078735\n",
      "Iteration 32 \t\t Training Loss: 0.06088943481445312 \t\t Validation Loss: 0.27295468375086784\n",
      "loss.item of the train =  32 0.3038952946662903\n",
      "loss.item of the train =  32 0.3037203550338745\n",
      "loss.item of the train =  32 0.30422118306159973\n",
      "loss.item of the train =  32 0.30460667610168457\n",
      "loss.item of the train =  32 0.3046911656856537\n",
      "loss.item of the valid =  32 0.25334832072257996\n",
      "loss.item of the valid =  32 0.08139114081859589\n",
      "loss.item of the valid =  32 0.048402339220047\n",
      "loss.item of the valid =  32 0.7153344750404358\n",
      "Iteration 33 \t\t Training Loss: 0.06093823313713074 \t\t Validation Loss: 0.27461906895041466\n",
      "loss.item of the train =  33 0.3043976128101349\n",
      "loss.item of the train =  33 0.3037155866622925\n",
      "loss.item of the train =  33 0.30331069231033325\n",
      "loss.item of the train =  33 0.3046131432056427\n",
      "loss.item of the train =  33 0.3033129572868347\n",
      "loss.item of the valid =  33 0.2539218068122864\n",
      "loss.item of the valid =  33 0.08138854801654816\n",
      "loss.item of the valid =  33 0.04212348163127899\n",
      "loss.item of the valid =  33 0.7183263897895813\n",
      "Iteration 34 \t\t Training Loss: 0.060662591457366945 \t\t Validation Loss: 0.2739400565624237\n",
      "loss.item of the train =  34 0.3037673532962799\n",
      "loss.item of the train =  34 0.30422279238700867\n",
      "loss.item of the train =  34 0.3042234480381012\n",
      "loss.item of the train =  34 0.30382072925567627\n",
      "loss.item of the train =  34 0.30353283882141113\n",
      "loss.item of the valid =  34 0.2537800073623657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item of the valid =  34 0.08042748272418976\n",
      "loss.item of the valid =  34 0.038596805185079575\n",
      "loss.item of the valid =  34 0.7193196415901184\n",
      "Iteration 35 \t\t Training Loss: 0.060706567764282224 \t\t Validation Loss: 0.27303098421543837\n",
      "loss.item of the train =  35 0.30373167991638184\n",
      "loss.item of the train =  35 0.3037812113761902\n",
      "loss.item of the train =  35 0.3036852777004242\n",
      "loss.item of the train =  35 0.30345022678375244\n",
      "loss.item of the train =  35 0.30323126912117004\n",
      "loss.item of the valid =  35 0.25506269931793213\n",
      "loss.item of the valid =  35 0.0826963484287262\n",
      "loss.item of the valid =  35 0.03648655489087105\n",
      "loss.item of the valid =  35 0.7220323085784912\n",
      "Iteration 36 \t\t Training Loss: 0.06064625382423401 \t\t Validation Loss: 0.27406947780400515\n",
      "loss.item of the train =  36 0.30455607175827026\n",
      "loss.item of the train =  36 0.3057042956352234\n",
      "loss.item of the train =  36 0.3063453137874603\n",
      "loss.item of the train =  36 0.3066280484199524\n",
      "loss.item of the train =  36 0.3066243827342987\n",
      "loss.item of the valid =  36 0.25326424837112427\n",
      "loss.item of the valid =  36 0.08266759663820267\n",
      "loss.item of the valid =  36 0.05441642552614212\n",
      "loss.item of the valid =  36 0.7134594321250916\n",
      "Iteration 37 \t\t Training Loss: 0.06132487654685974 \t\t Validation Loss: 0.27595192566514015\n",
      "loss.item of the train =  37 0.306363046169281\n",
      "loss.item of the train =  37 0.3058401942253113\n",
      "loss.item of the train =  37 0.3050209581851959\n",
      "loss.item of the train =  37 0.3038289546966553\n",
      "loss.item of the train =  37 0.30386587977409363\n",
      "loss.item of the valid =  37 0.25843697786331177\n",
      "loss.item of the valid =  37 0.08149490505456924\n",
      "loss.item of the valid =  37 0.038433097302913666\n",
      "loss.item of the valid =  37 0.7350625991821289\n",
      "Iteration 38 \t\t Training Loss: 0.06077317595481872 \t\t Validation Loss: 0.2783568948507309\n",
      "loss.item of the train =  38 0.30815020203590393\n",
      "loss.item of the train =  38 0.3048887848854065\n",
      "loss.item of the train =  38 0.303901344537735\n",
      "loss.item of the train =  38 0.3054450750350952\n",
      "loss.item of the train =  38 0.30664849281311035\n",
      "loss.item of the valid =  38 0.2493707239627838\n",
      "loss.item of the valid =  38 0.08040790259838104\n",
      "loss.item of the valid =  38 0.08186553418636322\n",
      "loss.item of the valid =  38 0.6998594403266907\n",
      "Iteration 39 \t\t Training Loss: 0.06132969856262207 \t\t Validation Loss: 0.2778759002685547\n",
      "loss.item of the train =  39 0.30736759305000305\n",
      "loss.item of the train =  39 0.30775365233421326\n",
      "loss.item of the train =  39 0.30788546800613403\n",
      "loss.item of the train =  39 0.30780211091041565\n",
      "loss.item of the train =  39 0.3075186014175415\n",
      "loss.item of the valid =  39 0.2501131296157837\n",
      "loss.item of the valid =  39 0.08093865215778351\n",
      "loss.item of the valid =  39 0.07671286165714264\n",
      "loss.item of the valid =  39 0.7023429870605469\n",
      "Iteration 40 \t\t Training Loss: 0.0615037202835083 \t\t Validation Loss: 0.2775269076228142\n",
      "loss.item of the train =  40 0.30702728033065796\n",
      "loss.item of the train =  40 0.30646491050720215\n",
      "loss.item of the train =  40 0.3056522309780121\n",
      "loss.item of the train =  40 0.3045197129249573\n",
      "loss.item of the train =  40 0.30403006076812744\n",
      "loss.item of the valid =  40 0.2554771304130554\n",
      "loss.item of the valid =  40 0.08117834478616714\n",
      "loss.item of the valid =  40 0.033929042518138885\n",
      "loss.item of the valid =  40 0.7283268570899963\n",
      "Iteration 41 \t\t Training Loss: 0.06080601215362549 \t\t Validation Loss: 0.27472784370183945\n",
      "loss.item of the train =  41 0.30496928095817566\n",
      "loss.item of the train =  41 0.3042394518852234\n",
      "loss.item of the train =  41 0.3038882911205292\n",
      "loss.item of the train =  41 0.30339086055755615\n",
      "loss.item of the train =  41 0.3040924668312073\n",
      "loss.item of the valid =  41 0.25665831565856934\n",
      "loss.item of the valid =  41 0.08375917375087738\n",
      "loss.item of the valid =  41 0.03371414542198181\n",
      "loss.item of the valid =  41 0.7289064526557922\n",
      "Iteration 42 \t\t Training Loss: 0.060818493366241455 \t\t Validation Loss: 0.2757595218718052\n",
      "loss.item of the train =  42 0.3043784499168396\n",
      "loss.item of the train =  42 0.3042129576206207\n",
      "loss.item of the train =  42 0.3060876131057739\n",
      "loss.item of the train =  42 0.30443814396858215\n",
      "loss.item of the train =  42 0.30534058809280396\n",
      "loss.item of the valid =  42 0.25369444489479065\n",
      "loss.item of the valid =  42 0.08288998156785965\n",
      "loss.item of the valid =  42 0.04877505078911781\n",
      "loss.item of the valid =  42 0.7159178256988525\n",
      "Iteration 43 \t\t Training Loss: 0.06106811761856079 \t\t Validation Loss: 0.27531932573765516\n",
      "loss.item of the train =  43 0.3059993088245392\n",
      "loss.item of the train =  43 0.30625489354133606\n",
      "loss.item of the train =  43 0.30619800090789795\n",
      "loss.item of the train =  43 0.30586546659469604\n",
      "loss.item of the train =  43 0.3055174946784973\n",
      "loss.item of the valid =  43 0.24962233006954193\n",
      "loss.item of the valid =  43 0.07906623184680939\n",
      "loss.item of the valid =  43 0.06775537878274918\n",
      "loss.item of the valid =  43 0.7048516869544983\n",
      "Iteration 44 \t\t Training Loss: 0.06110349893569946 \t\t Validation Loss: 0.2753239069133997\n",
      "loss.item of the train =  44 0.3055790364742279\n",
      "loss.item of the train =  44 0.30596163868904114\n",
      "loss.item of the train =  44 0.3057229220867157\n",
      "loss.item of the train =  44 0.30498364567756653\n",
      "loss.item of the train =  44 0.3044396638870239\n",
      "loss.item of the valid =  44 0.25408682227134705\n",
      "loss.item of the valid =  44 0.08248671889305115\n",
      "loss.item of the valid =  44 0.038981810212135315\n",
      "loss.item of the valid =  44 0.7196004390716553\n",
      "Iteration 45 \t\t Training Loss: 0.060887932777404785 \t\t Validation Loss: 0.2737889476120472\n",
      "loss.item of the train =  45 0.3045274317264557\n",
      "loss.item of the train =  45 0.3045511543750763\n",
      "loss.item of the train =  45 0.30414777994155884\n",
      "loss.item of the train =  45 0.30718472599983215\n",
      "loss.item of the train =  45 0.30657315254211426\n",
      "loss.item of the valid =  45 0.25636035203933716\n",
      "loss.item of the valid =  45 0.08437296748161316\n",
      "loss.item of the valid =  45 0.03431122004985809\n",
      "loss.item of the valid =  45 0.7273625731468201\n",
      "Iteration 46 \t\t Training Loss: 0.061314630508422854 \t\t Validation Loss: 0.2756017781794071\n",
      "loss.item of the train =  46 0.30482128262519836\n",
      "loss.item of the train =  46 0.305454820394516\n",
      "loss.item of the train =  46 0.30566850304603577\n",
      "loss.item of the train =  46 0.30554479360580444\n",
      "loss.item of the train =  46 0.305107980966568\n",
      "loss.item of the valid =  46 0.25261884927749634\n",
      "loss.item of the valid =  46 0.08200091868638992\n",
      "loss.item of the valid =  46 0.04433400556445122\n",
      "loss.item of the valid =  46 0.7151163816452026\n",
      "Iteration 47 \t\t Training Loss: 0.0610215961933136 \t\t Validation Loss: 0.27351753879338503\n",
      "loss.item of the train =  47 0.30528122186660767\n",
      "loss.item of the train =  47 0.3056910037994385\n",
      "loss.item of the train =  47 0.30568748712539673\n",
      "loss.item of the train =  47 0.30530327558517456\n",
      "loss.item of the train =  47 0.30460458993911743\n",
      "loss.item of the valid =  47 0.25525861978530884\n",
      "loss.item of the valid =  47 0.08415542542934418\n",
      "loss.item of the valid =  47 0.03264317661523819\n",
      "loss.item of the valid =  47 0.7231131792068481\n",
      "Iteration 48 \t\t Training Loss: 0.06092091798782349 \t\t Validation Loss: 0.27379260025918484\n",
      "loss.item of the train =  48 0.3049047887325287\n",
      "loss.item of the train =  48 0.30502554774284363\n",
      "loss.item of the train =  48 0.3048498332500458\n",
      "loss.item of the train =  48 0.3053790330886841\n",
      "loss.item of the train =  48 0.3055956959724426\n",
      "loss.item of the valid =  48 0.2569800019264221\n",
      "loss.item of the valid =  48 0.08560286462306976\n",
      "loss.item of the valid =  48 0.0357045903801918\n",
      "loss.item of the valid =  48 0.7283717393875122\n",
      "Iteration 49 \t\t Training Loss: 0.061119139194488525 \t\t Validation Loss: 0.276664799079299\n",
      "loss.item of the train =  49 0.3054763376712799\n",
      "loss.item of the train =  49 0.30503761768341064\n",
      "loss.item of the train =  49 0.30696627497673035\n",
      "loss.item of the train =  49 0.3054986596107483\n",
      "loss.item of the train =  49 0.30563783645629883\n",
      "loss.item of the valid =  49 0.25335681438446045\n",
      "loss.item of the valid =  49 0.08428499102592468\n",
      "loss.item of the valid =  49 0.04678048938512802\n",
      "loss.item of the valid =  49 0.7143511772155762\n",
      "Iteration 50 \t\t Training Loss: 0.06112756729125977 \t\t Validation Loss: 0.27469336800277233\n",
      "loss.item of the train =  50 0.3062118589878082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item of the train =  50 0.30641722679138184\n",
      "loss.item of the train =  50 0.3063296973705292\n",
      "loss.item of the train =  50 0.30597934126853943\n",
      "loss.item of the train =  50 0.307116836309433\n",
      "loss.item of the valid =  50 0.2493792176246643\n",
      "loss.item of the valid =  50 0.08184631913900375\n",
      "loss.item of the valid =  50 0.06284280866384506\n",
      "loss.item of the valid =  50 0.7034229040145874\n",
      "Iteration 51 \t\t Training Loss: 0.061423367261886595 \t\t Validation Loss: 0.27437281236052513\n",
      "loss.item of the train =  51 0.3075235188007355\n",
      "loss.item of the train =  51 0.30705076456069946\n",
      "loss.item of the train =  51 0.3059374690055847\n",
      "loss.item of the train =  51 0.3059825897216797\n",
      "loss.item of the train =  51 0.306126207113266\n",
      "loss.item of the valid =  51 0.25440725684165955\n",
      "loss.item of the valid =  51 0.08520917594432831\n",
      "loss.item of the valid =  51 0.03876996785402298\n",
      "loss.item of the valid =  51 0.7180854678153992\n",
      "Iteration 52 \t\t Training Loss: 0.0612252414226532 \t\t Validation Loss: 0.2741179671138525\n",
      "loss.item of the train =  52 0.30595993995666504\n",
      "loss.item of the train =  52 0.30549198389053345\n",
      "loss.item of the train =  52 0.3058841824531555\n",
      "loss.item of the train =  52 0.3055606186389923\n",
      "loss.item of the train =  52 0.3059123456478119\n",
      "loss.item of the valid =  52 0.25463223457336426\n",
      "loss.item of the valid =  52 0.08575919270515442\n",
      "loss.item of the valid =  52 0.03995327278971672\n",
      "loss.item of the valid =  52 0.7180095314979553\n",
      "Iteration 53 \t\t Training Loss: 0.06118246912956238 \t\t Validation Loss: 0.2745885578915477\n",
      "loss.item of the train =  53 0.3064787685871124\n",
      "loss.item of the train =  53 0.3067166805267334\n",
      "loss.item of the train =  53 0.30669105052948\n",
      "loss.item of the train =  53 0.30642664432525635\n",
      "loss.item of the train =  53 0.3059196174144745\n",
      "loss.item of the valid =  53 0.25369545817375183\n",
      "loss.item of the valid =  53 0.08544175326824188\n",
      "loss.item of the valid =  53 0.03693310543894768\n",
      "loss.item of the valid =  53 0.7164741158485413\n",
      "Iteration 54 \t\t Training Loss: 0.0611839234828949 \t\t Validation Loss: 0.27313610818237066\n",
      "loss.item of the train =  54 0.30513784289360046\n",
      "loss.item of the train =  54 0.3058460056781769\n",
      "loss.item of the train =  54 0.30873003602027893\n",
      "loss.item of the train =  54 0.30583256483078003\n",
      "loss.item of the train =  54 0.3051376938819885\n",
      "loss.item of the valid =  54 0.2533155083656311\n",
      "loss.item of the valid =  54 0.08553598821163177\n",
      "loss.item of the valid =  54 0.041869841516017914\n",
      "loss.item of the valid =  54 0.7144054770469666\n",
      "Iteration 55 \t\t Training Loss: 0.0610275387763977 \t\t Validation Loss: 0.27378170378506184\n",
      "loss.item of the train =  55 0.3056667745113373\n",
      "loss.item of the train =  55 0.30583655834198\n",
      "loss.item of the train =  55 0.30570581555366516\n",
      "loss.item of the train =  55 0.30528780817985535\n",
      "loss.item of the train =  55 0.30491700768470764\n",
      "loss.item of the valid =  55 0.2555975615978241\n",
      "loss.item of the valid =  55 0.08631793409585953\n",
      "loss.item of the valid =  55 0.03973272442817688\n",
      "loss.item of the valid =  55 0.7244372367858887\n",
      "Iteration 56 \t\t Training Loss: 0.060983401536941526 \t\t Validation Loss: 0.2765213642269373\n",
      "loss.item of the train =  56 0.3062182664871216\n",
      "loss.item of the train =  56 0.30516311526298523\n",
      "loss.item of the train =  56 0.305738627910614\n",
      "loss.item of the train =  56 0.3059505820274353\n",
      "loss.item of the train =  56 0.3058644235134125\n",
      "loss.item of the valid =  56 0.25484955310821533\n",
      "loss.item of the valid =  56 0.08626072108745575\n",
      "loss.item of the valid =  56 0.03431888297200203\n",
      "loss.item of the valid =  56 0.7198237776756287\n",
      "Iteration 57 \t\t Training Loss: 0.06117288470268249 \t\t Validation Loss: 0.27381323371082544\n",
      "loss.item of the train =  57 0.305499404668808\n",
      "loss.item of the train =  57 0.30483612418174744\n",
      "loss.item of the train =  57 0.30760657787323\n",
      "loss.item of the train =  57 0.3048667907714844\n",
      "loss.item of the train =  57 0.30584001541137695\n",
      "loss.item of the valid =  57 0.2519667148590088\n",
      "loss.item of the valid =  57 0.08540550619363785\n",
      "loss.item of the valid =  57 0.05446229502558708\n",
      "loss.item of the valid =  57 0.7085890769958496\n",
      "Iteration 58 \t\t Training Loss: 0.06116800308227539 \t\t Validation Loss: 0.27510589826852083\n",
      "loss.item of the train =  58 0.3066418468952179\n",
      "loss.item of the train =  58 0.30719152092933655\n",
      "loss.item of the train =  58 0.30754977464675903\n",
      "loss.item of the train =  58 0.3076290786266327\n",
      "loss.item of the train =  58 0.3074648678302765\n",
      "loss.item of the valid =  58 0.25043365359306335\n",
      "loss.item of the valid =  58 0.08488442003726959\n",
      "loss.item of the valid =  58 0.06270407140254974\n",
      "loss.item of the valid =  58 0.7037281394004822\n",
      "Iteration 59 \t\t Training Loss: 0.0614929735660553 \t\t Validation Loss: 0.2754375711083412\n",
      "loss.item of the train =  59 0.3070627450942993\n",
      "loss.item of the train =  59 0.30640268325805664\n",
      "loss.item of the train =  59 0.30572134256362915\n",
      "loss.item of the train =  59 0.3052143156528473\n",
      "loss.item of the train =  59 0.30503353476524353\n",
      "loss.item of the valid =  59 0.25568336248397827\n",
      "loss.item of the valid =  59 0.08667522668838501\n",
      "loss.item of the valid =  59 0.037312693893909454\n",
      "loss.item of the valid =  59 0.7233591079711914\n",
      "Iteration 60 \t\t Training Loss: 0.0610067069530487 \t\t Validation Loss: 0.27575759775936604\n",
      "loss.item of the train =  60 0.30503594875335693\n",
      "loss.item of the train =  60 0.30519750714302063\n",
      "loss.item of the train =  60 0.3054306209087372\n",
      "loss.item of the train =  60 0.3056955635547638\n",
      "loss.item of the train =  60 0.30599460005760193\n",
      "loss.item of the valid =  60 0.25531649589538574\n",
      "loss.item of the valid =  60 0.08668170869350433\n",
      "loss.item of the valid =  60 0.03380550444126129\n",
      "loss.item of the valid =  60 0.7207680344581604\n",
      "Iteration 61 \t\t Training Loss: 0.061198920011520386 \t\t Validation Loss: 0.27414293587207794\n",
      "loss.item of the train =  61 0.3059919476509094\n",
      "loss.item of the train =  61 0.30571824312210083\n",
      "loss.item of the train =  61 0.30516567826271057\n",
      "loss.item of the train =  61 0.30653610825538635\n",
      "loss.item of the train =  61 0.3054082989692688\n",
      "loss.item of the valid =  61 0.25350719690322876\n",
      "loss.item of the valid =  61 0.08629941195249557\n",
      "loss.item of the valid =  61 0.03871699050068855\n",
      "loss.item of the valid =  61 0.7151037454605103\n",
      "Iteration 62 \t\t Training Loss: 0.06108165979385376 \t\t Validation Loss: 0.2734068362042308\n",
      "loss.item of the train =  62 0.3053869605064392\n",
      "loss.item of the train =  62 0.30601170659065247\n",
      "loss.item of the train =  62 0.3064890503883362\n",
      "loss.item of the train =  62 0.3066976070404053\n",
      "loss.item of the train =  62 0.30667397379875183\n",
      "loss.item of the valid =  62 0.25095945596694946\n",
      "loss.item of the valid =  62 0.08561529219150543\n",
      "loss.item of the valid =  62 0.05528634041547775\n",
      "loss.item of the valid =  62 0.7060692310333252\n",
      "Iteration 63 \t\t Training Loss: 0.061334794759750365 \t\t Validation Loss: 0.27448257990181446\n",
      "loss.item of the train =  63 0.3064363896846771\n",
      "loss.item of the train =  63 0.3058953881263733\n",
      "loss.item of the train =  63 0.30537861585617065\n",
      "loss.item of the train =  63 0.30468958616256714\n",
      "loss.item of the train =  63 0.30629533529281616\n",
      "loss.item of the valid =  63 0.2565311789512634\n",
      "loss.item of the valid =  63 0.08734508603811264\n",
      "loss.item of the valid =  63 0.03856677934527397\n",
      "loss.item of the valid =  63 0.7261789441108704\n",
      "Iteration 64 \t\t Training Loss: 0.06125906705856323 \t\t Validation Loss: 0.2771554971113801\n",
      "loss.item of the train =  64 0.30520230531692505\n",
      "loss.item of the train =  64 0.3065369129180908\n",
      "loss.item of the train =  64 0.30737507343292236\n",
      "loss.item of the train =  64 0.3078806698322296\n",
      "loss.item of the train =  64 0.3081517815589905\n",
      "loss.item of the valid =  64 0.2536456286907196\n",
      "loss.item of the valid =  64 0.0863165482878685\n",
      "loss.item of the valid =  64 0.05511088669300079\n",
      "loss.item of the valid =  64 0.712302029132843\n",
      "Iteration 65 \t\t Training Loss: 0.0616303563117981 \t\t Validation Loss: 0.276843773201108\n",
      "loss.item of the train =  65 0.30824244022369385\n",
      "loss.item of the train =  65 0.30818235874176025\n",
      "loss.item of the train =  65 0.3079827129840851\n",
      "loss.item of the train =  65 0.3076411485671997\n",
      "loss.item of the train =  65 0.30714213848114014\n",
      "loss.item of the valid =  65 0.25582003593444824\n",
      "loss.item of the valid =  65 0.08726632595062256\n",
      "loss.item of the valid =  65 0.03338067978620529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item of the valid =  65 0.7220213413238525\n",
      "Iteration 66 \t\t Training Loss: 0.06142842769622803 \t\t Validation Loss: 0.27462209574878216\n",
      "loss.item of the train =  66 0.3064541518688202\n",
      "loss.item of the train =  66 0.3055223226547241\n",
      "loss.item of the train =  66 0.30859342217445374\n",
      "loss.item of the train =  66 0.3086759150028229\n",
      "loss.item of the train =  66 0.3056539297103882\n",
      "loss.item of the valid =  66 0.2534237504005432\n",
      "loss.item of the valid =  66 0.08724592626094818\n",
      "loss.item of the valid =  66 0.044152796268463135\n",
      "loss.item of the valid =  66 0.713409423828125\n",
      "Iteration 67 \t\t Training Loss: 0.06113078594207764 \t\t Validation Loss: 0.2745579741895199\n",
      "loss.item of the train =  67 0.30628713965415955\n",
      "loss.item of the train =  67 0.30728888511657715\n",
      "loss.item of the train =  67 0.308149516582489\n",
      "loss.item of the train =  67 0.30866482853889465\n",
      "loss.item of the train =  67 0.30892282724380493\n",
      "loss.item of the valid =  67 0.2487196922302246\n",
      "loss.item of the valid =  67 0.08615608513355255\n",
      "loss.item of the valid =  67 0.07831902801990509\n",
      "loss.item of the valid =  67 0.6965262293815613\n",
      "Iteration 68 \t\t Training Loss: 0.061784565448760986 \t\t Validation Loss: 0.2774302586913109\n",
      "loss.item of the train =  68 0.3089710474014282\n",
      "loss.item of the train =  68 0.30883321166038513\n",
      "loss.item of the train =  68 0.308515340089798\n",
      "loss.item of the train =  68 0.30800771713256836\n",
      "loss.item of the train =  68 0.3072822093963623\n",
      "loss.item of the valid =  68 0.25163692235946655\n",
      "loss.item of the valid =  68 0.08728493750095367\n",
      "loss.item of the valid =  68 0.05013849213719368\n",
      "loss.item of the valid =  68 0.7080183029174805\n",
      "Iteration 69 \t\t Training Loss: 0.06145644187927246 \t\t Validation Loss: 0.2742696637287736\n",
      "loss.item of the train =  69 0.30628788471221924\n",
      "loss.item of the train =  69 0.3051943778991699\n",
      "loss.item of the train =  69 0.3073369562625885\n",
      "loss.item of the train =  69 0.3060499131679535\n",
      "loss.item of the train =  69 0.306000292301178\n",
      "loss.item of the valid =  69 0.2545180320739746\n",
      "loss.item of the valid =  69 0.0873507708311081\n",
      "loss.item of the valid =  69 0.04180503636598587\n",
      "loss.item of the valid =  69 0.7167565226554871\n",
      "Iteration 70 \t\t Training Loss: 0.061200058460235594 \t\t Validation Loss: 0.2751075904816389\n",
      "loss.item of the train =  70 0.30683931708335876\n",
      "loss.item of the train =  70 0.30732595920562744\n",
      "loss.item of the train =  70 0.30756083130836487\n",
      "loss.item of the train =  70 0.30759915709495544\n",
      "loss.item of the train =  70 0.3074693977832794\n",
      "loss.item of the valid =  70 0.25492483377456665\n",
      "loss.item of the valid =  70 0.08718647062778473\n",
      "loss.item of the valid =  70 0.04191390424966812\n",
      "loss.item of the valid =  70 0.7180690765380859\n",
      "Iteration 71 \t\t Training Loss: 0.06149387955665588 \t\t Validation Loss: 0.27552357129752636\n",
      "loss.item of the train =  71 0.3071802854537964\n",
      "loss.item of the train =  71 0.3067232072353363\n",
      "loss.item of the train =  71 0.30607083439826965\n",
      "loss.item of the train =  71 0.30642634630203247\n",
      "loss.item of the train =  71 0.3062352240085602\n",
      "loss.item of the valid =  71 0.2556470036506653\n",
      "loss.item of the valid =  71 0.08798576891422272\n",
      "loss.item of the valid =  71 0.035415347665548325\n",
      "loss.item of the valid =  71 0.7219240665435791\n",
      "Iteration 72 \t\t Training Loss: 0.06124704480171204 \t\t Validation Loss: 0.27524304669350386\n",
      "loss.item of the train =  72 0.30593129992485046\n",
      "loss.item of the train =  72 0.30632469058036804\n",
      "loss.item of the train =  72 0.30642828345298767\n",
      "loss.item of the train =  72 0.3062848150730133\n",
      "loss.item of the train =  72 0.3059057295322418\n",
      "loss.item of the valid =  72 0.2530076503753662\n",
      "loss.item of the valid =  72 0.08829610794782639\n",
      "loss.item of the valid =  72 0.03992094844579697\n",
      "loss.item of the valid =  72 0.7131310105323792\n",
      "Iteration 73 \t\t Training Loss: 0.06118114590644837 \t\t Validation Loss: 0.2735889293253422\n",
      "loss.item of the train =  73 0.30546462535858154\n",
      "loss.item of the train =  73 0.30511972308158875\n",
      "loss.item of the train =  73 0.3072751760482788\n",
      "loss.item of the train =  73 0.304684042930603\n",
      "loss.item of the train =  73 0.3050549328327179\n",
      "loss.item of the valid =  73 0.2543146014213562\n",
      "loss.item of the valid =  73 0.08851831406354904\n",
      "loss.item of the valid =  73 0.036716025322675705\n",
      "loss.item of the valid =  73 0.7178887128829956\n",
      "Iteration 74 \t\t Training Loss: 0.06101098656654358 \t\t Validation Loss: 0.27435941342264414\n",
      "loss.item of the train =  74 0.30512651801109314\n",
      "loss.item of the train =  74 0.30488505959510803\n",
      "loss.item of the train =  74 0.3064526915550232\n",
      "loss.item of the train =  74 0.3052649199962616\n",
      "loss.item of the train =  74 0.30574092268943787\n",
      "loss.item of the valid =  74 0.2520325779914856\n",
      "loss.item of the valid =  74 0.08797507733106613\n",
      "loss.item of the valid =  74 0.05128776654601097\n",
      "loss.item of the valid =  74 0.708713173866272\n",
      "Iteration 75 \t\t Training Loss: 0.061148184537887576 \t\t Validation Loss: 0.27500214893370867\n",
      "loss.item of the train =  75 0.30659446120262146\n",
      "loss.item of the train =  75 0.3070707619190216\n",
      "loss.item of the train =  75 0.30722877383232117\n",
      "loss.item of the train =  75 0.30711719393730164\n",
      "loss.item of the train =  75 0.3067501485347748\n",
      "loss.item of the valid =  75 0.25238746404647827\n",
      "loss.item of the valid =  75 0.08824761211872101\n",
      "loss.item of the valid =  75 0.04639466106891632\n",
      "loss.item of the valid =  75 0.710458517074585\n",
      "Iteration 76 \t\t Training Loss: 0.06135002970695495 \t\t Validation Loss: 0.27437206357717514\n",
      "loss.item of the train =  76 0.3061133921146393\n",
      "loss.item of the train =  76 0.30515986680984497\n",
      "loss.item of the train =  76 0.3065684735774994\n",
      "loss.item of the train =  76 0.3069336712360382\n",
      "loss.item of the train =  76 0.3048401474952698\n",
      "loss.item of the valid =  76 0.2537107765674591\n",
      "loss.item of the valid =  76 0.08860644698143005\n",
      "loss.item of the valid =  76 0.035714469850063324\n",
      "loss.item of the valid =  76 0.7156975269317627\n",
      "Iteration 77 \t\t Training Loss: 0.06096802949905396 \t\t Validation Loss: 0.2734323050826788\n",
      "loss.item of the train =  77 0.30520349740982056\n",
      "loss.item of the train =  77 0.3053324520587921\n",
      "loss.item of the train =  77 0.3051302433013916\n",
      "loss.item of the train =  77 0.30486130714416504\n",
      "loss.item of the train =  77 0.3050207793712616\n",
      "loss.item of the valid =  77 0.25319957733154297\n",
      "loss.item of the valid =  77 0.08880002051591873\n",
      "loss.item of the valid =  77 0.03665706887841225\n",
      "loss.item of the valid =  77 0.7144452333450317\n",
      "Iteration 78 \t\t Training Loss: 0.06100415587425232 \t\t Validation Loss: 0.2732754750177264\n",
      "loss.item of the train =  78 0.30504608154296875\n",
      "loss.item of the train =  78 0.3046671748161316\n",
      "loss.item of the train =  78 0.3071187436580658\n",
      "loss.item of the train =  78 0.3046841323375702\n",
      "loss.item of the train =  78 0.30612680315971375\n",
      "loss.item of the valid =  78 0.251984179019928\n",
      "loss.item of the valid =  78 0.08781474083662033\n",
      "loss.item of the valid =  78 0.05513988435268402\n",
      "loss.item of the valid =  78 0.7079132199287415\n",
      "Iteration 79 \t\t Training Loss: 0.06122536063194275 \t\t Validation Loss: 0.27571300603449345\n",
      "loss.item of the train =  79 0.3070317506790161\n",
      "loss.item of the train =  79 0.3075360953807831\n",
      "loss.item of the train =  79 0.307828813791275\n",
      "loss.item of the train =  79 0.3079541325569153\n",
      "loss.item of the train =  79 0.3079157769680023\n",
      "loss.item of the valid =  79 0.2522108554840088\n",
      "loss.item of the valid =  79 0.0874372124671936\n",
      "loss.item of the valid =  79 0.05873522534966469\n",
      "loss.item of the valid =  79 0.707852840423584\n",
      "Iteration 80 \t\t Training Loss: 0.061583155393600465 \t\t Validation Loss: 0.27655903343111277\n",
      "loss.item of the train =  80 0.3077280521392822\n",
      "loss.item of the train =  80 0.3073917627334595\n",
      "loss.item of the train =  80 0.3068944811820984\n",
      "loss.item of the train =  80 0.306208074092865\n",
      "loss.item of the train =  80 0.3052847981452942\n",
      "loss.item of the valid =  80 0.25543707609176636\n",
      "loss.item of the valid =  80 0.08925241976976395\n",
      "loss.item of the valid =  80 0.04201669618487358\n",
      "loss.item of the valid =  80 0.722864031791687\n",
      "Iteration 81 \t\t Training Loss: 0.06105695962905884 \t\t Validation Loss: 0.2773925559595227\n",
      "loss.item of the train =  81 0.30687856674194336\n",
      "loss.item of the train =  81 0.30748751759529114\n",
      "loss.item of the train =  81 0.30508413910865784\n",
      "loss.item of the train =  81 0.3058597445487976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item of the train =  81 0.30619606375694275\n",
      "loss.item of the valid =  81 0.2522604465484619\n",
      "loss.item of the valid =  81 0.08839605748653412\n",
      "loss.item of the valid =  81 0.047046761959791183\n",
      "loss.item of the valid =  81 0.7100505232810974\n",
      "Iteration 82 \t\t Training Loss: 0.06123921275138855 \t\t Validation Loss: 0.27443844731897116\n",
      "loss.item of the train =  82 0.30618804693222046\n",
      "loss.item of the train =  82 0.305870920419693\n",
      "loss.item of the train =  82 0.3052689731121063\n",
      "loss.item of the train =  82 0.305349200963974\n"
     ]
    }
   ],
   "source": [
    "nb_iter=100\n",
    "InsDel, nodeSub,edgeSub,loss_plt,loss_valid_plt,loss_train_plt=classification(model,data,yt,nb_iter)\n",
    "plt.figure(0)\n",
    "plt.plot(InsDel[0:nb_iter,0],label=\"node\")\n",
    "plt.plot(InsDel[0:nb_iter,1],label=\"edge\")\n",
    "plt.title('Node/Edge insertion/deletion costs')\n",
    "plt.legend()\n",
    "plt.figure(1)\n",
    "for k in range(nodeSub.shape[1]):\n",
    "    plt.plot(nodeSub[0:nb_iter,k])\n",
    "plt.title('Node Substitutions costs')\n",
    "plt.figure(2)\n",
    "for k in range(edgeSub.shape[1]):\n",
    "    plt.plot(edgeSub[0:nb_iter,k])\n",
    "plt.title('Edge Substitutions costs')\n",
    "plt.figure(3)\n",
    "plt.plot(loss_plt)\n",
    "plt.title('Evolution of the train loss (loss_plt)')\n",
    "\n",
    "plt.figure(4)\n",
    "plt.plot(loss_valid_plt)\n",
    "plt.title('Evolution of the valid loss')\n",
    "'''\n",
    "plt.figure(5)\n",
    "plt.plot(loss_train_plt)\n",
    "plt.title('Evolution of the loss_train_plt')\n",
    "'''\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=torch.tensor(nx.to_scipy_sparse_matrix(Gs[0],dtype=int,weight='bond_type').todense(),dtype=torch.int) \n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_plt, label='train loss')\n",
    "plt.plot(loss_valid_plt, label='valid loss')\n",
    "plt.title('Train and valid losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.plot(InsDel[0:500,0],label=\"node\")\n",
    "plt.plot(InsDel[0:500,1],label=\"edge\")\n",
    "plt.title('Node/Edge insertion/deletion costs')\n",
    "plt.legend()\n",
    "plt.figure(1)\n",
    "for k in range(nodeSub.shape[1]):\n",
    "    plt.plot(nodeSub[0:500,k])\n",
    "plt.title('node Substitution costs')\n",
    "plt.figure(2)\n",
    "for k in range(edgeSub.shape[1]):\n",
    "    plt.plot(edgeSub[0:500,k])\n",
    "plt.title('edge Substitution costs')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
