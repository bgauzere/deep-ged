{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gklearn.utils.graphfiles import loadDataset\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge max label 3\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "def label_to_color(label):\n",
    "    if label == 'C':\n",
    "        return 0.1\n",
    "    elif label == 'O':\n",
    "        return 0.8\n",
    "    \n",
    "def nodes_to_color_sequence(G):\n",
    "    return [label_to_color(c[1]['label'][0]) for c in G.nodes(data=True)]\n",
    "\n",
    "Gs,y = loadDataset('../../DeepGED/MAO/dataset.ds')\n",
    "#for e in Gs[13].edges():\n",
    "#    print(Gs[13][e[0]][e[1]]['bond_type'])\n",
    "print('edge max label',max(max([[G[e[0]][e[1]]['bond_type'] for e in G.edges()] for G in Gs])))\n",
    "G1 = Gs[1]\n",
    "G2 = Gs[9]\n",
    "print(y[1],y[9])\n",
    "plt.figure(0)\n",
    "nx.draw_networkx(G1,with_labels=True,node_color = nodes_to_color_sequence(G1),cmap='autumn')\n",
    "\n",
    "plt.figure(1)\n",
    "nx.draw_networkx(G2,with_labels=True,node_color = nodes_to_color_sequence(G2),cmap='autumn')\n",
    "\n",
    "plt.show()\n",
    "import extended_label\n",
    "for g in Gs:\n",
    "    extended_label.compute_extended_labels(g)\n",
    "#for v in Gs[10].nodes():\n",
    "#        print(Gs[10].nodes[v])\n",
    "\n",
    "#print(nx.to_dict_of_lists(Gs[13]))\n",
    "\n",
    "\n",
    "\n",
    "#dict={'C':0,'N':1,'O':2}\n",
    "#A,labels=from_networkx_to_tensor2(Gs[13],dict)\n",
    "#print(A)\n",
    "#A1=(A==torch.ones(13,13)).int()\n",
    "#A2=(A==2*torch.ones(13,13)).int()\n",
    "#print(A1)\n",
    "#print(A2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n",
      "<torch.cuda.device object at 0x7eff9c5b7470>\n",
      "0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.__version__)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#model.to(device)\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gs= 68\n",
      "['C_1C', 'C_1C1C1N', 'C_1C1C2C', 'C_1C1N', 'C_1C1N2C', 'C_1C1O', 'C_1C1O2C', 'C_1C2C', 'C_1C3C', 'C_1N', 'C_1O', 'C_2C', 'C_2C2C', 'C_3C', 'N_1C', 'N_1C1C', 'N_1C1C1C', 'O_1C', 'O_1C1C']\n",
      "{'C_1C': 0, 'C_1C1C1N': 1, 'C_1C1C2C': 2, 'C_1C1N': 3, 'C_1C1N2C': 4, 'C_1C1O': 5, 'C_1C1O2C': 6, 'C_1C2C': 7, 'C_1C3C': 8, 'C_1N': 9, 'C_1O': 10, 'C_2C': 11, 'C_2C2C': 12, 'C_3C': 13, 'N_1C': 14, 'N_1C1C': 15, 'N_1C1C1C': 16, 'O_1C': 17, 'O_1C1C': 18} 19\n",
      "nb_edge_labels :  3\n",
      "torch.Size([68, 729])\n",
      "adjacency matrices tensor([[       0,        1,        0,  ...,        0,        0, 16777217],\n",
      "        [       0,        1,        0,  ...,        0,        0,        0],\n",
      "        [       0,        1,        0,  ...,        0,      256,        0],\n",
      "        ...,\n",
      "        [       0,        1,        0,  ...,        1,      257,        0],\n",
      "        [       0,        1,        0,  ...,        0,        0,    14497],\n",
      "        [       0,        1,        0,  ...,        0,        0,        0]],\n",
      "       dtype=torch.int32)\n",
      "node labels tensor([[        15,          4,          7,  ...,  306744464,          0,\n",
      "                  3],\n",
      "        [        15,          4,          7,  ...,          0,          0,\n",
      "                  0],\n",
      "        [        15,          4,          7,  ...,        256,          0,\n",
      "         -552192784],\n",
      "        ...,\n",
      "        [        16,          4,          7,  ...,          0,  306751456,\n",
      "                  0],\n",
      "        [        16,          4,          7,  ...,          0,          0,\n",
      "                  0],\n",
      "        [        16,          4,          7,  ...,          0,         32,\n",
      "                  0]], dtype=torch.int32)\n",
      "order of the graphs tensor([11, 12, 14, 14, 15, 17, 15, 16, 19, 15, 16, 19, 12, 13, 15, 18, 16, 16,\n",
      "        17, 16, 17, 17, 18, 19, 19, 18, 18, 22, 22, 15, 14, 13, 16, 17, 17, 21,\n",
      "        17, 18, 18, 21, 24, 25, 25, 14, 17, 18, 18, 22, 23, 23, 25, 27, 27, 15,\n",
      "        16, 23, 24, 24, 16, 17, 17, 20, 23, 24, 26, 16, 17, 21])\n",
      "27 68\n",
      "toto\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import svd\n",
    "import rings\n",
    "from svd import iterated_power as compute_major_axis\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "        \n",
    "    def __init__(self,GraphList,normalize=False,node_label='label'):\n",
    "        super(Net, self).__init__()   \n",
    "        self.normalize=normalize\n",
    "        self.node_label=node_label\n",
    "        dict,self.nb_edge_labels=self.build_node_dictionnary(GraphList)\n",
    "        self.nb_labels=len(dict)\n",
    "        print('nb_edge_labels : ', self.nb_edge_labels)\n",
    "        self.device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        #torch.device(\"cuda:0\")\n",
    "        nb_node_pair_label=self.nb_labels*(self.nb_labels-1)/2.0\n",
    "        nb_edge_pair_label=int(self.nb_edge_labels*(self.nb_edge_labels-1)/2)\n",
    "        \n",
    "        self.node_weighs=nn.Parameter(torch.tensor(1.0/(nb_node_pair_label+nb_edge_pair_label+2))+(1e-3)*torch.rand(int(self.nb_labels*(self.nb_labels-1)/2+1),requires_grad=True,device=self.device)) # all substitution costs+ nodeIns/Del. old version: 0 node subs, 1 nodeIns/Del, 2 : edgeSubs, 3 edgeIns/Del        \n",
    "        self.edge_weighs=nn.Parameter(torch.tensor(1.0/(nb_node_pair_label+nb_edge_pair_label+2))+(1e-3)*torch.rand(nb_edge_pair_label+1,requires_grad=True,device=self.device)) #edgeIns/Del\n",
    "        \n",
    "        self.card=torch.tensor([G.order() for G in GraphList]).to(self.device)\n",
    "        card_max=self.card.max()\n",
    "        self.A=torch.empty((len(GraphList),card_max*card_max),dtype=torch.int,device=self.device)\n",
    "        self.labels=torch.empty((len(GraphList),card_max),dtype=torch.int,device=self.device)\n",
    "        print(self.A.shape)\n",
    "        for k in range(len(GraphList)):\n",
    "            A,l=self.from_networkx_to_tensor(GraphList[k],dict)             \n",
    "            self.A[k,0:A.shape[1]]=A[0]\n",
    "            self.labels[k,0:l.shape[0]]=l\n",
    "        print('adjacency matrices',self.A)\n",
    "        print('node labels',self.labels)\n",
    "        print('order of the graphs',self.card)\n",
    "        \n",
    "    def forward(self, input):        \n",
    "        ged=torch.zeros(len(input)).to(self.device) \n",
    "        node_costs,nodeInsDel,edge_costs,edgeInsDel=self.from_weighs_to_costs()\n",
    "        \n",
    "        #print('weighs:',self.weighs.device,'device:',self.device,'card:',self.card.device,'A:',self.A.device,'labels:',self.labels.device)\n",
    "        for k in range(len(input)):            \n",
    "            g1=input[k][0]\n",
    "            g2=input[k][1]\n",
    "            n=self.card[g1]\n",
    "            m=self.card[g2]\n",
    "            \n",
    "            self.ring_g,self.ring_h = rings.build_rings(g1,edgeInsDel.size()), rings.build_rings(g2,edgeInsDel.size()) \n",
    "                        \n",
    "            C=self.construct_cost_matrix(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)      \n",
    "            #S=self.mapping_from_similarity(C,n,m)\n",
    "            #S=self.mapping_from_cost(C,n,m)\n",
    "            \n",
    "            #S=self.new_mapping_from_cost(C,n,m,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "            S=self.mapping_from_cost_sans_FW(n,m,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "            v=torch.flatten(S)\n",
    "            \n",
    "            normalize_factor=1.0\n",
    "            if self.normalize:\n",
    "                nb_edge1=(self.A[g1][0:n*n] != torch.zeros(n*n,device=self.device)).int().sum()\n",
    "                nb_edge2=(self.A[g2][0:m*m] != torch.zeros(m*m,device=self.device)).int().sum()\n",
    "                normalize_factor=nodeInsDel*(n+m)+edgeInsDel*(nb_edge1+nb_edge2)\n",
    "                \n",
    "            ged[k]=.5*(v.t()@C@v)/normalize_factor\n",
    "        return ged\n",
    "    \n",
    "    def from_weighs_to_costs(self):\n",
    "        \n",
    "        #cn=torch.exp(self.node_weighs)\n",
    "        #ce=torch.exp(self.edge_weighs)\n",
    "        cn=self.node_weighs*self.node_weighs\n",
    "        ce=self.edge_weighs*self.edge_weighs\n",
    "        total_cost=cn.sum()+ce.sum()\n",
    "        cn=cn/total_cost\n",
    "        ce=ce/total_cost\n",
    "        edgeInsDel=ce[-1]\n",
    "\n",
    "        node_costs=torch.zeros((self.nb_labels,self.nb_labels),device=self.device)\n",
    "        upper_part=torch.triu_indices(node_costs.shape[0],node_costs.shape[1],offset=1,device=self.device)        \n",
    "        node_costs[upper_part[0],upper_part[1]]=cn[0:-1]\n",
    "        node_costs=node_costs+node_costs.T\n",
    "\n",
    "        if self.nb_edge_labels>1:\n",
    "            edge_costs=torch.zeros((self.nb_edge_labels,self.nb_edge_labels),device=self.device)\n",
    "            upper_part=torch.triu_indices(edge_costs.shape[0],edge_costs.shape[1],offset=1,device=self.device)        \n",
    "            edge_costs[upper_part[0],upper_part[1]]=ce[0:-1]\n",
    "            edge_costs=edge_costs+edge_costs.T\n",
    "        else:\n",
    "            edge_costs=torch.zeros(0,device=self.device)\n",
    "        \n",
    "        return node_costs,cn[-1],edge_costs,edgeInsDel\n",
    "    \n",
    "    def build_node_dictionnary(self,GraphList):\n",
    "        #extraction de tous les labels d'atomes\n",
    "        node_labels=[]\n",
    "        for G in Gs:\n",
    "            for v in nx.nodes(G):\n",
    "                if not G.nodes[v][self.node_label][0] in node_labels:\n",
    "                    node_labels.append(G.nodes[v][self.node_label][0])\n",
    "        node_labels.sort()\n",
    "        #extraction d'un dictionnaire permettant de numéroter chaque label par un numéro.\n",
    "        dict={}\n",
    "        k=0\n",
    "        for label in node_labels:\n",
    "            dict[label]=k\n",
    "            k=k+1\n",
    "        print(node_labels)\n",
    "        print(dict,len(dict))\n",
    "    \n",
    "        return dict,max(max([[int(G[e[0]][e[1]]['bond_type']) for e in G.edges()] for G in GraphList]))\n",
    "    \n",
    "    def from_networkx_to_tensor(self,G,dict):    \n",
    "        A=torch.tensor(nx.to_scipy_sparse_matrix(G,dtype=int,weight='bond_type').todense(),dtype=torch.int)        \n",
    "        lab=[dict[G.nodes[v][self.node_label][0]] for v in nx.nodes(G)]\n",
    "   \n",
    "        return (A.view(1,A.shape[0]*A.shape[1]),torch.tensor(lab))\n",
    "\n",
    "    def construct_cost_matrix(self,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel):\n",
    "        n = self.card[g1].item()\n",
    "        m = self.card[g2].item()\n",
    "        \n",
    "        A1=torch.zeros((n+1,n+1),dtype=torch.int,device=self.device)\n",
    "        A1[0:n,0:n]=self.A[g1][0:n*n].view(n,n)\n",
    "        A2=torch.zeros((m+1,m+1),dtype=torch.int,device=self.device)\n",
    "        A2[0:m,0:m]=self.A[g2][0:m*m].view(m,m)\n",
    "        \n",
    "        \n",
    "         # costs: 0 node subs, 1 nodeIns/Del, 2 : edgeSubs, 3 edgeIns/Del\n",
    "        \n",
    "        #C=cost[3]*torch.cat([torch.cat([C12[l][k] for k in range(n+1)],1) for l in range(n+1)])\n",
    "        #Pas bien sur mais cela semble fonctionner.\n",
    "        C=edgeInsDel*self.matrix_edgeInsDel(A1,A2)\n",
    "        if self.nb_edge_labels>1:\n",
    "            for k in range(self.nb_edge_labels):\n",
    "                for l in range(self.nb_edge_labels):\n",
    "                    if k != l:\n",
    "#                    C.add_(self.matrix_edgeSubst(A1,A2,k+1,l+1),alpha=edge_costs[k][l])\n",
    "                        C=C+edge_costs[k][l]*self.matrix_edgeSubst(A1,A2,k+1,l+1)\n",
    "        #C=cost[3]*torch.tensor(np.array([ [  k!=l and A1[k//(m+1),l//(m+1)]^A2[k%(m+1),l%(m+1)] for k in range((n+1)*(m+1))] for l in range((n+1)*(m+1))]),device=self.device)        \n",
    "\n",
    "        l1=self.labels[g1][0:n]\n",
    "        l2=self.labels[g2][0:m]\n",
    "        D=torch.zeros((n+1)*(m+1),device=self.device)\n",
    "        D[n*(m+1):]=nodeInsDel\n",
    "        D[n*(m+1)+m]=0\n",
    "        D[[i*(m+1)+m for i in range(n)]]=nodeInsDel\n",
    "        D[[k for k in range(n*(m+1)) if k%(m+1) != m]]=torch.tensor([node_costs[l1[k//(m+1)],l2[k%(m+1)]] for k in range(n*(m+1)) if k%(m+1) != m],device=self.device )\n",
    "        mask = torch.diag(torch.ones_like(D))\n",
    "        C=mask*torch.diag(D) + (1. - mask)*C\n",
    "        \n",
    "        #C[range(len(C)),range(len(C))]=D\n",
    "      \n",
    "        return C\n",
    "    \n",
    "    def matrix_edgeInsDel(self,A1,A2):\n",
    "        Abin1=(A1!=torch.zeros((A1.shape[0],A1.shape[1]),device=self.device))\n",
    "        Abin2=(A2!=torch.zeros((A2.shape[0],A2.shape[1]),device=self.device))\n",
    "        C1=torch.einsum('ij,kl->ijkl',torch.logical_not(Abin1),Abin2)\n",
    "        C2=torch.einsum('ij,kl->ijkl',Abin1,torch.logical_not(Abin2))\n",
    "        C12=torch.logical_or(C1,C2).int()\n",
    "    \n",
    "        return torch.cat(torch.unbind(torch.cat(torch.unbind(C12,1),1),0),1)\n",
    "\n",
    "    def matrix_edgeSubst(self,A1,A2,lab1,lab2):\n",
    "        Abin1=(A1==lab1*torch.ones((A1.shape[0],A1.shape[1]),device=self.device)).int()\n",
    "        Abin2=(A2==lab2*torch.ones((A2.shape[0],A2.shape[1]),device=self.device)).int()\n",
    "        C=torch.einsum('ij,kl->ijkl',Abin1,Abin2)\n",
    "        \n",
    "        return torch.cat(torch.unbind(torch.cat(torch.unbind(C,1),1),0),1)\n",
    "    \n",
    "    def similarity_from_cost(self,C):\n",
    "        N=C.shape[0]\n",
    "             \n",
    "        #return (torch.norm(C,p='fro')*torch.eye(N,device=self.device) -C)\n",
    "        return (C.max()*torch.eye(N,device=self.device) -C)\n",
    "    \n",
    "\n",
    "    \n",
    "    def lsape_populate_instance(self,first_graph,second_graph,average_node_cost, average_edge_cost,alpha,lbda):       #ring_g, ring_h come from global ring with all graphs in so ring_g = rings['g'] and ring_h = rings['h']\n",
    "        g,h = Gs[first_graph], Gs[second_graph]\n",
    "        self.average_cost =[average_node_cost, average_edge_cost]\n",
    "        self.first_graph, self.second_graph = first_graph,second_graph\n",
    "        \n",
    "        node_costs,nodeInsDel,edge_costs,edgeInsDel=self.from_weighs_to_costs()\n",
    "\n",
    "        lsape_instance = [[0 for _ in range(len(g) + 1)] for __ in range(len(h) + 1)]\n",
    "        for g_node_index in range(len(g) + 1):\n",
    "            for h_node_index in range(len(h) + 1):\n",
    "                lsape_instance[h_node_index][g_node_index] = rings.compute_ring_distance(g,h,self.ring_g,self.ring_h,g_node_index,h_node_index,alpha,lbda,node_costs,nodeInsDel,edge_costs,edgeInsDel,first_graph,second_graph)\n",
    "        for i in lsape_instance :\n",
    "            i = torch.as_tensor(i)\n",
    "        lsape_instance = torch.as_tensor(lsape_instance)\n",
    "        #print(type(lsape_instance))\n",
    "        return lsape_instance\n",
    "    \n",
    "  \n",
    "    def mapping_from_cost_sans_FW(self,n,m,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel): \n",
    "        c_0 =self.lsape_populate_instance(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "        x0=svd.eps_assigment_from_mapping(torch.exp(-c_0),10).view((n+1)*(m+1),1)\n",
    "        return x0\n",
    "    \n",
    "    def new_mapping_from_cost(self,C,n,m,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel): \n",
    "        c=torch.diag(C)       \n",
    "        c_0 =self.lsape_populate_instance(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "        D=C-torch.eye(C.shape[0],device=self.device)*c\n",
    "        x0=svd.eps_assigment_from_mapping(torch.exp(-c_0),10).view((n+1)*(m+1),1)\n",
    "        return svd.franck_wolfe(x0,D,c,5,15,n,m)\n",
    "    \n",
    "    def mapping_from_cost(self,C,n,m): #à améliorer car on prend que les coût des sommets\n",
    "        c=torch.diag(C)       #diag donc vecteur/ matrice ligne, alors comment .view(n+1,m+1) est sensé marcher ?\n",
    "        c_0=lsape_populate_instance(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "        print('C.shape[0] : ', C.shape[0])\n",
    "        D=C-torch.eye(C.shape[0],device=self.device)*c\n",
    "        print('c : ',c)\n",
    "        #x0=svd.eps_assigment_from_mapping(c,10)\n",
    "        x0=svd.eps_assigment_from_mapping(torch.exp(-c_0),10).view((n+1)*(m+1),1)\n",
    "        return svd.franck_wolfe(x0,D,c,5,15,n,m)\n",
    "    \n",
    "        \n",
    "    def mapping_from_similarity(self,C,n,m):\n",
    "        M=self.similarity_from_cost(C)\n",
    "        first_ev=compute_major_axis(M)\n",
    "        #first_ev=self.iterated_power(M,inv=True)\n",
    "        if(first_ev.sum() <0):\n",
    "            first_ev=-first_ev\n",
    "        S=torch.exp(first_ev.view(n+1,m+1)) # enforce the difference, accelerate the convergence. \n",
    "        S=self.eps_assigment_from_mapping(S)\n",
    "        return  S\n",
    "  \n",
    "print('Gs=',len(Gs))\n",
    "model = Net(Gs,normalize=True,node_label='extended_label')\n",
    "\n",
    "#params = list(model.parameters())\n",
    "#print(len(params))\n",
    "#print(params[0])\n",
    "#print(model(input))\n",
    "print(max([G.order() for G in Gs]),len(Gs))\n",
    "print('toto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 24, 18, 27, 13,  9, 21, 28])\n",
      "tensor([21, 37,  4, 44, 26, 65, 58,  7, 31, 57, 41, 54, 50, 31, 11])\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "nb=len(Gs)\n",
    "class1=torch.tensor([k for k in range(len(y)) if y[k]==1])\n",
    "class2=torch.tensor([k for k in range(len(y)) if y[k]==0])\n",
    "\n",
    "train_size=15\n",
    "\n",
    "if train_size % 2 == 0:\n",
    "    nb_class1=int(train_size/2)\n",
    "    nb_class2=int(train_size/2)\n",
    "else:\n",
    "    nb_class1=int(train_size/2)+1\n",
    "    nb_class2=int(train_size/2)\n",
    "    \n",
    "print((torch.abs(10000*torch.randn(nb_class1)).int()%class1.size()[0]).long())\n",
    "random_class1=class1[(torch.abs(10000*torch.randn(nb_class1)).int()%class1.size()[0]).long()]\n",
    "random_class2=class2[(torch.abs(10000*torch.randn(nb_class2)).int()%class2.size()[0]).long()]\n",
    "train_graphs=torch.cat((random_class1,random_class2),0)\n",
    "print(train_graphs)\n",
    "\n",
    "couples=torch.triu_indices(train_size,train_size,offset=1)\n",
    "\n",
    "#combinations=itertools.combinations(range(nb),2)\n",
    "\n",
    "nb_elt=int(train_size*(train_size-1)/2)\n",
    "data=torch.empty((nb_elt,2),dtype=torch.int)\n",
    "yt=torch.ones(nb_elt)\n",
    "\n",
    "data[0:nb_elt,0]=train_graphs[couples[0]]\n",
    "data[0:nb_elt,1]=train_graphs[couples[1]]\n",
    "print(nb_elt)\n",
    "#couples=[]\n",
    "for k in range(nb_elt):\n",
    "    if (y[data[k][0]]!=y[data[k][1]]):\n",
    "        yt[k]=-1.0        \n",
    "\n",
    "#print('data=',data)\n",
    "\n",
    "#print(couples[1:2])\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")          # a CUDA device object    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "0 0.493192583322525\n",
      "Distances:  tensor([0.4108, 0.3958, 0.3545, 0.4096, 0.3995, 0.3996, 0.3994, 0.4120, 0.5007,\n",
      "        0.4925, 0.4005, 0.4935, 0.4120, 0.4210, 0.4015, 0.4000, 0.3548, 0.4009,\n",
      "        0.4012, 0.4014, 0.4213, 0.4721, 0.4922, 0.4016, 0.4937, 0.4213, 0.4089,\n",
      "        0.4153, 0.4425, 0.4108, 0.4125, 0.4122, 0.4032, 0.5672, 0.5446, 0.4119,\n",
      "        0.5440, 0.4032, 0.4372, 0.4099, 0.3990, 0.3990, 0.3992, 0.4131, 0.4976,\n",
      "        0.4872, 0.4000, 0.4883, 0.4131, 0.4209, 0.4004, 0.4004, 0.4006, 0.4204,\n",
      "        0.4727, 0.4899, 0.4005, 0.4921, 0.4204, 0.4091, 0.3545, 0.3544, 0.4047,\n",
      "        0.5135, 0.5432, 0.3549, 0.5441, 0.4047, 0.4421, 0.3544, 0.4057, 0.5184,\n",
      "        0.5429, 0.3549, 0.5437, 0.4057, 0.4414, 0.4069, 0.5193, 0.5415, 0.3548,\n",
      "        0.5424, 0.4069, 0.4392, 0.6408, 0.6290, 0.4463, 0.6297, 0.3532, 0.4812,\n",
      "        0.4069, 0.4575, 0.4080, 0.5510, 0.4039, 0.4713, 0.3576, 0.5720, 0.4220,\n",
      "        0.5469, 0.4058, 0.4420, 0.5724, 0.4230, 0.4812], grad_fn=<CopySlices>)\n",
      "Loss Triangular: 0.0\n",
      "node_costs :\n",
      "tensor([[0.0000, 0.0050, 0.0051, 0.0054, 0.0050, 0.0054, 0.0065, 0.0056, 0.0052,\n",
      "         0.0055, 0.0050, 0.0065, 0.0066, 0.0055, 0.0061, 0.0053, 0.0057, 0.0051,\n",
      "         0.0050],\n",
      "        [0.0050, 0.0000, 0.0049, 0.0049, 0.0054, 0.0052, 0.0066, 0.0062, 0.0053,\n",
      "         0.0054, 0.0058, 0.0049, 0.0059, 0.0051, 0.0063, 0.0052, 0.0051, 0.0058,\n",
      "         0.0049],\n",
      "        [0.0051, 0.0049, 0.0000, 0.0052, 0.0049, 0.0060, 0.0055, 0.0050, 0.0063,\n",
      "         0.0057, 0.0054, 0.0055, 0.0053, 0.0066, 0.0063, 0.0062, 0.0066, 0.0064,\n",
      "         0.0048],\n",
      "        [0.0054, 0.0049, 0.0052, 0.0000, 0.0065, 0.0055, 0.0051, 0.0050, 0.0058,\n",
      "         0.0065, 0.0056, 0.0056, 0.0048, 0.0060, 0.0053, 0.0065, 0.0050, 0.0060,\n",
      "         0.0051],\n",
      "        [0.0050, 0.0054, 0.0049, 0.0065, 0.0000, 0.0063, 0.0052, 0.0061, 0.0056,\n",
      "         0.0060, 0.0049, 0.0050, 0.0057, 0.0050, 0.0050, 0.0063, 0.0052, 0.0064,\n",
      "         0.0063],\n",
      "        [0.0054, 0.0052, 0.0060, 0.0055, 0.0063, 0.0000, 0.0059, 0.0054, 0.0057,\n",
      "         0.0058, 0.0063, 0.0057, 0.0062, 0.0054, 0.0064, 0.0051, 0.0055, 0.0062,\n",
      "         0.0065],\n",
      "        [0.0065, 0.0066, 0.0055, 0.0051, 0.0052, 0.0059, 0.0000, 0.0063, 0.0055,\n",
      "         0.0057, 0.0051, 0.0065, 0.0062, 0.0066, 0.0057, 0.0063, 0.0051, 0.0049,\n",
      "         0.0066],\n",
      "        [0.0056, 0.0062, 0.0050, 0.0050, 0.0061, 0.0054, 0.0063, 0.0000, 0.0052,\n",
      "         0.0049, 0.0060, 0.0049, 0.0061, 0.0052, 0.0065, 0.0058, 0.0055, 0.0060,\n",
      "         0.0058],\n",
      "        [0.0052, 0.0053, 0.0063, 0.0058, 0.0056, 0.0057, 0.0055, 0.0052, 0.0000,\n",
      "         0.0052, 0.0049, 0.0055, 0.0049, 0.0054, 0.0065, 0.0056, 0.0061, 0.0060,\n",
      "         0.0064],\n",
      "        [0.0055, 0.0054, 0.0057, 0.0065, 0.0060, 0.0058, 0.0057, 0.0049, 0.0052,\n",
      "         0.0000, 0.0058, 0.0048, 0.0050, 0.0061, 0.0065, 0.0062, 0.0051, 0.0064,\n",
      "         0.0060],\n",
      "        [0.0050, 0.0058, 0.0054, 0.0056, 0.0049, 0.0063, 0.0051, 0.0060, 0.0049,\n",
      "         0.0058, 0.0000, 0.0060, 0.0051, 0.0057, 0.0052, 0.0052, 0.0066, 0.0063,\n",
      "         0.0061],\n",
      "        [0.0065, 0.0049, 0.0055, 0.0056, 0.0050, 0.0057, 0.0065, 0.0049, 0.0055,\n",
      "         0.0048, 0.0060, 0.0000, 0.0052, 0.0057, 0.0058, 0.0052, 0.0048, 0.0051,\n",
      "         0.0059],\n",
      "        [0.0066, 0.0059, 0.0053, 0.0048, 0.0057, 0.0062, 0.0062, 0.0061, 0.0049,\n",
      "         0.0050, 0.0051, 0.0052, 0.0000, 0.0057, 0.0063, 0.0052, 0.0050, 0.0052,\n",
      "         0.0064],\n",
      "        [0.0055, 0.0051, 0.0066, 0.0060, 0.0050, 0.0054, 0.0066, 0.0052, 0.0054,\n",
      "         0.0061, 0.0057, 0.0057, 0.0057, 0.0000, 0.0061, 0.0063, 0.0054, 0.0054,\n",
      "         0.0061],\n",
      "        [0.0061, 0.0063, 0.0063, 0.0053, 0.0050, 0.0064, 0.0057, 0.0065, 0.0065,\n",
      "         0.0065, 0.0052, 0.0058, 0.0063, 0.0061, 0.0000, 0.0058, 0.0053, 0.0051,\n",
      "         0.0063],\n",
      "        [0.0053, 0.0052, 0.0062, 0.0065, 0.0063, 0.0051, 0.0063, 0.0058, 0.0056,\n",
      "         0.0062, 0.0052, 0.0052, 0.0052, 0.0063, 0.0058, 0.0000, 0.0060, 0.0059,\n",
      "         0.0064],\n",
      "        [0.0057, 0.0051, 0.0066, 0.0050, 0.0052, 0.0055, 0.0051, 0.0055, 0.0061,\n",
      "         0.0051, 0.0066, 0.0048, 0.0050, 0.0054, 0.0053, 0.0060, 0.0000, 0.0060,\n",
      "         0.0063],\n",
      "        [0.0051, 0.0058, 0.0064, 0.0060, 0.0064, 0.0062, 0.0049, 0.0060, 0.0060,\n",
      "         0.0064, 0.0063, 0.0051, 0.0052, 0.0054, 0.0051, 0.0059, 0.0060, 0.0000,\n",
      "         0.0060],\n",
      "        [0.0050, 0.0049, 0.0048, 0.0051, 0.0063, 0.0065, 0.0066, 0.0058, 0.0064,\n",
      "         0.0060, 0.0061, 0.0059, 0.0064, 0.0061, 0.0063, 0.0064, 0.0063, 0.0060,\n",
      "         0.0000]], grad_fn=<AddBackward0>)\n",
      "nodeInsDel: 0.004891549237072468\n",
      "edge_costs :\n",
      "tensor([[0.0000, 0.0066, 0.0053],\n",
      "        [0.0066, 0.0000, 0.0064],\n",
      "        [0.0053, 0.0064, 0.0000]], grad_fn=<AddBackward0>)\n",
      "edgeInsDel: 0.006616823375225067\n",
      "1 0.4876651465892792\n",
      "2 0.48507943749427795\n",
      "3 0.48359307646751404\n",
      "4 0.4827564060688019\n",
      "5 0.48223748803138733\n",
      "6 0.48185351490974426\n",
      "7 0.4815174639225006\n",
      "8 0.48118242621421814\n",
      "9 0.48080796003341675\n",
      "10 0.4809468388557434\n",
      "11 0.48064762353897095\n",
      "12 0.4801585078239441\n",
      "13 0.4795527160167694\n",
      "14 0.4787607491016388\n",
      "15 0.47757869958877563\n",
      "16 0.4758705198764801\n",
      "17 0.4733360707759857\n",
      "18 0.4695501923561096\n",
      "19 0.4637535512447357\n",
      "20 0.45898184180259705\n",
      "21 0.4638995826244354\n",
      "22 0.46181520819664\n",
      "23 0.45905718207359314\n",
      "24 0.4582548141479492\n",
      "25 0.4599738121032715\n",
      "26 0.4607425630092621\n",
      "27 0.4603649079799652\n",
      "28 0.45913082361221313\n",
      "29 0.4578785300254822\n",
      "30 0.45815470814704895\n",
      "31 0.4586363732814789\n",
      "32 0.45890021324157715\n",
      "33 0.45894166827201843\n",
      "34 0.4587760269641876\n",
      "35 0.45843619108200073\n",
      "36 0.4579622447490692\n",
      "37 0.45766931772232056\n",
      "38 0.45772039890289307\n",
      "39 0.45840394496917725\n",
      "40 0.45841488242149353\n",
      "41 0.45773443579673767\n",
      "42 0.4576273560523987\n",
      "43 0.4575842022895813\n",
      "44 0.4578061103820801\n",
      "45 0.4579136073589325\n",
      "46 0.45782068371772766\n",
      "47 0.4575433135032654\n",
      "48 0.45749086141586304\n",
      "49 0.45749929547309875\n",
      "50 0.4574960768222809\n",
      "51 0.4576827585697174\n",
      "52 0.45743900537490845\n",
      "53 0.45738962292671204\n",
      "54 0.45733457803726196\n",
      "55 0.4572731554508209\n",
      "56 0.4572329521179199\n",
      "57 0.4572013318538666\n",
      "58 0.4571261405944824\n",
      "59 0.45700183510780334\n",
      "60 0.4568931758403778\n",
      "61 0.4567906856536865\n",
      "62 0.45667362213134766\n",
      "63 0.45663511753082275\n",
      "64 0.45642542839050293\n",
      "65 0.45630350708961487\n",
      "66 0.45629698038101196\n",
      "67 0.4559468924999237\n",
      "68 0.45574626326560974\n",
      "69 0.45557650923728943\n",
      "70 0.4553174078464508\n",
      "71 0.45507949590682983\n",
      "72 0.4548107385635376\n",
      "73 0.45454466342926025\n",
      "74 0.4541761577129364\n",
      "75 0.4538174867630005\n",
      "76 0.45347774028778076\n",
      "77 0.4530216455459595\n",
      "78 0.45298534631729126\n",
      "79 0.45213913917541504\n",
      "80 0.45385727286338806\n",
      "81 0.45176833868026733\n",
      "82 0.45203477144241333\n",
      "83 0.4503920376300812\n",
      "84 0.4527197778224945\n",
      "85 0.449431449174881\n",
      "86 0.4499281346797943\n",
      "87 0.4492611289024353\n",
      "88 0.44939032196998596\n",
      "89 0.4485512971878052\n",
      "90 0.44908130168914795\n",
      "91 0.44807761907577515\n",
      "92 0.4495036005973816\n",
      "93 0.44784149527549744\n",
      "94 0.44823071360588074\n",
      "95 0.44806790351867676\n",
      "96 0.44802966713905334\n",
      "97 0.44970056414604187\n",
      "98 0.44831398129463196\n",
      "99 0.44941872358322144\n",
      "Distances:  tensor([0.6182, 0.4794, 0.3134, 0.6523, 0.5531, 0.5508, 0.5364, 0.5205, 0.9393,\n",
      "        1.0026, 0.5910, 0.9978, 0.5205, 0.6610, 0.4728, 0.5020, 0.3230, 0.4633,\n",
      "        0.4705, 0.4616, 0.5325, 0.8257, 0.9200, 0.5107, 0.8691, 0.5325, 0.6170,\n",
      "        0.6299, 0.8194, 0.6797, 0.6829, 0.6956, 0.5681, 1.2854, 1.2526, 0.7387,\n",
      "        1.2010, 0.5681, 0.7000, 0.6423, 0.5323, 0.5299, 0.5354, 0.5575, 0.9365,\n",
      "        0.9959, 0.5817, 0.9926, 0.5575, 0.6578, 0.4945, 0.4871, 0.4793, 0.5543,\n",
      "        0.8700, 0.9710, 0.5195, 0.9364, 0.5543, 0.6449, 0.3315, 0.3300, 0.5599,\n",
      "        1.0641, 1.1102, 0.3626, 1.1069, 0.5599, 0.7676, 0.3300, 0.5602, 1.0668,\n",
      "        1.1096, 0.3626, 1.1062, 0.5602, 0.7851, 0.5598, 1.0331, 1.1042, 0.3605,\n",
      "        1.1028, 0.5598, 0.7561, 1.6838, 1.6102, 0.9464, 1.6015, 0.4255, 1.1629,\n",
      "        0.4852, 0.6226, 0.4794, 0.9322, 0.4470, 0.6477, 0.2423, 0.9983, 0.4795,\n",
      "        1.2020, 0.5964, 0.7977, 0.9947, 0.4732, 1.1629], grad_fn=<CopySlices>)\n",
      "Loss Triangular: 0.006348885595798492\n",
      "node_costs :\n",
      "tensor([[0.0000, 0.0057, 0.0057, 0.0057, 0.0057, 0.0057, 0.0059, 0.0058, 0.0057,\n",
      "         0.0058, 0.0057, 0.0059, 0.0059, 0.0058, 0.0059, 0.0057, 0.0058, 0.0057,\n",
      "         0.0057],\n",
      "        [0.0057, 0.0000, 0.0056, 0.0057, 0.0058, 0.0057, 0.0059, 0.0059, 0.0057,\n",
      "         0.0057, 0.0058, 0.0057, 0.0058, 0.0057, 0.0059, 0.0057, 0.0057, 0.0058,\n",
      "         0.0057],\n",
      "        [0.0057, 0.0056, 0.0000, 0.0057, 0.0057, 0.0058, 0.0058, 0.0057, 0.0059,\n",
      "         0.0058, 0.0057, 0.0058, 0.0057, 0.0059, 0.0059, 0.0059, 0.0059, 0.0059,\n",
      "         0.0072],\n",
      "        [0.0057, 0.0057, 0.0057, 0.0000, 0.0059, 0.0058, 0.0057, 0.0057, 0.0058,\n",
      "         0.0059, 0.0058, 0.0058, 0.0072, 0.0058, 0.0057, 0.0059, 0.0057, 0.0059,\n",
      "         0.0057],\n",
      "        [0.0057, 0.0058, 0.0057, 0.0059, 0.0000, 0.0059, 0.0057, 0.0059, 0.0058,\n",
      "         0.0058, 0.0057, 0.0057, 0.0058, 0.0057, 0.0057, 0.0059, 0.0057, 0.0059,\n",
      "         0.0059],\n",
      "        [0.0057, 0.0057, 0.0058, 0.0058, 0.0059, 0.0000, 0.0058, 0.0058, 0.0058,\n",
      "         0.0058, 0.0059, 0.0058, 0.0059, 0.0057, 0.0059, 0.0057, 0.0058, 0.0059,\n",
      "         0.0059],\n",
      "        [0.0059, 0.0059, 0.0058, 0.0057, 0.0057, 0.0058, 0.0000, 0.0059, 0.0058,\n",
      "         0.0058, 0.0057, 0.0059, 0.0059, 0.0059, 0.0058, 0.0059, 0.0057, 0.0056,\n",
      "         0.0059],\n",
      "        [0.0058, 0.0059, 0.0057, 0.0057, 0.0059, 0.0058, 0.0059, 0.0000, 0.0057,\n",
      "         0.0057, 0.0059, 0.0057, 0.0059, 0.0057, 0.0059, 0.0058, 0.0058, 0.0058,\n",
      "         0.0058],\n",
      "        [0.0057, 0.0057, 0.0059, 0.0058, 0.0058, 0.0058, 0.0058, 0.0057, 0.0000,\n",
      "         0.0057, 0.0057, 0.0058, 0.0056, 0.0057, 0.0059, 0.0058, 0.0059, 0.0058,\n",
      "         0.0059],\n",
      "        [0.0058, 0.0057, 0.0058, 0.0059, 0.0058, 0.0058, 0.0058, 0.0057, 0.0057,\n",
      "         0.0000, 0.0058, 0.0072, 0.0057, 0.0059, 0.0059, 0.0059, 0.0057, 0.0059,\n",
      "         0.0058],\n",
      "        [0.0057, 0.0058, 0.0057, 0.0058, 0.0057, 0.0059, 0.0057, 0.0059, 0.0057,\n",
      "         0.0058, 0.0000, 0.0058, 0.0057, 0.0058, 0.0057, 0.0057, 0.0059, 0.0059,\n",
      "         0.0059],\n",
      "        [0.0059, 0.0057, 0.0058, 0.0058, 0.0057, 0.0058, 0.0059, 0.0057, 0.0058,\n",
      "         0.0072, 0.0058, 0.0000, 0.0057, 0.0058, 0.0058, 0.0057, 0.0072, 0.0057,\n",
      "         0.0058],\n",
      "        [0.0059, 0.0058, 0.0057, 0.0072, 0.0058, 0.0059, 0.0059, 0.0059, 0.0056,\n",
      "         0.0057, 0.0057, 0.0057, 0.0000, 0.0058, 0.0059, 0.0057, 0.0057, 0.0057,\n",
      "         0.0059],\n",
      "        [0.0058, 0.0057, 0.0059, 0.0058, 0.0057, 0.0057, 0.0059, 0.0057, 0.0057,\n",
      "         0.0059, 0.0058, 0.0058, 0.0058, 0.0000, 0.0059, 0.0059, 0.0057, 0.0057,\n",
      "         0.0059],\n",
      "        [0.0059, 0.0059, 0.0059, 0.0057, 0.0057, 0.0059, 0.0058, 0.0059, 0.0059,\n",
      "         0.0059, 0.0057, 0.0058, 0.0059, 0.0059, 0.0000, 0.0058, 0.0057, 0.0057,\n",
      "         0.0059],\n",
      "        [0.0057, 0.0057, 0.0059, 0.0059, 0.0059, 0.0057, 0.0059, 0.0058, 0.0058,\n",
      "         0.0059, 0.0057, 0.0057, 0.0057, 0.0059, 0.0058, 0.0000, 0.0058, 0.0058,\n",
      "         0.0059],\n",
      "        [0.0058, 0.0057, 0.0059, 0.0057, 0.0057, 0.0058, 0.0057, 0.0058, 0.0059,\n",
      "         0.0057, 0.0059, 0.0072, 0.0057, 0.0057, 0.0057, 0.0058, 0.0000, 0.0058,\n",
      "         0.0059],\n",
      "        [0.0057, 0.0058, 0.0059, 0.0059, 0.0059, 0.0059, 0.0056, 0.0058, 0.0058,\n",
      "         0.0059, 0.0059, 0.0057, 0.0057, 0.0057, 0.0057, 0.0058, 0.0058, 0.0000,\n",
      "         0.0058],\n",
      "        [0.0057, 0.0057, 0.0072, 0.0057, 0.0059, 0.0059, 0.0059, 0.0058, 0.0059,\n",
      "         0.0058, 0.0059, 0.0058, 0.0059, 0.0059, 0.0059, 0.0059, 0.0059, 0.0058,\n",
      "         0.0000]], grad_fn=<AddBackward0>)\n",
      "nodeInsDel: 0.0003196343604940921\n",
      "edge_costs :\n",
      "tensor([[0.0000e+00, 3.4722e-03, 6.1253e-08],\n",
      "        [3.4722e-03, 0.0000e+00, 3.3251e-05],\n",
      "        [6.1253e-08, 3.3251e-05, 0.0000e+00]], grad_fn=<AddBackward0>)\n",
      "edgeInsDel: 4.405786057759542e-06\n",
      "100 0.4487045109272003\n",
      "101 0.4482799470424652\n",
      "102 0.451363205909729\n",
      "103 0.44868919253349304\n",
      "104 0.45104333758354187\n",
      "105 0.451902836561203\n",
      "106 0.4481338560581207\n",
      "107 0.45080694556236267\n",
      "108 0.45061370730400085\n",
      "109 0.44808298349380493\n",
      "110 0.44967377185821533\n",
      "111 0.44889748096466064\n",
      "112 0.4479810297489166\n",
      "113 0.44814372062683105\n",
      "114 0.448529988527298\n",
      "115 0.44810232520103455\n",
      "116 0.448934406042099\n",
      "117 0.449016273021698\n",
      "118 0.4480971693992615\n",
      "119 0.4480549693107605\n",
      "120 0.45057734847068787\n",
      "121 0.4490058422088623\n",
      "122 0.448349267244339\n",
      "123 0.4514278471469879\n",
      "124 0.4492295980453491\n",
      "125 0.448056161403656\n",
      "126 0.45153918862342834\n",
      "127 0.45200732350349426\n",
      "128 0.449069082736969\n",
      "129 0.4486260712146759\n",
      "130 0.45273661613464355\n",
      "131 0.45107951760292053\n",
      "132 0.44798338413238525\n",
      "133 0.44940808415412903\n",
      "134 0.44991838932037354\n",
      "135 0.4481251835823059\n",
      "136 0.44810083508491516\n",
      "137 0.44852301478385925\n",
      "138 0.4487336277961731\n",
      "139 0.4483633041381836\n",
      "140 0.4480198621749878\n",
      "141 0.448110967874527\n",
      "142 0.4481774568557739\n",
      "143 0.44860485196113586\n",
      "144 0.4480690062046051\n",
      "145 0.44833850860595703\n",
      "146 0.4488470256328583\n",
      "147 0.4487449526786804\n",
      "148 0.4482015073299408\n",
      "149 0.4480939209461212\n",
      "150 0.44833579659461975\n",
      "151 0.4481801986694336\n",
      "152 0.44813916087150574\n",
      "153 0.4480881094932556\n",
      "154 0.4480268061161041\n",
      "155 0.4480976462364197\n",
      "156 0.44811129570007324\n",
      "157 0.44799748063087463\n",
      "158 0.4480270743370056\n",
      "159 0.44803911447525024\n",
      "160 0.44803541898727417\n",
      "161 0.4480177164077759\n",
      "162 0.4479866623878479\n",
      "163 0.447944700717926\n",
      "164 0.4479638636112213\n",
      "165 0.44796648621559143\n",
      "166 0.44798821210861206\n",
      "167 0.44799262285232544\n",
      "168 0.44798147678375244\n",
      "169 0.4479560852050781\n",
      "170 0.44791722297668457\n",
      "171 0.44792571663856506\n",
      "172 0.4478783905506134\n",
      "173 0.4478735625743866\n",
      "174 0.4478611350059509\n",
      "175 0.44785571098327637\n",
      "176 0.4478413760662079\n",
      "177 0.4478759765625\n",
      "178 0.4478457570075989\n",
      "179 0.447859525680542\n",
      "180 0.44785481691360474\n",
      "181 0.44783368706703186\n",
      "182 0.44779688119888306\n",
      "183 0.44785672426223755\n",
      "184 0.4477677047252655\n",
      "185 0.44780033826828003\n",
      "186 0.4478163719177246\n",
      "187 0.4478132724761963\n",
      "188 0.44779255986213684\n",
      "189 0.44775575399398804\n",
      "190 0.44771531224250793\n",
      "191 0.4477463960647583\n",
      "192 0.4477221965789795\n",
      "193 0.4477420449256897\n",
      "194 0.44774124026298523\n",
      "195 0.4477217197418213\n",
      "196 0.4476846158504486\n",
      "197 0.44765910506248474\n",
      "198 0.44770547747612\n",
      "199 0.4476511478424072\n",
      "Distances:  tensor([0.5814, 0.4518, 0.2960, 0.6183, 0.5258, 0.5233, 0.5102, 0.4916, 0.8682,\n",
      "        0.9221, 0.5668, 0.9166, 0.4916, 0.6259, 0.4433, 0.4761, 0.3074, 0.4354,\n",
      "        0.4418, 0.4329, 0.4991, 0.7667, 0.8506, 0.4853, 0.7996, 0.4991, 0.5911,\n",
      "        0.5873, 0.7674, 0.6412, 0.6447, 0.6591, 0.5428, 1.1826, 1.1471, 0.7053,\n",
      "        1.1000, 0.5428, 0.6598, 0.6074, 0.5074, 0.5049, 0.5094, 0.5244, 0.8659,\n",
      "        0.9158, 0.5580, 0.9116, 0.5244, 0.6225, 0.4692, 0.4627, 0.4548, 0.5240,\n",
      "        0.8186, 0.9043, 0.4982, 0.8678, 0.5240, 0.6237, 0.3147, 0.3134, 0.5297,\n",
      "        0.9909, 1.0120, 0.3483, 1.0085, 0.5297, 0.7238, 0.3134, 0.5299, 0.9939,\n",
      "        1.0115, 0.3483, 1.0079, 0.5299, 0.7427, 0.5299, 0.9646, 1.0068, 0.3465,\n",
      "        1.0049, 0.5299, 0.7125, 1.5602, 1.4732, 0.9014, 1.4639, 0.4127, 1.0890,\n",
      "        0.4653, 0.5820, 0.4591, 0.8561, 0.4250, 0.5991, 0.2277, 0.9111, 0.4527,\n",
      "        1.1112, 0.5699, 0.7567, 0.9073, 0.4460, 1.0890], grad_fn=<CopySlices>)\n",
      "Loss Triangular: 0.006489003077149391\n",
      "node_costs :\n",
      "tensor([[0.0000, 0.0057, 0.0057, 0.0057, 0.0057, 0.0057, 0.0059, 0.0058, 0.0057,\n",
      "         0.0058, 0.0057, 0.0059, 0.0059, 0.0058, 0.0059, 0.0057, 0.0058, 0.0057,\n",
      "         0.0057],\n",
      "        [0.0057, 0.0000, 0.0056, 0.0057, 0.0057, 0.0057, 0.0059, 0.0059, 0.0057,\n",
      "         0.0057, 0.0058, 0.0057, 0.0058, 0.0057, 0.0059, 0.0057, 0.0057, 0.0058,\n",
      "         0.0057],\n",
      "        [0.0057, 0.0056, 0.0000, 0.0057, 0.0057, 0.0058, 0.0058, 0.0057, 0.0059,\n",
      "         0.0058, 0.0057, 0.0058, 0.0057, 0.0059, 0.0059, 0.0059, 0.0059, 0.0059,\n",
      "         0.0071],\n",
      "        [0.0057, 0.0057, 0.0057, 0.0000, 0.0059, 0.0058, 0.0057, 0.0057, 0.0058,\n",
      "         0.0059, 0.0058, 0.0058, 0.0071, 0.0058, 0.0057, 0.0059, 0.0057, 0.0058,\n",
      "         0.0057],\n",
      "        [0.0057, 0.0057, 0.0057, 0.0059, 0.0000, 0.0059, 0.0057, 0.0059, 0.0058,\n",
      "         0.0058, 0.0057, 0.0057, 0.0058, 0.0057, 0.0057, 0.0059, 0.0057, 0.0059,\n",
      "         0.0059],\n",
      "        [0.0057, 0.0057, 0.0058, 0.0058, 0.0059, 0.0000, 0.0058, 0.0057, 0.0058,\n",
      "         0.0058, 0.0059, 0.0058, 0.0059, 0.0057, 0.0059, 0.0057, 0.0058, 0.0059,\n",
      "         0.0059],\n",
      "        [0.0059, 0.0059, 0.0058, 0.0057, 0.0057, 0.0058, 0.0000, 0.0059, 0.0058,\n",
      "         0.0058, 0.0057, 0.0059, 0.0059, 0.0059, 0.0058, 0.0059, 0.0057, 0.0056,\n",
      "         0.0059],\n",
      "        [0.0058, 0.0059, 0.0057, 0.0057, 0.0059, 0.0057, 0.0059, 0.0000, 0.0057,\n",
      "         0.0057, 0.0058, 0.0057, 0.0059, 0.0057, 0.0059, 0.0058, 0.0058, 0.0058,\n",
      "         0.0058],\n",
      "        [0.0057, 0.0057, 0.0059, 0.0058, 0.0058, 0.0058, 0.0058, 0.0057, 0.0000,\n",
      "         0.0057, 0.0057, 0.0058, 0.0056, 0.0057, 0.0059, 0.0058, 0.0059, 0.0058,\n",
      "         0.0059],\n",
      "        [0.0058, 0.0057, 0.0058, 0.0059, 0.0058, 0.0058, 0.0058, 0.0057, 0.0057,\n",
      "         0.0000, 0.0058, 0.0071, 0.0057, 0.0059, 0.0059, 0.0059, 0.0057, 0.0059,\n",
      "         0.0058],\n",
      "        [0.0057, 0.0058, 0.0057, 0.0058, 0.0057, 0.0059, 0.0057, 0.0058, 0.0057,\n",
      "         0.0058, 0.0000, 0.0058, 0.0057, 0.0058, 0.0057, 0.0057, 0.0059, 0.0059,\n",
      "         0.0059],\n",
      "        [0.0059, 0.0057, 0.0058, 0.0058, 0.0057, 0.0058, 0.0059, 0.0057, 0.0058,\n",
      "         0.0071, 0.0058, 0.0000, 0.0057, 0.0058, 0.0058, 0.0057, 0.0071, 0.0057,\n",
      "         0.0058],\n",
      "        [0.0059, 0.0058, 0.0057, 0.0071, 0.0058, 0.0059, 0.0059, 0.0059, 0.0056,\n",
      "         0.0057, 0.0057, 0.0057, 0.0000, 0.0058, 0.0059, 0.0057, 0.0057, 0.0057,\n",
      "         0.0059],\n",
      "        [0.0058, 0.0057, 0.0059, 0.0058, 0.0057, 0.0057, 0.0059, 0.0057, 0.0057,\n",
      "         0.0059, 0.0058, 0.0058, 0.0058, 0.0000, 0.0059, 0.0059, 0.0057, 0.0057,\n",
      "         0.0059],\n",
      "        [0.0059, 0.0059, 0.0059, 0.0057, 0.0057, 0.0059, 0.0058, 0.0059, 0.0059,\n",
      "         0.0059, 0.0057, 0.0058, 0.0059, 0.0059, 0.0000, 0.0058, 0.0057, 0.0057,\n",
      "         0.0059],\n",
      "        [0.0057, 0.0057, 0.0059, 0.0059, 0.0059, 0.0057, 0.0059, 0.0058, 0.0058,\n",
      "         0.0059, 0.0057, 0.0057, 0.0057, 0.0059, 0.0058, 0.0000, 0.0058, 0.0058,\n",
      "         0.0059],\n",
      "        [0.0058, 0.0057, 0.0059, 0.0057, 0.0057, 0.0058, 0.0057, 0.0058, 0.0059,\n",
      "         0.0057, 0.0059, 0.0071, 0.0057, 0.0057, 0.0057, 0.0058, 0.0000, 0.0058,\n",
      "         0.0059],\n",
      "        [0.0057, 0.0058, 0.0059, 0.0058, 0.0059, 0.0059, 0.0056, 0.0058, 0.0058,\n",
      "         0.0059, 0.0059, 0.0057, 0.0057, 0.0057, 0.0057, 0.0058, 0.0058, 0.0000,\n",
      "         0.0058],\n",
      "        [0.0057, 0.0057, 0.0071, 0.0057, 0.0059, 0.0059, 0.0059, 0.0058, 0.0059,\n",
      "         0.0058, 0.0059, 0.0058, 0.0059, 0.0059, 0.0059, 0.0059, 0.0059, 0.0058,\n",
      "         0.0000]], grad_fn=<AddBackward0>)\n",
      "nodeInsDel: 0.00037074220017530024\n",
      "edge_costs :\n",
      "tensor([[0.0000e+00, 4.2283e-03, 2.8105e-13],\n",
      "        [4.2283e-03, 0.0000e+00, 9.1685e-11],\n",
      "        [2.8105e-13, 9.1685e-11, 0.0000e+00]], grad_fn=<AddBackward0>)\n",
      "edgeInsDel: 3.1919525356194356e-10\n"
     ]
    }
   ],
   "source": [
    "#if torch.cuda.device_count() > 1:\n",
    "#  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "#  model = nn.DataParallel(model)\n",
    "from triangular_losses import TriangularConstraint as triangular_constraint\n",
    "model.to(device)\n",
    "def classification(model,data,yt,nb_iter):\n",
    "\n",
    "    criterion = torch.nn.HingeEmbeddingLoss(margin=1.0)\n",
    "    criterionTri=triangular_constraint()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    print(device)\n",
    "\n",
    "#torch.cat((same_class[0:20],diff_class[0:20]),0).to(device)\n",
    "    input=data.to(device)\n",
    "    target=yt.to(device) \n",
    "#torch.ones(40,device=device)\n",
    "#target[20:]=-1.0\n",
    "#target=(yt[0:20]).to(device)\n",
    "    InsDel=np.empty((nb_iter,2))\n",
    "    node_costs,nodeInsDel,edge_costs,edgeInsDel=model.from_weighs_to_costs()\n",
    "    nodeSub=np.empty((nb_iter,int(node_costs.shape[0]*(node_costs.shape[0]-1)/2)))\n",
    "    edgeSub=np.empty((nb_iter,int(edge_costs.shape[0]*(edge_costs.shape[0]-1)/2)))\n",
    "    loss_plt=np.empty(nb_iter)\n",
    "    for t in range(nb_iter):    \n",
    "        # Forward pass: Compute predicted y by passing data to the model    \n",
    "\n",
    "\n",
    "        y_pred = model(input).to(device)\n",
    "    \n",
    "    \n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, target).to(device)    \n",
    "        node_costs,nodeInsDel,edge_costs,edgeInsDel=model.from_weighs_to_costs()\n",
    "        triangularInq=criterionTri(node_costs,nodeInsDel,edge_costs,edgeInsDel)\n",
    "        loss=loss*(1+triangularInq)\n",
    "        loss.to(device)\n",
    "        InsDel[t][0]=nodeInsDel.item()\n",
    "        InsDel[t][1]=edgeInsDel.item()\n",
    "        loss_plt[t]=loss.item()\n",
    "        print(t, loss.item())  \n",
    "        k=0\n",
    "        for p in range(node_costs.shape[0]):\n",
    "            for q in range(p+1,node_costs.shape[0]):\n",
    "                nodeSub[t][k]=node_costs[p][q]\n",
    "                k=k+1\n",
    "        k=0\n",
    "        for p in range(edge_costs.shape[0]):\n",
    "            for q in range(p+1,edge_costs.shape[0]):\n",
    "                edgeSub[t][k]=edge_costs[p][q]\n",
    "                k=k+1\n",
    "        if t % 100 == 99 or t==0:                         \n",
    "            print('Distances: ',y_pred)\n",
    "            print('Loss Triangular:',triangularInq.item())\n",
    "            print('node_costs :')\n",
    "            print(node_costs)\n",
    "            print('nodeInsDel:',nodeInsDel.item())\n",
    "            print('edge_costs :')\n",
    "            print(edge_costs)\n",
    "            print('edgeInsDel:',edgeInsDel.item())\n",
    "        \n",
    "        \n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return InsDel,nodeSub,edgeSub,loss_plt\n",
    "\n",
    "nb_iter=200\n",
    "InsDel, nodeSub,edgeSub,loss_plt=classification(model,data,yt,nb_iter)\n",
    "plt.figure(0)\n",
    "plt.plot(InsDel[0:nb_iter,0],label=\"node\")\n",
    "plt.plot(InsDel[0:nb_iter,1],label=\"edge\")\n",
    "plt.title('Node/Edge insertion/deletion costs')\n",
    "plt.legend()\n",
    "plt.figure(1)\n",
    "for k in range(nodeSub.shape[1]):\n",
    "    plt.plot(nodeSub[0:nb_iter,k])\n",
    "plt.title('Node Substitutions costs')\n",
    "plt.figure(2)\n",
    "for k in range(edgeSub.shape[1]):\n",
    "    plt.plot(edgeSub[0:nb_iter,k])\n",
    "plt.title('Edge Substitutions costs')\n",
    "plt.figure(3)\n",
    "plt.plot(loss_plt)\n",
    "plt.title('Evolution of the loss')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "A=torch.tensor(nx.to_scipy_sparse_matrix(Gs[0],dtype=int,weight='bond_type').todense(),dtype=torch.int) \n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.plot(InsDel[0:500,0],label=\"node\")\n",
    "plt.plot(InsDel[0:500,1],label=\"edge\")\n",
    "plt.title('Node/Edge insertion/deletion costs')\n",
    "plt.legend()\n",
    "plt.figure(1)\n",
    "for k in range(nodeSub.shape[1]):\n",
    "    plt.plot(nodeSub[0:500,k])\n",
    "plt.title('node Substitution costs')\n",
    "plt.figure(2)\n",
    "for k in range(edgeSub.shape[1]):\n",
    "    plt.plot(edgeSub[0:500,k])\n",
    "plt.title('edge Substitution costs')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
