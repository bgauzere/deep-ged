{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gklearn.utils.graphfiles import loadDataset\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge max label 3\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "def label_to_color(label):\n",
    "    if label == 'C':\n",
    "        return 0.1\n",
    "    elif label == 'O':\n",
    "        return 0.8\n",
    "    \n",
    "def nodes_to_color_sequence(G):\n",
    "    return [label_to_color(c[1]['label'][0]) for c in G.nodes(data=True)]\n",
    "\n",
    "Gs,y = loadDataset('/home/ines/Documents/M2/Stage/stage_ged/Ines/DeepGED/MAO/dataset.ds')\n",
    "#for e in Gs[13].edges():\n",
    "#    print(Gs[13][e[0]][e[1]]['bond_type'])\n",
    "print('edge max label',max(max([[G[e[0]][e[1]]['bond_type'] for e in G.edges()] for G in Gs])))\n",
    "G1 = Gs[1]\n",
    "G2 = Gs[9]\n",
    "print(y[1],y[9])\n",
    "plt.figure(0)\n",
    "nx.draw_networkx(G1,with_labels=True,node_color = nodes_to_color_sequence(G1),cmap='autumn')\n",
    "\n",
    "plt.figure(1)\n",
    "nx.draw_networkx(G2,with_labels=True,node_color = nodes_to_color_sequence(G2),cmap='autumn')\n",
    "\n",
    "plt.show()\n",
    "import extended_label\n",
    "for g in Gs:\n",
    "    extended_label.compute_extended_labels(g)\n",
    "#for v in Gs[10].nodes():\n",
    "#        print(Gs[10].nodes[v])\n",
    "\n",
    "#print(nx.to_dict_of_lists(Gs[13]))\n",
    "\n",
    "\n",
    "\n",
    "#dict={'C':0,'N':1,'O':2}\n",
    "#A,labels=from_networkx_to_tensor2(Gs[13],dict)\n",
    "#print(A)\n",
    "#A1=(A==torch.ones(13,13)).int()\n",
    "#A2=(A==2*torch.ones(13,13)).int()\n",
    "#print(A1)\n",
    "#print(A2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gs= 68\n",
      "['C_1C', 'C_1C1C1N', 'C_1C1C2C', 'C_1C1N', 'C_1C1N2C', 'C_1C1O', 'C_1C1O2C', 'C_1C2C', 'C_1C3C', 'C_1N', 'C_1O', 'C_2C', 'C_2C2C', 'C_3C', 'N_1C', 'N_1C1C', 'N_1C1C1C', 'O_1C', 'O_1C1C']\n",
      "{'C_1C': 0, 'C_1C1C1N': 1, 'C_1C1C2C': 2, 'C_1C1N': 3, 'C_1C1N2C': 4, 'C_1C1O': 5, 'C_1C1O2C': 6, 'C_1C2C': 7, 'C_1C3C': 8, 'C_1N': 9, 'C_1O': 10, 'C_2C': 11, 'C_2C2C': 12, 'C_3C': 13, 'N_1C': 14, 'N_1C1C': 15, 'N_1C1C1C': 16, 'O_1C': 17, 'O_1C1C': 18} 19\n",
      "3\n",
      "torch.Size([68, 729])\n",
      "adjacency matrices tensor([[          0,           1,           0,  ..., -1960201184,\n",
      "               32729,   565413936],\n",
      "        [          0,           1,           0,  ...,       32729,\n",
      "         -1889688488,       32729],\n",
      "        [          0,           1,           0,  ...,   975793452,\n",
      "           538976266,   538976288],\n",
      "        ...,\n",
      "        [          0,           1,           0,  ...,           0,\n",
      "                   0,           0],\n",
      "        [          0,           1,           0,  ...,           0,\n",
      "                   0,           0],\n",
      "        [          0,           1,           0,  ...,           0,\n",
      "                   0,           0]], dtype=torch.int32)\n",
      "node labels tensor([[         15,           4,           7,  ...,           1,\n",
      "                   0,         216],\n",
      "        [         15,           4,           7,  ...,           0,\n",
      "           643919600,       32729],\n",
      "        [         15,           4,           7,  ...,  1332066176,\n",
      "                   0,           0],\n",
      "        ...,\n",
      "        [         16,           4,           7,  ...,           0,\n",
      "                  26,          18],\n",
      "        [         16,           4,           7,  ...,           0,\n",
      "                   0,           0],\n",
      "        [         16,           4,           7,  ...,  1814980707,\n",
      "         -1889677496,       32729]], dtype=torch.int32)\n",
      "order of the graphs tensor([11, 12, 14, 14, 15, 17, 15, 16, 19, 15, 16, 19, 12, 13, 15, 18, 16, 16,\n",
      "        17, 16, 17, 17, 18, 19, 19, 18, 18, 22, 22, 15, 14, 13, 16, 17, 17, 21,\n",
      "        17, 18, 18, 21, 24, 25, 25, 14, 17, 18, 18, 22, 23, 23, 25, 27, 27, 15,\n",
      "        16, 23, 24, 24, 16, 17, 17, 20, 23, 24, 26, 16, 17, 21])\n",
      "2\n",
      "Parameter containing:\n",
      "tensor([0.0058, 0.0062, 0.0060, 0.0057, 0.0057, 0.0067, 0.0062, 0.0060, 0.0062,\n",
      "        0.0058, 0.0063, 0.0066, 0.0066, 0.0058, 0.0064, 0.0058, 0.0062, 0.0064,\n",
      "        0.0062, 0.0062, 0.0062, 0.0067, 0.0059, 0.0060, 0.0058, 0.0065, 0.0058,\n",
      "        0.0065, 0.0059, 0.0059, 0.0057, 0.0063, 0.0065, 0.0060, 0.0058, 0.0063,\n",
      "        0.0065, 0.0062, 0.0064, 0.0060, 0.0057, 0.0059, 0.0059, 0.0065, 0.0061,\n",
      "        0.0058, 0.0066, 0.0064, 0.0062, 0.0062, 0.0062, 0.0065, 0.0059, 0.0059,\n",
      "        0.0066, 0.0063, 0.0065, 0.0062, 0.0064, 0.0058, 0.0066, 0.0059, 0.0060,\n",
      "        0.0057, 0.0066, 0.0065, 0.0060, 0.0061, 0.0061, 0.0066, 0.0066, 0.0064,\n",
      "        0.0059, 0.0058, 0.0064, 0.0061, 0.0059, 0.0061, 0.0066, 0.0060, 0.0058,\n",
      "        0.0057, 0.0065, 0.0064, 0.0064, 0.0065, 0.0061, 0.0066, 0.0066, 0.0065,\n",
      "        0.0065, 0.0065, 0.0064, 0.0065, 0.0065, 0.0062, 0.0058, 0.0064, 0.0061,\n",
      "        0.0066, 0.0060, 0.0059, 0.0066, 0.0061, 0.0058, 0.0060, 0.0059, 0.0057,\n",
      "        0.0067, 0.0060, 0.0062, 0.0060, 0.0065, 0.0066, 0.0059, 0.0060, 0.0062,\n",
      "        0.0061, 0.0061, 0.0065, 0.0057, 0.0061, 0.0064, 0.0064, 0.0067, 0.0060,\n",
      "        0.0061, 0.0059, 0.0063, 0.0063, 0.0066, 0.0066, 0.0062, 0.0061, 0.0064,\n",
      "        0.0063, 0.0059, 0.0061, 0.0057, 0.0057, 0.0066, 0.0062, 0.0066, 0.0057,\n",
      "        0.0061, 0.0062, 0.0060, 0.0065, 0.0058, 0.0057, 0.0060, 0.0064, 0.0064,\n",
      "        0.0060, 0.0061, 0.0066, 0.0065, 0.0063, 0.0065, 0.0063, 0.0057, 0.0061,\n",
      "        0.0062, 0.0060, 0.0062, 0.0061, 0.0060, 0.0060, 0.0060, 0.0065, 0.0059,\n",
      "        0.0062], requires_grad=True)\n",
      "27 68\n",
      "toto\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import svd\n",
    "from svd import iterated_power as compute_major_axis\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "        \n",
    "    def __init__(self,GraphList,normalize=False,node_label='label'):\n",
    "        super(Net, self).__init__()   \n",
    "        self.normalize=normalize\n",
    "        self.node_label=node_label\n",
    "        dict,self.nb_edge_labels=self.build_node_dictionnary(GraphList)\n",
    "        self.nb_labels=len(dict)\n",
    "        print(self.nb_edge_labels)\n",
    "        self.device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        nb_node_pair_label=self.nb_labels*(self.nb_labels-1)/2.0\n",
    "        nb_edge_pair_label=int(self.nb_edge_labels*(self.nb_edge_labels-1)/2)\n",
    "        \n",
    "        self.node_weighs=nn.Parameter(torch.tensor(1.0/(nb_node_pair_label+nb_edge_pair_label+2))+(1e-3)*torch.rand(int(self.nb_labels*(self.nb_labels-1)/2+1),requires_grad=True,device=self.device)) # all substitution costs+ nodeIns/Del. old version: 0 node subs, 1 nodeIns/Del, 2 : edgeSubs, 3 edgeIns/Del        \n",
    "        self.edge_weighs=nn.Parameter(torch.tensor(1.0/(nb_node_pair_label+nb_edge_pair_label+2))+(1e-3)*torch.rand(nb_edge_pair_label+1,requires_grad=True,device=self.device)) #edgeIns/Del\n",
    "        \n",
    "        self.card=torch.tensor([G.order() for G in GraphList]).to(self.device)\n",
    "        card_max=self.card.max()\n",
    "        self.A=torch.empty((len(GraphList),card_max*card_max),dtype=torch.int,device=self.device)\n",
    "        self.labels=torch.empty((len(GraphList),card_max),dtype=torch.int,device=self.device)\n",
    "        print(self.A.shape)\n",
    "        for k in range(len(GraphList)):\n",
    "            A,l=self.from_networkx_to_tensor(GraphList[k],dict)             \n",
    "            self.A[k,0:A.shape[1]]=A[0]\n",
    "            self.labels[k,0:l.shape[0]]=l\n",
    "        print('adjacency matrices',self.A)\n",
    "        print('node labels',self.labels)\n",
    "        print('order of the graphs',self.card)\n",
    "        \n",
    "    def forward(self, input):        \n",
    "        ged=torch.zeros(len(input)).to(self.device) \n",
    "        node_costs,nodeInsDel,edge_costs,edgeInsDel=self.from_weighs_to_costs()\n",
    "        \n",
    "            \n",
    "        \n",
    "        #print('weighs:',self.weighs.device,'device:',self.device,'card:',self.card.device,'A:',self.A.device,'labels:',self.labels.device)\n",
    "        for k in range(len(input)):            \n",
    "            g1=input[k][0]\n",
    "            g2=input[k][1]\n",
    "            n=self.card[g1]\n",
    "            m=self.card[g2]\n",
    "            C=self.construct_cost_matrix(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)      \n",
    "            #S=self.mapping_from_similarity(C,n,m)\n",
    "            S=self.mapping_from_cost(C,n,m)            \n",
    "            v=torch.flatten(S)\n",
    "            \n",
    "            normalize_factor=1.0\n",
    "            if self.normalize:\n",
    "                nb_edge1=(self.A[g1][0:n*n] != torch.zeros(n*n,device=self.device)).int().sum()\n",
    "                nb_edge2=(self.A[g2][0:m*m] != torch.zeros(m*m,device=self.device)).int().sum()\n",
    "                normalize_factor=nodeInsDel*(n+m)+edgeInsDel*(nb_edge1+nb_edge2)\n",
    "            c=torch.diag(C)\n",
    "            D=C-torch.eye(C.shape[0],device=self.device)*c\n",
    "            ged[k]=(.5*v.T@D@v+c.T@v)/normalize_factor\n",
    "        max=torch.max(ged)\n",
    "        min=torch.min(ged)\n",
    "        ged=(ged-min)/(max-min)\n",
    "        \n",
    "        return ged\n",
    "    \n",
    "    def from_weighs_to_costs(self):\n",
    "        \n",
    "        #cn=torch.exp(self.node_weighs)\n",
    "        #ce=torch.exp(self.edge_weighs)\n",
    "        cn=self.node_weighs*self.node_weighs\n",
    "        ce=self.edge_weighs*self.edge_weighs\n",
    "        total_cost=cn.sum()+ce.sum()\n",
    "        cn=cn/total_cost\n",
    "        ce=ce/total_cost\n",
    "        edgeInsDel=ce[-1]\n",
    "\n",
    "        node_costs=torch.zeros((self.nb_labels,self.nb_labels),device=self.device)\n",
    "        upper_part=torch.triu_indices(node_costs.shape[0],node_costs.shape[1],offset=1,device=self.device)        \n",
    "        node_costs[upper_part[0],upper_part[1]]=cn[0:-1]\n",
    "        node_costs=node_costs+node_costs.T\n",
    "\n",
    "        if self.nb_edge_labels>1:\n",
    "            edge_costs=torch.zeros((self.nb_edge_labels,self.nb_edge_labels),device=self.device)\n",
    "            upper_part=torch.triu_indices(edge_costs.shape[0],edge_costs.shape[1],offset=1,device=self.device)        \n",
    "            edge_costs[upper_part[0],upper_part[1]]=ce[0:-1]\n",
    "            edge_costs=edge_costs+edge_costs.T\n",
    "        else:\n",
    "            edge_costs=torch.zeros(0,device=self.device)\n",
    "        \n",
    "        return node_costs,cn[-1],edge_costs,edgeInsDel\n",
    "    \n",
    "    def build_node_dictionnary(self,GraphList):\n",
    "        #extraction de tous les labels d'atomes\n",
    "        node_labels=[]\n",
    "        for G in Gs:\n",
    "            for v in nx.nodes(G):\n",
    "                if not G.nodes[v][self.node_label][0] in node_labels:\n",
    "                    node_labels.append(G.nodes[v][self.node_label][0])\n",
    "        node_labels.sort()\n",
    "        #extraction d'un dictionnaire permettant de numéroter chaque label par un numéro.\n",
    "        dict={}\n",
    "        k=0\n",
    "        for label in node_labels:\n",
    "            dict[label]=k\n",
    "            k=k+1\n",
    "        print(node_labels)\n",
    "        print(dict,len(dict))\n",
    "    \n",
    "        return dict,max(max([[int(G[e[0]][e[1]]['bond_type']) for e in G.edges()] for G in GraphList]))\n",
    "    \n",
    "    def from_networkx_to_tensor(self,G,dict):    \n",
    "        A=torch.tensor(nx.to_scipy_sparse_matrix(G,dtype=int,weight='bond_type').todense(),dtype=torch.int)        \n",
    "        lab=[dict[G.nodes[v][self.node_label][0]] for v in nx.nodes(G)]\n",
    "   \n",
    "        return (A.view(1,A.shape[0]*A.shape[1]),torch.tensor(lab))\n",
    "\n",
    "    def construct_cost_matrix(self,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel):\n",
    "        n = self.card[g1].item()\n",
    "        m = self.card[g2].item()\n",
    "        \n",
    "        A1=torch.zeros((n+1,n+1),dtype=torch.int,device=self.device)\n",
    "        A1[0:n,0:n]=self.A[g1][0:n*n].view(n,n)\n",
    "        A2=torch.zeros((m+1,m+1),dtype=torch.int,device=self.device)\n",
    "        A2[0:m,0:m]=self.A[g2][0:m*m].view(m,m)\n",
    "        \n",
    "        \n",
    "         # costs: 0 node subs, 1 nodeIns/Del, 2 : edgeSubs, 3 edgeIns/Del\n",
    "        \n",
    "        #C=cost[3]*torch.cat([torch.cat([C12[l][k] for k in range(n+1)],1) for l in range(n+1)])\n",
    "        #Pas bien sur mais cela semble fonctionner.\n",
    "        C=edgeInsDel*self.matrix_edgeInsDel(A1,A2)\n",
    "        if self.nb_edge_labels>1:\n",
    "            for k in range(self.nb_edge_labels):\n",
    "                for l in range(self.nb_edge_labels):\n",
    "                    if k != l:\n",
    "#                    C.add_(self.matrix_edgeSubst(A1,A2,k+1,l+1),alpha=edge_costs[k][l])\n",
    "                        C=C+edge_costs[k][l]*self.matrix_edgeSubst(A1,A2,k+1,l+1)\n",
    "        #C=cost[3]*torch.tensor(np.array([ [  k!=l and A1[k//(m+1),l//(m+1)]^A2[k%(m+1),l%(m+1)] for k in range((n+1)*(m+1))] for l in range((n+1)*(m+1))]),device=self.device)        \n",
    "\n",
    "        l1=self.labels[g1][0:n]\n",
    "        l2=self.labels[g2][0:m]\n",
    "        D=torch.zeros((n+1)*(m+1),device=self.device)\n",
    "        D[n*(m+1):]=nodeInsDel\n",
    "        D[n*(m+1)+m]=0\n",
    "        D[[i*(m+1)+m for i in range(n)]]=nodeInsDel\n",
    "        D[[k for k in range(n*(m+1)) if k%(m+1) != m]]=torch.tensor([node_costs[l1[k//(m+1)],l2[k%(m+1)]] for k in range(n*(m+1)) if k%(m+1) != m],device=self.device )\n",
    "        mask = torch.diag(torch.ones_like(D))\n",
    "        C=mask*torch.diag(D) + (1. - mask)*C\n",
    "        \n",
    "        #C[range(len(C)),range(len(C))]=D\n",
    "      \n",
    "        return C\n",
    "    def matrix_edgeInsDel(self,A1,A2):\n",
    "        Abin1=(A1!=torch.zeros((A1.shape[0],A1.shape[1]),device=self.device))\n",
    "        Abin2=(A2!=torch.zeros((A2.shape[0],A2.shape[1]),device=self.device))\n",
    "        C1=torch.einsum('ij,kl->ijkl',torch.logical_not(Abin1),Abin2)\n",
    "        C2=torch.einsum('ij,kl->ijkl',Abin1,torch.logical_not(Abin2))\n",
    "        C12=torch.logical_or(C1,C2).int()\n",
    "    \n",
    "        return torch.cat(torch.unbind(torch.cat(torch.unbind(C12,1),1),0),1)\n",
    "\n",
    "    def matrix_edgeSubst(self,A1,A2,lab1,lab2):\n",
    "        Abin1=(A1==lab1*torch.ones((A1.shape[0],A1.shape[1]),device=self.device)).int()\n",
    "        Abin2=(A2==lab2*torch.ones((A2.shape[0],A2.shape[1]),device=self.device)).int()\n",
    "        C=torch.einsum('ij,kl->ijkl',Abin1,Abin2)\n",
    "        \n",
    "        return torch.cat(torch.unbind(torch.cat(torch.unbind(C,1),1),0),1)\n",
    "    \n",
    "    def similarity_from_cost(self,C):\n",
    "        N=C.shape[0]\n",
    "             \n",
    "        #return (torch.norm(C,p='fro')*torch.eye(N,device=self.device) -C)\n",
    "        return (C.max()*torch.eye(N,device=self.device) -C)\n",
    "    \n",
    "    def mapping_from_cost(self,C,n,m):\n",
    "        c=torch.diag(C)\n",
    "        D=C-torch.eye(C.shape[0],device=self.device)*c\n",
    "        x0=svd.eps_assigment_from_mapping(torch.exp(-.5*c.view(n+1,m+1)),10).view((n+1)*(m+1),1)\n",
    "        x=svd.franck_wolfe(x0,D,c,5,10,n,m)\n",
    "        def print_grad(grad):\n",
    "            if(grad.norm()!= 0.0):\n",
    "                print(grad)\n",
    "        \n",
    "#        x.register_hook(print_grad)\n",
    "        return x\n",
    "    \n",
    "    def mapping_from_similarity(self,C,n,m):\n",
    "        M=self.similarity_from_cost(C)\n",
    "        first_ev=compute_major_axis(M)\n",
    "        #first_ev=self.iterated_power(M,inv=True)\n",
    "        if(first_ev.sum() <0):\n",
    "            first_ev=-first_ev\n",
    "        S=torch.exp(first_ev.view(n+1,m+1)) # enforce the difference, accelerate the convergence. \n",
    "        S=self.eps_assigment_from_mapping(S)\n",
    "        return  S\n",
    "        \n",
    "    def eps_assigment_from_mapping(self,S):\n",
    "        ones_n = torch.ones(S.shape[0],device=S.device)\n",
    "        ones_m = torch.ones(S.shape[1],device=S.device)\n",
    "    \n",
    "        Sk = S\n",
    "        for i in range(20):\n",
    "            D=torch.diag(1.0/(Sk@ones_m))\n",
    "            D[D.shape[0]-1,D.shape[1]-1]=1.0\n",
    "            Sk1 = D@Sk\n",
    "            D=torch.diag(1.0/(ones_n@Sk1))\n",
    "            D[D.shape[0]-1,D.shape[1]-1]=1.0\n",
    "            Sk = Sk1@D\n",
    "        \n",
    "        return Sk\n",
    "\n",
    "print('Gs=',len(Gs))\n",
    "model = Net(Gs,normalize=True,node_label='extended_label')\n",
    "\n",
    "params = list(model.parameters())\n",
    "print(len(params))\n",
    "print(params[0])\n",
    "#print(model(input))\n",
    "print(max([G.order() for G in Gs]),len(Gs))\n",
    "print('toto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "nb=len(Gs)\n",
    "class1=torch.tensor([k for k in range(len(y)) if y[k]==1])\n",
    "class2=torch.tensor([k for k in range(len(y)) if y[k]==0])\n",
    "\n",
    "nb_class1=12\n",
    "nb_class2=int((nb_class1-1)/2)\n",
    "train_size=nb_class1+nb_class2\n",
    "#train_size=20\n",
    "\n",
    "#if train_size % 2 == 0:\n",
    "#    nb_class1=int(train_size/2)\n",
    "#    nb_class2=int(train_size/2)\n",
    "#else:\n",
    "#    nb_class1=int(train_size/2)+1\n",
    "#    nb_class2=int(train_size/2)\n",
    "    \n",
    "print((torch.abs(10000*torch.randn(nb_class1)).int()%class1.size()[0]).long())\n",
    "random_class1=class1[(torch.abs(10000*torch.randn(nb_class1)).int()%class1.size()[0]).long()]\n",
    "random_class2=class2[(torch.abs(10000*torch.randn(nb_class2)).int()%class2.size()[0]).long()]\n",
    "train_graphs=torch.cat((random_class1,random_class2),0)\n",
    "print('train graphs:',train_graphs)\n",
    "\n",
    "couples=torch.triu_indices(train_size,train_size,offset=1)\n",
    "print('couples=',couples)\n",
    "print('nb_class1/nb_class2=',nb_class1,nb_class2)\n",
    "#combinations=itertools.combinations(range(nb),2)\n",
    "\n",
    "nb_elt=int(nb_class1*(nb_class1+2*nb_class2-1)/2)\n",
    "print('couples restreints:',couples[:,0:nb_elt])\n",
    "\n",
    "#nb_elt=int(train_size*(train_size-1)/2)\n",
    "data=torch.empty((nb_elt,2),dtype=torch.int)\n",
    "yt=torch.ones(nb_elt)\n",
    "print('old_size, new size=',nb_elt,.5*nb_class1*(nb_class1+2*nb_class2-1))\n",
    "data[0:nb_elt,0]=train_graphs[couples[0,0:nb_elt]]\n",
    "data[0:nb_elt,1]=train_graphs[couples[1,0:nb_elt]]\n",
    "\n",
    "#data[0:nb_elt,0]=train_graphs[couples[0]]\n",
    "#data[0:nb_elt,1]=train_graphs[couples[1]]\n",
    "print(nb_elt)\n",
    "#couples=[]\n",
    "for k in range(nb_elt):\n",
    "    if (y[data[k][0]]!=y[data[k][1]]):\n",
    "        yt[k]=-1.0        \n",
    "\n",
    "print('data=',data)\n",
    "\n",
    "#print(couples[1:2])\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")          # a CUDA device object    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "0 45.26795196533203\n",
      "ged= tensor([ 0.1649,  0.0000,  0.0852,  0.0851,  0.0000,  0.2567,  0.0764,  0.1162,\n",
      "         0.1841,  0.0764,  0.1979, -0.1033, -0.1074, -0.8296, -0.3208, -0.5160,\n",
      "         0.1678,  0.2679,  0.2679,  0.1678,  0.3421,  0.2292,  0.3086,  0.2629,\n",
      "         0.2292,  0.2893, -0.2479, -0.3502, -0.9623, -0.4204, -0.7563,  0.2199,\n",
      "         0.2200,  0.0106,  0.3259,  0.1455,  0.2445,  0.2368,  0.1455,  0.2167,\n",
      "        -0.1368, -0.0780, -0.9908, -0.3927, -0.7526,  0.1583,  0.1759,  0.2920,\n",
      "         0.1801,  0.2041,  0.2319,  0.1801,  0.2914, -0.2370, -0.3864, -0.8093,\n",
      "        -0.3636, -0.5313,  0.1760,  0.2919,  0.1801,  0.2041,  0.2319,  0.1801,\n",
      "         0.2914, -0.2371, -0.3864, -0.8093, -0.3636, -0.5313,  0.3259,  0.1455,\n",
      "         0.2445,  0.2368,  0.1455,  0.2167, -0.1368, -0.0780, -0.9908, -0.3927,\n",
      "        -0.7526,  0.1661,  0.3042,  0.2129,  0.1661,  0.3351, -0.2895, -0.5914,\n",
      "        -0.7142, -0.3205, -0.5445,  0.2482,  0.1499,  0.0180,  0.2761, -0.1933,\n",
      "        -0.3396, -0.7439, -0.1975, -0.5391,  0.3152,  0.2481,  0.2403, -0.2489,\n",
      "        -0.4368, -0.8458, -0.3727, -0.5564,  0.1501,  0.3261, -0.2498, -0.4417,\n",
      "        -0.8147, -0.3556, -0.6318,  0.2761, -0.1933, -0.3396, -0.7439, -0.1975,\n",
      "        -0.5391, -0.2606, -0.4047, -1.0000, -0.4300, -0.7823], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "Distances:  tensor([0.1649, 0.0000, 0.0852, 0.0851, 0.0000, 0.2567, 0.0764, 0.1162, 0.1841,\n",
      "        0.0764, 0.1979, 0.1033, 0.1074, 0.8296, 0.3208, 0.5160, 0.1678, 0.2679,\n",
      "        0.2679, 0.1678, 0.3421, 0.2292, 0.3086, 0.2629, 0.2292, 0.2893, 0.2479,\n",
      "        0.3502, 0.9623, 0.4204, 0.7563, 0.2199, 0.2200, 0.0106, 0.3259, 0.1455,\n",
      "        0.2445, 0.2368, 0.1455, 0.2167, 0.1368, 0.0780, 0.9908, 0.3927, 0.7526,\n",
      "        0.1583, 0.1759, 0.2920, 0.1801, 0.2041, 0.2319, 0.1801, 0.2914, 0.2370,\n",
      "        0.3864, 0.8093, 0.3636, 0.5313, 0.1760, 0.2919, 0.1801, 0.2041, 0.2319,\n",
      "        0.1801, 0.2914, 0.2371, 0.3864, 0.8093, 0.3636, 0.5313, 0.3259, 0.1455,\n",
      "        0.2445, 0.2368, 0.1455, 0.2167, 0.1368, 0.0780, 0.9908, 0.3927, 0.7526,\n",
      "        0.1661, 0.3042, 0.2129, 0.1661, 0.3351, 0.2895, 0.5914, 0.7142, 0.3205,\n",
      "        0.5445, 0.2482, 0.1499, 0.0180, 0.2761, 0.1933, 0.3396, 0.7439, 0.1975,\n",
      "        0.5391, 0.3152, 0.2481, 0.2403, 0.2489, 0.4368, 0.8458, 0.3727, 0.5564,\n",
      "        0.1501, 0.3261, 0.2498, 0.4417, 0.8147, 0.3556, 0.6318, 0.2761, 0.1933,\n",
      "        0.3396, 0.7439, 0.1975, 0.5391, 0.2606, 0.4047, 1.0000, 0.4300, 0.7823],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss Triangular: 0.0\n",
      "node_costs :\n",
      "tensor([[0.0000, 0.0064, 0.0061, 0.0057, 0.0066, 0.0052, 0.0063, 0.0053, 0.0051,\n",
      "         0.0058, 0.0048, 0.0064, 0.0052, 0.0065, 0.0053, 0.0055, 0.0050, 0.0048,\n",
      "         0.0066],\n",
      "        [0.0064, 0.0000, 0.0063, 0.0060, 0.0054, 0.0049, 0.0063, 0.0060, 0.0054,\n",
      "         0.0050, 0.0064, 0.0057, 0.0055, 0.0059, 0.0055, 0.0055, 0.0055, 0.0051,\n",
      "         0.0049],\n",
      "        [0.0061, 0.0063, 0.0000, 0.0055, 0.0048, 0.0059, 0.0065, 0.0065, 0.0065,\n",
      "         0.0053, 0.0057, 0.0059, 0.0048, 0.0066, 0.0051, 0.0060, 0.0064, 0.0054,\n",
      "         0.0060],\n",
      "        [0.0057, 0.0060, 0.0055, 0.0000, 0.0054, 0.0060, 0.0054, 0.0053, 0.0065,\n",
      "         0.0051, 0.0057, 0.0052, 0.0066, 0.0060, 0.0061, 0.0065, 0.0050, 0.0053,\n",
      "         0.0050],\n",
      "        [0.0066, 0.0054, 0.0048, 0.0054, 0.0000, 0.0061, 0.0062, 0.0050, 0.0050,\n",
      "         0.0062, 0.0048, 0.0049, 0.0060, 0.0050, 0.0062, 0.0051, 0.0051, 0.0063,\n",
      "         0.0054],\n",
      "        [0.0052, 0.0049, 0.0059, 0.0060, 0.0061, 0.0000, 0.0060, 0.0060, 0.0062,\n",
      "         0.0060, 0.0065, 0.0049, 0.0063, 0.0060, 0.0055, 0.0050, 0.0054, 0.0049,\n",
      "         0.0066],\n",
      "        [0.0063, 0.0063, 0.0065, 0.0054, 0.0062, 0.0060, 0.0000, 0.0064, 0.0057,\n",
      "         0.0061, 0.0058, 0.0062, 0.0063, 0.0059, 0.0054, 0.0059, 0.0054, 0.0050,\n",
      "         0.0056],\n",
      "        [0.0053, 0.0060, 0.0065, 0.0053, 0.0050, 0.0060, 0.0064, 0.0000, 0.0059,\n",
      "         0.0051, 0.0055, 0.0053, 0.0053, 0.0057, 0.0059, 0.0057, 0.0051, 0.0054,\n",
      "         0.0057],\n",
      "        [0.0051, 0.0054, 0.0065, 0.0065, 0.0050, 0.0062, 0.0057, 0.0059, 0.0000,\n",
      "         0.0064, 0.0052, 0.0054, 0.0053, 0.0049, 0.0058, 0.0057, 0.0051, 0.0062,\n",
      "         0.0060],\n",
      "        [0.0058, 0.0050, 0.0053, 0.0051, 0.0062, 0.0060, 0.0061, 0.0051, 0.0064,\n",
      "         0.0000, 0.0050, 0.0054, 0.0056, 0.0060, 0.0062, 0.0065, 0.0053, 0.0056,\n",
      "         0.0057],\n",
      "        [0.0048, 0.0064, 0.0057, 0.0057, 0.0048, 0.0065, 0.0058, 0.0055, 0.0052,\n",
      "         0.0050, 0.0000, 0.0052, 0.0065, 0.0054, 0.0063, 0.0054, 0.0048, 0.0062,\n",
      "         0.0058],\n",
      "        [0.0064, 0.0057, 0.0059, 0.0052, 0.0049, 0.0049, 0.0062, 0.0053, 0.0054,\n",
      "         0.0054, 0.0052, 0.0000, 0.0062, 0.0048, 0.0051, 0.0057, 0.0062, 0.0051,\n",
      "         0.0063],\n",
      "        [0.0052, 0.0055, 0.0048, 0.0066, 0.0060, 0.0063, 0.0063, 0.0053, 0.0053,\n",
      "         0.0056, 0.0065, 0.0062, 0.0000, 0.0063, 0.0048, 0.0063, 0.0066, 0.0060,\n",
      "         0.0055],\n",
      "        [0.0065, 0.0059, 0.0066, 0.0060, 0.0050, 0.0060, 0.0059, 0.0057, 0.0049,\n",
      "         0.0060, 0.0054, 0.0048, 0.0063, 0.0000, 0.0050, 0.0052, 0.0052, 0.0055,\n",
      "         0.0061],\n",
      "        [0.0053, 0.0055, 0.0051, 0.0061, 0.0062, 0.0055, 0.0054, 0.0059, 0.0058,\n",
      "         0.0062, 0.0063, 0.0051, 0.0048, 0.0050, 0.0000, 0.0063, 0.0063, 0.0052,\n",
      "         0.0057],\n",
      "        [0.0055, 0.0055, 0.0060, 0.0065, 0.0051, 0.0050, 0.0059, 0.0057, 0.0057,\n",
      "         0.0065, 0.0054, 0.0057, 0.0063, 0.0052, 0.0063, 0.0000, 0.0050, 0.0064,\n",
      "         0.0056],\n",
      "        [0.0050, 0.0055, 0.0064, 0.0050, 0.0051, 0.0054, 0.0054, 0.0051, 0.0051,\n",
      "         0.0053, 0.0048, 0.0062, 0.0066, 0.0052, 0.0063, 0.0050, 0.0000, 0.0054,\n",
      "         0.0052],\n",
      "        [0.0048, 0.0051, 0.0054, 0.0053, 0.0063, 0.0049, 0.0050, 0.0054, 0.0062,\n",
      "         0.0056, 0.0062, 0.0051, 0.0060, 0.0055, 0.0052, 0.0064, 0.0054, 0.0000,\n",
      "         0.0051],\n",
      "        [0.0066, 0.0049, 0.0060, 0.0050, 0.0054, 0.0066, 0.0056, 0.0057, 0.0060,\n",
      "         0.0057, 0.0058, 0.0063, 0.0055, 0.0061, 0.0057, 0.0056, 0.0052, 0.0051,\n",
      "         0.0000]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "nodeInsDel: 0.005352935753762722\n",
      "edge_costs :\n",
      "tensor([[0.0000, 0.0061, 0.0065],\n",
      "        [0.0061, 0.0000, 0.0055],\n",
      "        [0.0065, 0.0055, 0.0000]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "edgeInsDel: 0.00611684238538146\n",
      "1 44.093143463134766\n",
      "2 43.435604095458984\n",
      "3 42.969722747802734\n",
      "4 42.58000946044922\n",
      "5 42.24940490722656\n",
      "6 41.964988708496094\n",
      "7 41.71727752685547\n",
      "8 41.498863220214844\n",
      "9 41.30418395996094\n",
      "10 41.12879180908203\n",
      "11 40.96942138671875\n",
      "12 40.82326126098633\n",
      "13 40.68783950805664\n",
      "14 40.589263916015625\n",
      "15 40.5247802734375\n",
      "16 40.45737075805664\n",
      "17 40.387962341308594\n",
      "18 40.31771469116211\n",
      "19 40.25126647949219\n",
      "20 40.18608093261719\n",
      "21 40.11779022216797\n",
      "22 40.04473876953125\n",
      "23 39.981605529785156\n",
      "24 39.933555603027344\n",
      "25 39.894775390625\n",
      "26 39.85881042480469\n",
      "27 39.82520294189453\n",
      "28 39.79695129394531\n",
      "29 39.804893493652344\n",
      "30 39.811649322509766\n",
      "31 39.81758117675781\n",
      "32 39.822959899902344\n",
      "33 39.82789611816406\n",
      "34 39.832374572753906\n",
      "35 39.83625030517578\n",
      "36 39.83924102783203\n",
      "37 39.84120178222656\n",
      "38 39.841827392578125\n",
      "39 39.840919494628906\n",
      "40 39.83837890625\n",
      "41 39.83421325683594\n",
      "42 39.83324432373047\n",
      "43 39.824424743652344\n",
      "44 39.81721496582031\n",
      "45 39.811885833740234\n",
      "46 39.80672836303711\n",
      "47 39.80171203613281\n",
      "48 39.79679489135742\n",
      "49 39.79184341430664\n",
      "50 39.78678512573242\n",
      "51 39.78150939941406\n",
      "52 39.77595520019531\n",
      "53 39.77003479003906\n",
      "54 39.775230407714844\n",
      "55 39.776512145996094\n",
      "56 39.77166748046875\n",
      "57 39.763671875\n",
      "58 39.76543045043945\n",
      "59 39.76590347290039\n",
      "60 39.764984130859375\n",
      "61 39.76277542114258\n",
      "62 39.762718200683594\n",
      "63 39.76215362548828\n",
      "64 39.761314392089844\n",
      "65 39.76194763183594\n",
      "66 39.760929107666016\n",
      "67 39.758445739746094\n",
      "68 39.7615852355957\n",
      "69 39.76069259643555\n",
      "70 39.75587463378906\n",
      "71 39.75611114501953\n",
      "72 39.75476837158203\n",
      "73 39.75401306152344\n",
      "74 39.75224304199219\n",
      "75 39.75094985961914\n",
      "76 39.753273010253906\n",
      "77 39.750022888183594\n",
      "78 39.75176239013672\n",
      "79 39.75303649902344\n",
      "80 39.75275421142578\n",
      "81 39.75115966796875\n",
      "82 39.74836349487305\n",
      "83 39.7455940246582\n",
      "84 39.7452392578125\n",
      "85 39.746124267578125\n",
      "86 39.746788024902344\n",
      "87 39.74614715576172\n",
      "88 39.74437713623047\n",
      "89 39.74342727661133\n",
      "90 39.74182891845703\n",
      "91 39.742767333984375\n",
      "92 39.74260711669922\n",
      "93 39.7430419921875\n",
      "94 39.742286682128906\n",
      "95 39.7404670715332\n",
      "96 39.74420928955078\n",
      "97 39.74262237548828\n",
      "98 39.74069595336914\n",
      "99 39.74213409423828\n",
      "ged= tensor([ 1.5384e-02,  4.4900e-04,  4.9915e-02,  4.9942e-02,  4.4900e-04,\n",
      "         1.1796e-01,  4.7453e-02,  5.3177e-02,  5.2808e-02,  4.7453e-02,\n",
      "         1.8820e-02, -6.0682e-03, -2.6954e-01, -8.5756e-01, -2.0143e-01,\n",
      "        -6.7201e-01,  9.9787e-03,  5.9476e-02,  5.9510e-02,  9.9787e-03,\n",
      "         1.2256e-01,  5.6386e-02,  6.3007e-02,  5.7179e-02,  5.6386e-02,\n",
      "         2.3499e-02, -1.3972e-02, -2.8213e-01, -8.6443e-01, -2.0733e-01,\n",
      "        -6.8419e-01,  1.2497e-01,  1.2504e-01,  6.5180e-03,  2.1070e-01,\n",
      "         1.1982e-01,  1.2760e-01,  1.2396e-01,  1.1982e-01,  5.9904e-02,\n",
      "        -1.2874e-02, -1.5447e-01, -1.0000e+00, -3.0994e-01, -8.1607e-01,\n",
      "         1.4403e-02,  3.7866e-02,  5.5562e-02,  1.3746e-02,  1.8474e-02,\n",
      "         1.5875e-02,  1.3746e-02,  1.5487e-02, -4.1386e-02, -4.0931e-01,\n",
      "        -7.3109e-01, -1.2060e-01, -5.5103e-01,  3.7901e-02,  5.5555e-02,\n",
      "         1.3785e-02,  1.8505e-02,  1.5860e-02,  1.3785e-02,  1.5513e-02,\n",
      "        -4.1388e-02, -4.0945e-01, -7.3109e-01, -1.2058e-01, -5.5104e-01,\n",
      "         2.1070e-01,  1.1982e-01,  1.2760e-01,  1.2396e-01,  1.1982e-01,\n",
      "         5.9904e-02, -1.2874e-02, -1.5447e-01, -1.0000e+00, -3.0994e-01,\n",
      "        -8.1607e-01,  0.0000e+00,  9.5058e-03,  1.5976e-03,  0.0000e+00,\n",
      "         3.6092e-02, -9.7160e-02, -5.4741e-01, -6.0876e-01, -5.5143e-02,\n",
      "        -4.3918e-01,  1.7946e-02,  1.0353e-02,  3.7934e-03,  1.2509e-02,\n",
      "        -3.6866e-02, -4.0578e-01, -7.2741e-01, -1.1059e-01, -5.5018e-01,\n",
      "         2.1263e-02,  1.8400e-02,  1.4237e-02, -4.3649e-02, -4.1411e-01,\n",
      "        -7.3394e-01, -1.2186e-01, -5.5378e-01,  1.0803e-02,  1.4848e-02,\n",
      "        -3.9613e-02, -4.1010e-01, -7.3057e-01, -1.1893e-01, -5.5472e-01,\n",
      "         1.2509e-02, -3.6866e-02, -4.0578e-01, -7.2741e-01, -1.1059e-01,\n",
      "        -5.5018e-01, -1.6351e-02, -2.8741e-01, -8.6736e-01, -2.0863e-01,\n",
      "        -6.8700e-01], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Distances:  tensor([1.5384e-02, 4.4900e-04, 4.9915e-02, 4.9942e-02, 4.4900e-04, 1.1796e-01,\n",
      "        4.7453e-02, 5.3177e-02, 5.2808e-02, 4.7453e-02, 1.8820e-02, 6.0682e-03,\n",
      "        2.6954e-01, 8.5756e-01, 2.0143e-01, 6.7201e-01, 9.9787e-03, 5.9476e-02,\n",
      "        5.9510e-02, 9.9787e-03, 1.2256e-01, 5.6386e-02, 6.3007e-02, 5.7179e-02,\n",
      "        5.6386e-02, 2.3499e-02, 1.3972e-02, 2.8213e-01, 8.6443e-01, 2.0733e-01,\n",
      "        6.8419e-01, 1.2497e-01, 1.2504e-01, 6.5180e-03, 2.1070e-01, 1.1982e-01,\n",
      "        1.2760e-01, 1.2396e-01, 1.1982e-01, 5.9904e-02, 1.2874e-02, 1.5447e-01,\n",
      "        1.0000e+00, 3.0994e-01, 8.1607e-01, 1.4403e-02, 3.7866e-02, 5.5562e-02,\n",
      "        1.3746e-02, 1.8474e-02, 1.5875e-02, 1.3746e-02, 1.5487e-02, 4.1386e-02,\n",
      "        4.0931e-01, 7.3109e-01, 1.2060e-01, 5.5103e-01, 3.7901e-02, 5.5555e-02,\n",
      "        1.3785e-02, 1.8505e-02, 1.5860e-02, 1.3785e-02, 1.5513e-02, 4.1388e-02,\n",
      "        4.0945e-01, 7.3109e-01, 1.2058e-01, 5.5104e-01, 2.1070e-01, 1.1982e-01,\n",
      "        1.2760e-01, 1.2396e-01, 1.1982e-01, 5.9904e-02, 1.2874e-02, 1.5447e-01,\n",
      "        1.0000e+00, 3.0994e-01, 8.1607e-01, 0.0000e+00, 9.5058e-03, 1.5976e-03,\n",
      "        0.0000e+00, 3.6092e-02, 9.7160e-02, 5.4741e-01, 6.0876e-01, 5.5143e-02,\n",
      "        4.3918e-01, 1.7946e-02, 1.0353e-02, 3.7934e-03, 1.2509e-02, 3.6866e-02,\n",
      "        4.0578e-01, 7.2741e-01, 1.1059e-01, 5.5018e-01, 2.1263e-02, 1.8400e-02,\n",
      "        1.4237e-02, 4.3649e-02, 4.1411e-01, 7.3394e-01, 1.2186e-01, 5.5378e-01,\n",
      "        1.0803e-02, 1.4848e-02, 3.9613e-02, 4.1010e-01, 7.3057e-01, 1.1893e-01,\n",
      "        5.5472e-01, 1.2509e-02, 3.6866e-02, 4.0578e-01, 7.2741e-01, 1.1059e-01,\n",
      "        5.5018e-01, 1.6351e-02, 2.8741e-01, 8.6736e-01, 2.0863e-01, 6.8700e-01],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss Triangular: 0.0\n",
      "node_costs :\n",
      "tensor([[0.0000, 0.0068, 0.0062, 0.0052, 0.0072, 0.0042, 0.0064, 0.0044, 0.0040,\n",
      "         0.0055, 0.0035, 0.0067, 0.0042, 0.0070, 0.0044, 0.0049, 0.0038, 0.0034,\n",
      "         0.0072],\n",
      "        [0.0068, 0.0000, 0.0065, 0.0058, 0.0046, 0.0036, 0.0066, 0.0058, 0.0046,\n",
      "         0.0039, 0.0068, 0.0052, 0.0049, 0.0057, 0.0048, 0.0049, 0.0048, 0.0040,\n",
      "         0.0036],\n",
      "        [0.0062, 0.0065, 0.0000, 0.0049, 0.0035, 0.0057, 0.0069, 0.0070, 0.0070,\n",
      "         0.0044, 0.0053, 0.0057, 0.0035, 0.0071, 0.0040, 0.0058, 0.0066, 0.0046,\n",
      "         0.0059],\n",
      "        [0.0052, 0.0058, 0.0049, 0.0000, 0.0046, 0.0059, 0.0046, 0.0045, 0.0069,\n",
      "         0.0040, 0.0052, 0.0043, 0.0071, 0.0058, 0.0061, 0.0070, 0.0039, 0.0045,\n",
      "         0.0039],\n",
      "        [0.0072, 0.0046, 0.0035, 0.0046, 0.0000, 0.0061, 0.0063, 0.0038, 0.0038,\n",
      "         0.0063, 0.0035, 0.0035, 0.0059, 0.0038, 0.0062, 0.0041, 0.0041, 0.0066,\n",
      "         0.0046],\n",
      "        [0.0042, 0.0036, 0.0057, 0.0059, 0.0061, 0.0000, 0.0058, 0.0058, 0.0062,\n",
      "         0.0058, 0.0069, 0.0036, 0.0065, 0.0058, 0.0047, 0.0039, 0.0045, 0.0037,\n",
      "         0.0072],\n",
      "        [0.0064, 0.0066, 0.0069, 0.0046, 0.0063, 0.0058, 0.0000, 0.0067, 0.0052,\n",
      "         0.0060, 0.0054, 0.0062, 0.0065, 0.0057, 0.0047, 0.0058, 0.0046, 0.0039,\n",
      "         0.0051],\n",
      "        [0.0044, 0.0058, 0.0070, 0.0045, 0.0038, 0.0058, 0.0067, 0.0000, 0.0057,\n",
      "         0.0040, 0.0049, 0.0045, 0.0044, 0.0053, 0.0057, 0.0053, 0.0040, 0.0047,\n",
      "         0.0051],\n",
      "        [0.0040, 0.0046, 0.0070, 0.0069, 0.0038, 0.0062, 0.0052, 0.0057, 0.0000,\n",
      "         0.0068, 0.0042, 0.0046, 0.0045, 0.0037, 0.0053, 0.0052, 0.0041, 0.0063,\n",
      "         0.0058],\n",
      "        [0.0055, 0.0039, 0.0044, 0.0040, 0.0063, 0.0058, 0.0060, 0.0040, 0.0068,\n",
      "         0.0000, 0.0038, 0.0046, 0.0050, 0.0058, 0.0063, 0.0069, 0.0045, 0.0050,\n",
      "         0.0052],\n",
      "        [0.0035, 0.0068, 0.0053, 0.0052, 0.0035, 0.0069, 0.0054, 0.0049, 0.0042,\n",
      "         0.0038, 0.0000, 0.0042, 0.0070, 0.0047, 0.0065, 0.0046, 0.0035, 0.0064,\n",
      "         0.0055],\n",
      "        [0.0067, 0.0052, 0.0057, 0.0043, 0.0035, 0.0036, 0.0062, 0.0045, 0.0046,\n",
      "         0.0046, 0.0042, 0.0000, 0.0063, 0.0035, 0.0040, 0.0053, 0.0063, 0.0041,\n",
      "         0.0066],\n",
      "        [0.0042, 0.0049, 0.0035, 0.0071, 0.0059, 0.0065, 0.0065, 0.0044, 0.0045,\n",
      "         0.0050, 0.0070, 0.0063, 0.0000, 0.0064, 0.0035, 0.0065, 0.0071, 0.0059,\n",
      "         0.0049],\n",
      "        [0.0070, 0.0057, 0.0071, 0.0058, 0.0038, 0.0058, 0.0057, 0.0053, 0.0037,\n",
      "         0.0058, 0.0047, 0.0035, 0.0064, 0.0000, 0.0039, 0.0041, 0.0042, 0.0049,\n",
      "         0.0060],\n",
      "        [0.0044, 0.0048, 0.0040, 0.0061, 0.0062, 0.0047, 0.0047, 0.0057, 0.0053,\n",
      "         0.0063, 0.0065, 0.0040, 0.0035, 0.0039, 0.0000, 0.0065, 0.0066, 0.0042,\n",
      "         0.0052],\n",
      "        [0.0049, 0.0049, 0.0058, 0.0070, 0.0041, 0.0039, 0.0058, 0.0053, 0.0052,\n",
      "         0.0069, 0.0046, 0.0053, 0.0065, 0.0041, 0.0065, 0.0000, 0.0038, 0.0067,\n",
      "         0.0051],\n",
      "        [0.0038, 0.0048, 0.0066, 0.0039, 0.0041, 0.0045, 0.0046, 0.0040, 0.0041,\n",
      "         0.0045, 0.0035, 0.0063, 0.0071, 0.0042, 0.0066, 0.0038, 0.0000, 0.0045,\n",
      "         0.0043],\n",
      "        [0.0034, 0.0040, 0.0046, 0.0045, 0.0066, 0.0037, 0.0039, 0.0047, 0.0063,\n",
      "         0.0050, 0.0064, 0.0041, 0.0059, 0.0049, 0.0042, 0.0067, 0.0045, 0.0000,\n",
      "         0.0040],\n",
      "        [0.0072, 0.0036, 0.0059, 0.0039, 0.0046, 0.0072, 0.0051, 0.0051, 0.0058,\n",
      "         0.0052, 0.0055, 0.0066, 0.0049, 0.0060, 0.0052, 0.0051, 0.0043, 0.0040,\n",
      "         0.0000]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "nodeInsDel: 0.06197088956832886\n",
      "edge_costs :\n",
      "tensor([[0.0000e+00, 3.5986e-03, 1.4832e-03],\n",
      "        [3.5986e-03, 0.0000e+00, 3.9234e-05],\n",
      "        [1.4832e-03, 3.9234e-05, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "edgeInsDel: 0.04285779595375061\n"
     ]
    }
   ],
   "source": [
    "#if torch.cuda.device_count() > 1:\n",
    "#  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "#  model = nn.DataParallel(model)\n",
    "from triangular_losses import TriangularConstraint as triangular_constraint\n",
    "model.to(device)\n",
    "def classification(model,data,yt,nb_iter):\n",
    "\n",
    "    criterion = torch.nn.HingeEmbeddingLoss(margin=1.0,reduction='sum')\n",
    "    criterionTri=triangular_constraint()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "    print(device)\n",
    "\n",
    "#torch.cat((same_class[0:20],diff_class[0:20]),0).to(device)\n",
    "    input=data.to(device)\n",
    "    target=yt.to(device) \n",
    "#torch.ones(40,device=device)\n",
    "#target[20:]=-1.0\n",
    "#target=(yt[0:20]).to(device)\n",
    "    InsDel=np.empty((nb_iter,2))\n",
    "    node_costs,nodeInsDel,edge_costs,edgeInsDel=model.from_weighs_to_costs()\n",
    "    nodeSub=np.empty((nb_iter,int(node_costs.shape[0]*(node_costs.shape[0]-1)/2)))\n",
    "    edgeSub=np.empty((nb_iter,int(edge_costs.shape[0]*(edge_costs.shape[0]-1)/2)))\n",
    "    loss_plt=np.empty(nb_iter)\n",
    "    for t in range(nb_iter):    \n",
    "        # Forward pass: Compute predicted y by passing data to the model    \n",
    "\n",
    "\n",
    "        y_pred = model(input).to(device)\n",
    "        \n",
    "        \n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, target).to(device)    \n",
    "        node_costs,nodeInsDel,edge_costs,edgeInsDel=model.from_weighs_to_costs()\n",
    "        triangularInq=criterionTri(node_costs,nodeInsDel,edge_costs,edgeInsDel)\n",
    "        loss=loss*(1+triangularInq)\n",
    "        loss.to(device)\n",
    "        InsDel[t][0]=nodeInsDel.item()\n",
    "        InsDel[t][1]=edgeInsDel.item()\n",
    "        loss_plt[t]=loss.item()\n",
    "        print(t, loss.item())  \n",
    "        k=0\n",
    "        for p in range(node_costs.shape[0]):\n",
    "            for q in range(p+1,node_costs.shape[0]):\n",
    "                nodeSub[t][k]=node_costs[p][q]\n",
    "                k=k+1\n",
    "        k=0\n",
    "        for p in range(edge_costs.shape[0]):\n",
    "            for q in range(p+1,edge_costs.shape[0]):\n",
    "                edgeSub[t][k]=edge_costs[p][q]\n",
    "                k=k+1\n",
    "        if t % 100 == 99 or t==0:   \n",
    "            print('ged=',y_pred*target)\n",
    "            print('Distances: ',y_pred)\n",
    "            print('Loss Triangular:',triangularInq.item())\n",
    "            print('node_costs :')\n",
    "            print(node_costs)\n",
    "            print('nodeInsDel:',nodeInsDel.item())\n",
    "            print('edge_costs :')\n",
    "            print(edge_costs)\n",
    "            print('edgeInsDel:',edgeInsDel.item())\n",
    "        \n",
    "        \n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return InsDel,nodeSub,edgeSub,loss_plt\n",
    "\n",
    "nb_iter=100\n",
    "InsDel, nodeSub,edgeSub,loss_plt=classification(model,data,yt,nb_iter)\n",
    "plt.figure(0)\n",
    "plt.plot(InsDel[0:nb_iter,0],label=\"node\")\n",
    "plt.plot(InsDel[0:nb_iter,1],label=\"edge\")\n",
    "plt.title('Node/Edge insertion/deletion costs')\n",
    "plt.legend()\n",
    "plt.figure(1)\n",
    "for k in range(nodeSub.shape[1]):\n",
    "    plt.plot(nodeSub[0:nb_iter,k])\n",
    "plt.title('Node Substitutions costs')\n",
    "plt.figure(2)\n",
    "for k in range(edgeSub.shape[1]):\n",
    "    plt.plot(edgeSub[0:nb_iter,k])\n",
    "plt.title('Edge Substitutions costs')\n",
    "plt.figure(3)\n",
    "plt.plot(loss_plt)\n",
    "plt.title('Evolution of the loss')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "A=torch.tensor(nx.to_scipy_sparse_matrix(Gs[0],dtype=int,weight='bond_type').todense(),dtype=torch.int) \n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.plot(InsDel[0:500,0],label=\"node\")\n",
    "plt.plot(InsDel[0:500,1],label=\"edge\")\n",
    "plt.title('Node/Edge insertion/deletion costs')\n",
    "plt.legend()\n",
    "plt.figure(1)\n",
    "for k in range(nodeSub.shape[1]):\n",
    "    plt.plot(nodeSub[0:500,k])\n",
    "plt.title('node Substitution costs')\n",
    "plt.figure(2)\n",
    "for k in range(edgeSub.shape[1]):\n",
    "    plt.plot(edgeSub[0:500,k])\n",
    "plt.title('edge Substitution costs')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
