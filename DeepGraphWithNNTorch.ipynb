{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gklearn.utils.graphfiles import loadDataset\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge max label 3\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "def label_to_color(label):\n",
    "    if label == 'C':\n",
    "        return 0.1\n",
    "    elif label == 'O':\n",
    "        return 0.8\n",
    "    \n",
    "def nodes_to_color_sequence(G):\n",
    "    return [label_to_color(c[1]['label'][0]) for c in G.nodes(data=True)]\n",
    "\n",
    "Gs,y = loadDataset('../DeepGED/MAO/dataset.ds')\n",
    "#for e in Gs[13].edges():\n",
    "#    print(Gs[13][e[0]][e[1]]['bond_type'])\n",
    "print('edge max label',max(max([[G[e[0]][e[1]]['bond_type'] for e in G.edges()] for G in Gs])))\n",
    "G1 = Gs[1]\n",
    "G2 = Gs[9]\n",
    "print(y[1],y[9])\n",
    "plt.figure(0)\n",
    "nx.draw_networkx(G1,with_labels=True,node_color = nodes_to_color_sequence(G1),cmap='autumn')\n",
    "\n",
    "plt.figure(1)\n",
    "nx.draw_networkx(G2,with_labels=True,node_color = nodes_to_color_sequence(G2),cmap='autumn')\n",
    "\n",
    "plt.show()\n",
    "import extended_label\n",
    "for g in Gs:\n",
    "    extended_label.compute_extended_labels(g)\n",
    "#for v in Gs[10].nodes():\n",
    "#        print(Gs[10].nodes[v])\n",
    "\n",
    "#print(nx.to_dict_of_lists(Gs[13]))\n",
    "\n",
    "\n",
    "\n",
    "#dict={'C':0,'N':1,'O':2}\n",
    "#A,labels=from_networkx_to_tensor2(Gs[13],dict)\n",
    "#print(A)\n",
    "#A1=(A==torch.ones(13,13)).int()\n",
    "#A2=(A==2*torch.ones(13,13)).int()\n",
    "#print(A1)\n",
    "#print(A2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n",
      "<torch.cuda.device object at 0x7f4d9a0d9390>\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.__version__)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#model.to(device)\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gs= 68\n",
      "['C_1C', 'C_1C1C1N', 'C_1C1C2C', 'C_1C1N', 'C_1C1N2C', 'C_1C1O', 'C_1C1O2C', 'C_1C2C', 'C_1C3C', 'C_1N', 'C_1O', 'C_2C', 'C_2C2C', 'C_3C', 'N_1C', 'N_1C1C', 'N_1C1C1C', 'O_1C', 'O_1C1C']\n",
      "{'C_1C': 0, 'C_1C1C1N': 1, 'C_1C1C2C': 2, 'C_1C1N': 3, 'C_1C1N2C': 4, 'C_1C1O': 5, 'C_1C1O2C': 6, 'C_1C2C': 7, 'C_1C3C': 8, 'C_1N': 9, 'C_1O': 10, 'C_2C': 11, 'C_2C2C': 12, 'C_3C': 13, 'N_1C': 14, 'N_1C1C': 15, 'N_1C1C1C': 16, 'O_1C': 17, 'O_1C1C': 18} 19\n",
      "nb_edge_labels :  3\n",
      "torch.Size([68, 729])\n",
      "adjacency matrices tensor([[         0,          1,          0,  ..., 1734632748, 1868783461,\n",
      "          745763955],\n",
      "        [         0,          1,          0,  ..., 1818575987,  537541161,\n",
      "          538976288],\n",
      "        [         0,          1,          0,  ...,  544106784, 1914728307,\n",
      "         1600613993],\n",
      "        ...,\n",
      "        [         0,          1,          0,  ...,  538976288,  538976288,\n",
      "         1126178848],\n",
      "        [         0,          1,          0,  ...,       9504,          0,\n",
      "                 -1],\n",
      "        [         0,          1,          0,  ..., 1601660270, 1886413165,\n",
      "         1600613993]], dtype=torch.int32)\n",
      "node labels tensor([[       15,         4,         7,  ...,        10,        10,\n",
      "                25],\n",
      "        [       15,         4,         7,  ...,         0,  76577600,\n",
      "                 0],\n",
      "        [       15,         4,         7,  ...,  76555336,         0,\n",
      "          31661952],\n",
      "        ...,\n",
      "        [       16,         4,         7,  ...,     32590,  31661952,\n",
      "             32590],\n",
      "        [       16,         4,         7,  ...,        27,        18,\n",
      "                25],\n",
      "        [       16,         4,         7,  ..., 538976288,  76562232,\n",
      "                 0]], dtype=torch.int32)\n",
      "order of the graphs tensor([11, 12, 14, 14, 15, 17, 15, 16, 19, 15, 16, 19, 12, 13, 15, 18, 16, 16,\n",
      "        17, 16, 17, 17, 18, 19, 19, 18, 18, 22, 22, 15, 14, 13, 16, 17, 17, 21,\n",
      "        17, 18, 18, 21, 24, 25, 25, 14, 17, 18, 18, 22, 23, 23, 25, 27, 27, 15,\n",
      "        16, 23, 24, 24, 16, 17, 17, 20, 23, 24, 26, 16, 17, 21])\n",
      "27 68\n",
      "toto\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import svd\n",
    "import rings\n",
    "from svd import iterated_power as compute_major_axis\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "        \n",
    "    def __init__(self,GraphList,normalize=False,node_label='label'):\n",
    "        super(Net, self).__init__()   \n",
    "        self.normalize=normalize\n",
    "        self.node_label=node_label\n",
    "        dict,self.nb_edge_labels=self.build_node_dictionnary(GraphList)\n",
    "        self.nb_labels=len(dict)\n",
    "        print('nb_edge_labels : ', self.nb_edge_labels)\n",
    "        self.device='cuda' if torch.cuda.is_available() else 'cpu'  #torch.device(\"cuda:0\")\n",
    "        nb_node_pair_label=self.nb_labels*(self.nb_labels-1)/2.0\n",
    "        nb_edge_pair_label=int(self.nb_edge_labels*(self.nb_edge_labels-1)/2)\n",
    "        \n",
    "        self.node_weighs=nn.Parameter(torch.tensor(1.0/(nb_node_pair_label+nb_edge_pair_label+2))+(1e-3)*torch.rand(int(self.nb_labels*(self.nb_labels-1)/2+1),requires_grad=True,device=self.device)) # all substitution costs+ nodeIns/Del. old version: 0 node subs, 1 nodeIns/Del, 2 : edgeSubs, 3 edgeIns/Del        \n",
    "        self.edge_weighs=nn.Parameter(torch.tensor(1.0/(nb_node_pair_label+nb_edge_pair_label+2))+(1e-3)*torch.rand(nb_edge_pair_label+1,requires_grad=True,device=self.device)) #edgeIns/Del\n",
    "                \n",
    "        self.card=torch.tensor([G.order() for G in GraphList]).to(self.device)\n",
    "        card_max=self.card.max()\n",
    "        self.A=torch.empty((len(GraphList),card_max*card_max),dtype=torch.int,device=self.device)\n",
    "        self.labels=torch.empty((len(GraphList),card_max),dtype=torch.int,device=self.device)\n",
    "        print(self.A.shape)\n",
    "        for k in range(len(GraphList)):\n",
    "            A,l=self.from_networkx_to_tensor(GraphList[k],dict)             \n",
    "            self.A[k,0:A.shape[1]]=A[0]\n",
    "            self.labels[k,0:l.shape[0]]=l\n",
    "        print('adjacency matrices',self.A)\n",
    "        print('node labels',self.labels)\n",
    "        print('order of the graphs',self.card)\n",
    "        \n",
    "    def forward(self, input):        \n",
    "        ged=torch.zeros(len(input)).to(self.device) \n",
    "        node_costs,nodeInsDel,edge_costs,edgeInsDel=self.from_weighs_to_costs()\n",
    "        \n",
    "        #print('weighs:',self.weighs.device,'device:',self.device,'card:',self.card.device,'A:',self.A.device,'labels:',self.labels.device)\n",
    "        for k in range(len(input)):            \n",
    "            g1=input[k][0]\n",
    "            g2=input[k][1]\n",
    "            n=self.card[g1]\n",
    "            m=self.card[g2]\n",
    "            \n",
    "            self.ring_g,self.ring_h = rings.build_rings(g1,edgeInsDel.size()), rings.build_rings(g2,edgeInsDel.size()) \n",
    "                        \n",
    "            C=self.construct_cost_matrix(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)      \n",
    "            #S=self.mapping_from_similarity(C,n,m)\n",
    "            #S=self.mapping_from_cost(C,n,m)\n",
    "            \n",
    "            #S=self.new_mapping_from_cost(C,n,m,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "            S=self.mapping_from_cost_sans_FW(n,m,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "            v=torch.flatten(S)\n",
    "            \n",
    "            normalize_factor=1.0\n",
    "            if self.normalize:\n",
    "                nb_edge1=(self.A[g1][0:n*n] != torch.zeros(n*n,device=self.device)).int().sum()\n",
    "                nb_edge2=(self.A[g2][0:m*m] != torch.zeros(m*m,device=self.device)).int().sum()\n",
    "                normalize_factor=nodeInsDel*(n+m)+edgeInsDel*(nb_edge1+nb_edge2)\n",
    "                \n",
    "            ged[k]=.5*(v.t()@C@v)/normalize_factor\n",
    "        return ged\n",
    "    \n",
    "    def from_weighs_to_costs(self):\n",
    "        \n",
    "        #cn=torch.exp(self.node_weighs)\n",
    "        #ce=torch.exp(self.edge_weighs)\n",
    "        cn=self.node_weighs*self.node_weighs\n",
    "        ce=self.edge_weighs*self.edge_weighs\n",
    "        total_cost=cn.sum()+ce.sum()\n",
    "        cn=cn/total_cost\n",
    "        ce=ce/total_cost\n",
    "        edgeInsDel=ce[-1]\n",
    "\n",
    "        node_costs=torch.zeros((self.nb_labels,self.nb_labels),device=self.device)\n",
    "        upper_part=torch.triu_indices(node_costs.shape[0],node_costs.shape[1],offset=1,device=self.device)        \n",
    "        node_costs[upper_part[0],upper_part[1]]=cn[0:-1]\n",
    "        node_costs=node_costs+node_costs.T\n",
    "\n",
    "        if self.nb_edge_labels>1:\n",
    "            edge_costs=torch.zeros((self.nb_edge_labels,self.nb_edge_labels),device=self.device)\n",
    "            upper_part=torch.triu_indices(edge_costs.shape[0],edge_costs.shape[1],offset=1,device=self.device)        \n",
    "            edge_costs[upper_part[0],upper_part[1]]=ce[0:-1]\n",
    "            edge_costs=edge_costs+edge_costs.T\n",
    "        else:\n",
    "            edge_costs=torch.zeros(0,device=self.device)\n",
    "        \n",
    "        #print('res from_w_to_cost : ', node_costs,cn[-1],edge_costs,edgeInsDel)\n",
    "        return node_costs,cn[-1],edge_costs,edgeInsDel\n",
    "    \n",
    "    def build_node_dictionnary(self,GraphList):\n",
    "        #extraction de tous les labels d'atomes\n",
    "        node_labels=[]\n",
    "        for G in Gs:\n",
    "            for v in nx.nodes(G):\n",
    "                if not G.nodes[v][self.node_label][0] in node_labels:\n",
    "                    node_labels.append(G.nodes[v][self.node_label][0])\n",
    "        node_labels.sort()\n",
    "        #extraction d'un dictionnaire permettant de numéroter chaque label par un numéro.\n",
    "        dict={}\n",
    "        k=0\n",
    "        for label in node_labels:\n",
    "            dict[label]=k\n",
    "            k=k+1\n",
    "        print(node_labels)\n",
    "        print(dict,len(dict))\n",
    "    \n",
    "        return dict,max(max([[int(G[e[0]][e[1]]['bond_type']) for e in G.edges()] for G in GraphList]))\n",
    "    \n",
    "    def from_networkx_to_tensor(self,G,dict):    \n",
    "        A=torch.tensor(nx.to_scipy_sparse_matrix(G,dtype=int,weight='bond_type').todense(),dtype=torch.int)        \n",
    "        lab=[dict[G.nodes[v][self.node_label][0]] for v in nx.nodes(G)]\n",
    "   \n",
    "        return (A.view(1,A.shape[0]*A.shape[1]),torch.tensor(lab))\n",
    "\n",
    "    def construct_cost_matrix(self,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel):\n",
    "        n = self.card[g1].item()\n",
    "        m = self.card[g2].item()\n",
    "        \n",
    "        A1=torch.zeros((n+1,n+1),dtype=torch.int,device=self.device)\n",
    "        A1[0:n,0:n]=self.A[g1][0:n*n].view(n,n)\n",
    "        A2=torch.zeros((m+1,m+1),dtype=torch.int,device=self.device)\n",
    "        A2[0:m,0:m]=self.A[g2][0:m*m].view(m,m)\n",
    "        \n",
    "        \n",
    "         # costs: 0 node subs, 1 nodeIns/Del, 2 : edgeSubs, 3 edgeIns/Del\n",
    "        \n",
    "        #C=cost[3]*torch.cat([torch.cat([C12[l][k] for k in range(n+1)],1) for l in range(n+1)])\n",
    "        #Pas bien sur mais cela semble fonctionner.\n",
    "        C=edgeInsDel*self.matrix_edgeInsDel(A1,A2)\n",
    "        if self.nb_edge_labels>1:\n",
    "            for k in range(self.nb_edge_labels):\n",
    "                for l in range(self.nb_edge_labels):\n",
    "                    if k != l:\n",
    "#                    C.add_(self.matrix_edgeSubst(A1,A2,k+1,l+1),alpha=edge_costs[k][l])\n",
    "                        C=C+edge_costs[k][l]*self.matrix_edgeSubst(A1,A2,k+1,l+1)\n",
    "        #C=cost[3]*torch.tensor(np.array([ [  k!=l and A1[k//(m+1),l//(m+1)]^A2[k%(m+1),l%(m+1)] for k in range((n+1)*(m+1))] for l in range((n+1)*(m+1))]),device=self.device)        \n",
    "\n",
    "        l1=self.labels[g1][0:n]\n",
    "        l2=self.labels[g2][0:m]\n",
    "        D=torch.zeros((n+1)*(m+1),device=self.device)\n",
    "        D[n*(m+1):]=nodeInsDel\n",
    "        D[n*(m+1)+m]=0\n",
    "        D[[i*(m+1)+m for i in range(n)]]=nodeInsDel\n",
    "        D[[k for k in range(n*(m+1)) if k%(m+1) != m]]=torch.tensor([node_costs[l1[k//(m+1)],l2[k%(m+1)]] for k in range(n*(m+1)) if k%(m+1) != m],device=self.device )\n",
    "        mask = torch.diag(torch.ones_like(D))\n",
    "        C=mask*torch.diag(D) + (1. - mask)*C\n",
    "        \n",
    "        #C[range(len(C)),range(len(C))]=D\n",
    "      \n",
    "        return C\n",
    "    \n",
    "    def matrix_edgeInsDel(self,A1,A2):\n",
    "        Abin1=(A1!=torch.zeros((A1.shape[0],A1.shape[1]),device=self.device))\n",
    "        Abin2=(A2!=torch.zeros((A2.shape[0],A2.shape[1]),device=self.device))\n",
    "        C1=torch.einsum('ij,kl->ijkl',torch.logical_not(Abin1),Abin2)\n",
    "        C2=torch.einsum('ij,kl->ijkl',Abin1,torch.logical_not(Abin2))\n",
    "        C12=torch.logical_or(C1,C2).int()\n",
    "    \n",
    "        return torch.cat(torch.unbind(torch.cat(torch.unbind(C12,1),1),0),1)\n",
    "\n",
    "    def matrix_edgeSubst(self,A1,A2,lab1,lab2):\n",
    "        Abin1=(A1==lab1*torch.ones((A1.shape[0],A1.shape[1]),device=self.device)).int()\n",
    "        Abin2=(A2==lab2*torch.ones((A2.shape[0],A2.shape[1]),device=self.device)).int()\n",
    "        C=torch.einsum('ij,kl->ijkl',Abin1,Abin2)\n",
    "        \n",
    "        return torch.cat(torch.unbind(torch.cat(torch.unbind(C,1),1),0),1)\n",
    "    \n",
    "    def similarity_from_cost(self,C):\n",
    "        N=C.shape[0]\n",
    "             \n",
    "        #return (torch.norm(C,p='fro')*torch.eye(N,device=self.device) -C)\n",
    "        return (C.max()*torch.eye(N,device=self.device) -C)\n",
    "    \n",
    "\n",
    "    \n",
    "    def lsape_populate_instance(self,first_graph,second_graph,average_node_cost, average_edge_cost,alpha,lbda):       #ring_g, ring_h come from global ring with all graphs in so ring_g = rings['g'] and ring_h = rings['h']\n",
    "        g,h = Gs[first_graph], Gs[second_graph]\n",
    "        self.average_cost =[average_node_cost, average_edge_cost]\n",
    "        self.first_graph, self.second_graph = first_graph,second_graph\n",
    "        \n",
    "        node_costs,nodeInsDel,edge_costs,edgeInsDel=self.from_weighs_to_costs()\n",
    "\n",
    "        lsape_instance = [[0 for _ in range(len(g) + 1)] for __ in range(len(h) + 1)]\n",
    "        for g_node_index in range(len(g) + 1):\n",
    "            for h_node_index in range(len(h) + 1):\n",
    "                lsape_instance[h_node_index][g_node_index] = rings.compute_ring_distance(g,h,self.ring_g,self.ring_h,g_node_index,h_node_index,alpha,lbda,node_costs,nodeInsDel,edge_costs,edgeInsDel,first_graph,second_graph)\n",
    "        for i in lsape_instance :\n",
    "            i = torch.as_tensor(i)\n",
    "        lsape_instance = torch.as_tensor(lsape_instance)\n",
    "        #print(type(lsape_instance))\n",
    "        return lsape_instance\n",
    "    \n",
    "  \n",
    "    def mapping_from_cost_sans_FW(self,n,m,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel): \n",
    "        c_0 =self.lsape_populate_instance(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "        x0=svd.eps_assigment_from_mapping(torch.exp(-c_0),10).view((n+1)*(m+1),1)\n",
    "        return x0\n",
    "    \n",
    "    def new_mapping_from_cost(self,C,n,m,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel): \n",
    "        c=torch.diag(C)       \n",
    "        c_0 =self.lsape_populate_instance(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "        D=C-torch.eye(C.shape[0],device=self.device)*c\n",
    "        x0=svd.eps_assigment_from_mapping(torch.exp(-c_0),10).view((n+1)*(m+1),1)\n",
    "        return svd.franck_wolfe(x0,D,c,5,15,n,m)\n",
    "    \n",
    "    def mapping_from_cost(self,C,n,m): #à améliorer car on prend que les coût des sommets\n",
    "        c=torch.diag(C)       #diag donc vecteur/ matrice ligne, alors comment .view(n+1,m+1) est sensé marcher ?\n",
    "        c_0=lsape_populate_instance(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "        print('C.shape[0] : ', C.shape[0])\n",
    "        D=C-torch.eye(C.shape[0],device=self.device)*c\n",
    "        print('c : ',c)\n",
    "        #x0=svd.eps_assigment_from_mapping(c,10)\n",
    "        x0=svd.eps_assigment_from_mapping(torch.exp(-c_0),10).view((n+1)*(m+1),1)\n",
    "        return svd.franck_wolfe(x0,D,c,5,15,n,m)\n",
    "    \n",
    "        \n",
    "    def mapping_from_similarity(self,C,n,m):\n",
    "        M=self.similarity_from_cost(C)\n",
    "        first_ev=compute_major_axis(M)\n",
    "        #first_ev=self.iterated_power(M,inv=True)\n",
    "        if(first_ev.sum() <0):\n",
    "            first_ev=-first_ev\n",
    "        S=torch.exp(first_ev.view(n+1,m+1)) # enforce the difference, accelerate the convergence. \n",
    "        S=self.eps_assigment_from_mapping(S)\n",
    "        return  S\n",
    "  \n",
    "print('Gs=',len(Gs))\n",
    "model = Net(Gs,normalize=True,node_label='extended_label')\n",
    "\n",
    "#params = list(model.parameters())\n",
    "#print(len(params))\n",
    "#print(params[0])\n",
    "#print(model(input))\n",
    "print(max([G.order() for G in Gs]),len(Gs))\n",
    "print('toto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([22,  9,  2,  6,  3,  7, 10, 14])\n",
      "tensor([ 4, 66, 16, 60, 65, 10, 23, 45, 30, 57, 48, 55, 29, 40, 15])\n",
      "tensor([53, 23, 36, 53, 51,  1, 31])\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "nb=len(Gs)\n",
    "class1=torch.tensor([k for k in range(len(y)) if y[k]==1])\n",
    "class2=torch.tensor([k for k in range(len(y)) if y[k]==0])\n",
    "\n",
    "train_size=15\n",
    "test_size=7\n",
    "\n",
    "if train_size % 2 == 0:\n",
    "    nb_class1=int(train_size/2)\n",
    "    nb_class2=int(train_size/2)\n",
    "else:\n",
    "    nb_class1=int(train_size/2)+1\n",
    "    nb_class2=int(train_size/2)\n",
    "    \n",
    "if test_size % 2 == 0:\n",
    "    nb_class1_test=int(test_size/2)\n",
    "    nb_class2_test=int(test_size/2)\n",
    "else:\n",
    "    nb_class1_test=int(test_size/2)+1\n",
    "    nb_class2_test=int(test_size/2)\n",
    "    \n",
    "print((torch.abs(10000*torch.randn(nb_class1)).int()%class1.size()[0]).long())\n",
    "random_class1=class1[(torch.abs(10000*torch.randn(nb_class1)).int()%class1.size()[0]).long()]\n",
    "random_class2=class2[(torch.abs(10000*torch.randn(nb_class2)).int()%class2.size()[0]).long()]\n",
    "\n",
    "random_class1_test=class1[(torch.abs(10000*torch.randn(nb_class1_test)).int()%class1.size()[0]).long()]\n",
    "random_class2_test=class2[(torch.abs(10000*torch.randn(nb_class2_test)).int()%class2.size()[0]).long()]\n",
    "\n",
    "train_graphs=torch.cat((random_class1,random_class2),0)\n",
    "test_graphs=torch.cat((random_class1_test,random_class2_test),0)\n",
    "\n",
    "print(train_graphs)\n",
    "print(test_graphs)\n",
    "\n",
    "couples=torch.triu_indices(train_size,train_size,offset=1)\n",
    "\n",
    "\n",
    "\n",
    "#combinations=itertools.combinations(range(nb),2)\n",
    "\n",
    "nb_elt=int(train_size*(train_size-1)/2)\n",
    "data=torch.empty((nb_elt,2),dtype=torch.int)\n",
    "yt=torch.ones(nb_elt)\n",
    "\n",
    "data[0:nb_elt,0]=train_graphs[couples[0]]\n",
    "data[0:nb_elt,1]=train_graphs[couples[1]]\n",
    "print(nb_elt)\n",
    "#couples=[]\n",
    "for k in range(nb_elt):\n",
    "    if (y[data[k][0]]!=y[data[k][1]]):\n",
    "        yt[k]=-1.0        \n",
    "\n",
    "#print('data=',data)\n",
    "\n",
    "#print(couples[1:2])\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")          # a CUDA device object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "0 0.5307437181472778\n",
      "min_loss =  0.5307437181472778\n",
      "node_costs for min of the loss :  tensor([[0.0000, 0.0057, 0.0058, 0.0058, 0.0063, 0.0052, 0.0057, 0.0058, 0.0050,\n",
      "         0.0052, 0.0064, 0.0060, 0.0055, 0.0055, 0.0051, 0.0066, 0.0050, 0.0057,\n",
      "         0.0061],\n",
      "        [0.0057, 0.0000, 0.0051, 0.0052, 0.0049, 0.0060, 0.0056, 0.0064, 0.0058,\n",
      "         0.0056, 0.0050, 0.0062, 0.0052, 0.0066, 0.0049, 0.0057, 0.0066, 0.0056,\n",
      "         0.0055],\n",
      "        [0.0058, 0.0051, 0.0000, 0.0057, 0.0050, 0.0049, 0.0055, 0.0061, 0.0061,\n",
      "         0.0061, 0.0060, 0.0056, 0.0064, 0.0058, 0.0060, 0.0052, 0.0063, 0.0063,\n",
      "         0.0054],\n",
      "        [0.0058, 0.0052, 0.0057, 0.0000, 0.0049, 0.0066, 0.0056, 0.0059, 0.0060,\n",
      "         0.0054, 0.0061, 0.0053, 0.0053, 0.0052, 0.0050, 0.0054, 0.0065, 0.0052,\n",
      "         0.0060],\n",
      "        [0.0063, 0.0049, 0.0050, 0.0049, 0.0000, 0.0067, 0.0055, 0.0050, 0.0067,\n",
      "         0.0051, 0.0060, 0.0049, 0.0060, 0.0054, 0.0058, 0.0049, 0.0057, 0.0050,\n",
      "         0.0058],\n",
      "        [0.0052, 0.0060, 0.0049, 0.0066, 0.0067, 0.0000, 0.0054, 0.0059, 0.0063,\n",
      "         0.0049, 0.0049, 0.0062, 0.0059, 0.0050, 0.0063, 0.0062, 0.0058, 0.0051,\n",
      "         0.0063],\n",
      "        [0.0057, 0.0056, 0.0055, 0.0056, 0.0055, 0.0054, 0.0000, 0.0054, 0.0051,\n",
      "         0.0056, 0.0054, 0.0066, 0.0055, 0.0054, 0.0060, 0.0065, 0.0050, 0.0061,\n",
      "         0.0067],\n",
      "        [0.0058, 0.0064, 0.0061, 0.0059, 0.0050, 0.0059, 0.0054, 0.0000, 0.0051,\n",
      "         0.0050, 0.0060, 0.0064, 0.0057, 0.0054, 0.0057, 0.0052, 0.0064, 0.0059,\n",
      "         0.0064],\n",
      "        [0.0050, 0.0058, 0.0061, 0.0060, 0.0067, 0.0063, 0.0051, 0.0051, 0.0000,\n",
      "         0.0065, 0.0061, 0.0052, 0.0058, 0.0061, 0.0057, 0.0049, 0.0063, 0.0058,\n",
      "         0.0065],\n",
      "        [0.0052, 0.0056, 0.0061, 0.0054, 0.0051, 0.0049, 0.0056, 0.0050, 0.0065,\n",
      "         0.0000, 0.0067, 0.0058, 0.0062, 0.0060, 0.0052, 0.0056, 0.0060, 0.0057,\n",
      "         0.0054],\n",
      "        [0.0064, 0.0050, 0.0060, 0.0061, 0.0060, 0.0049, 0.0054, 0.0060, 0.0061,\n",
      "         0.0067, 0.0000, 0.0056, 0.0052, 0.0050, 0.0057, 0.0052, 0.0062, 0.0055,\n",
      "         0.0051],\n",
      "        [0.0060, 0.0062, 0.0056, 0.0053, 0.0049, 0.0062, 0.0066, 0.0064, 0.0052,\n",
      "         0.0058, 0.0056, 0.0000, 0.0055, 0.0059, 0.0057, 0.0057, 0.0050, 0.0053,\n",
      "         0.0062],\n",
      "        [0.0055, 0.0052, 0.0064, 0.0053, 0.0060, 0.0059, 0.0055, 0.0057, 0.0058,\n",
      "         0.0062, 0.0052, 0.0055, 0.0000, 0.0051, 0.0056, 0.0049, 0.0056, 0.0051,\n",
      "         0.0051],\n",
      "        [0.0055, 0.0066, 0.0058, 0.0052, 0.0054, 0.0050, 0.0054, 0.0054, 0.0061,\n",
      "         0.0060, 0.0050, 0.0059, 0.0051, 0.0000, 0.0051, 0.0055, 0.0050, 0.0061,\n",
      "         0.0067],\n",
      "        [0.0051, 0.0049, 0.0060, 0.0050, 0.0058, 0.0063, 0.0060, 0.0057, 0.0057,\n",
      "         0.0052, 0.0057, 0.0057, 0.0056, 0.0051, 0.0000, 0.0060, 0.0066, 0.0066,\n",
      "         0.0063],\n",
      "        [0.0066, 0.0057, 0.0052, 0.0054, 0.0049, 0.0062, 0.0065, 0.0052, 0.0049,\n",
      "         0.0056, 0.0052, 0.0057, 0.0049, 0.0055, 0.0060, 0.0000, 0.0058, 0.0051,\n",
      "         0.0055],\n",
      "        [0.0050, 0.0066, 0.0063, 0.0065, 0.0057, 0.0058, 0.0050, 0.0064, 0.0063,\n",
      "         0.0060, 0.0062, 0.0050, 0.0056, 0.0050, 0.0066, 0.0058, 0.0000, 0.0049,\n",
      "         0.0050],\n",
      "        [0.0057, 0.0056, 0.0063, 0.0052, 0.0050, 0.0051, 0.0061, 0.0059, 0.0058,\n",
      "         0.0057, 0.0055, 0.0053, 0.0051, 0.0061, 0.0066, 0.0051, 0.0049, 0.0000,\n",
      "         0.0058],\n",
      "        [0.0061, 0.0055, 0.0054, 0.0060, 0.0058, 0.0063, 0.0067, 0.0064, 0.0065,\n",
      "         0.0054, 0.0051, 0.0062, 0.0051, 0.0067, 0.0063, 0.0055, 0.0050, 0.0058,\n",
      "         0.0000]], grad_fn=<AddBackward0>)\n",
      "Distances:  tensor([0.2198, 0.2357, 0.2247, 0.2357, 0.2409, 0.1965, 0.2104, 0.2650, 0.1697,\n",
      "        0.1735, 0.1735, 0.2467, 0.1670, 0.2106, 0.2626, 0.2463, 0.2626, 0.2626,\n",
      "        0.2222, 0.2364, 0.2993, 0.1845, 0.1901, 0.1901, 0.2761, 0.1816, 0.2365,\n",
      "        0.2409, 0.2465, 0.2466, 0.2117, 0.2210, 0.2779, 0.1768, 0.1824, 0.1824,\n",
      "        0.2633, 0.1740, 0.2211, 0.2627, 0.2627, 0.2222, 0.2363, 0.2995, 0.1847,\n",
      "        0.1901, 0.1901, 0.2762, 0.1817, 0.2365, 0.2466, 0.2118, 0.2210, 0.2779,\n",
      "        0.1766, 0.1824, 0.1824, 0.2635, 0.1738, 0.2212, 0.2117, 0.2211, 0.2784,\n",
      "        0.1768, 0.1824, 0.1824, 0.2637, 0.1740, 0.2212, 0.2606, 0.3212, 0.2009,\n",
      "        0.2111, 0.2111, 0.3051, 0.1978, 0.2608, 0.3126, 0.1925, 0.2024, 0.2024,\n",
      "        0.2966, 0.1894, 0.2461, 0.1585, 0.1654, 0.1654, 0.2349, 0.1560, 0.1957,\n",
      "        0.2609, 0.2609, 0.4122, 0.2468, 0.3356, 0.2470, 0.3887, 0.2396, 0.3238,\n",
      "        0.3887, 0.2397, 0.3237, 0.1667, 0.2104, 0.3355], grad_fn=<CopySlices>)\n",
      "Loss Triangular: 0.0\n",
      "node_costs :\n",
      "tensor([[0.0000, 0.0057, 0.0058, 0.0058, 0.0063, 0.0052, 0.0057, 0.0058, 0.0050,\n",
      "         0.0052, 0.0064, 0.0060, 0.0055, 0.0055, 0.0051, 0.0066, 0.0050, 0.0057,\n",
      "         0.0061],\n",
      "        [0.0057, 0.0000, 0.0051, 0.0052, 0.0049, 0.0060, 0.0056, 0.0064, 0.0058,\n",
      "         0.0056, 0.0050, 0.0062, 0.0052, 0.0066, 0.0049, 0.0057, 0.0066, 0.0056,\n",
      "         0.0055],\n",
      "        [0.0058, 0.0051, 0.0000, 0.0057, 0.0050, 0.0049, 0.0055, 0.0061, 0.0061,\n",
      "         0.0061, 0.0060, 0.0056, 0.0064, 0.0058, 0.0060, 0.0052, 0.0063, 0.0063,\n",
      "         0.0054],\n",
      "        [0.0058, 0.0052, 0.0057, 0.0000, 0.0049, 0.0066, 0.0056, 0.0059, 0.0060,\n",
      "         0.0054, 0.0061, 0.0053, 0.0053, 0.0052, 0.0050, 0.0054, 0.0065, 0.0052,\n",
      "         0.0060],\n",
      "        [0.0063, 0.0049, 0.0050, 0.0049, 0.0000, 0.0067, 0.0055, 0.0050, 0.0067,\n",
      "         0.0051, 0.0060, 0.0049, 0.0060, 0.0054, 0.0058, 0.0049, 0.0057, 0.0050,\n",
      "         0.0058],\n",
      "        [0.0052, 0.0060, 0.0049, 0.0066, 0.0067, 0.0000, 0.0054, 0.0059, 0.0063,\n",
      "         0.0049, 0.0049, 0.0062, 0.0059, 0.0050, 0.0063, 0.0062, 0.0058, 0.0051,\n",
      "         0.0063],\n",
      "        [0.0057, 0.0056, 0.0055, 0.0056, 0.0055, 0.0054, 0.0000, 0.0054, 0.0051,\n",
      "         0.0056, 0.0054, 0.0066, 0.0055, 0.0054, 0.0060, 0.0065, 0.0050, 0.0061,\n",
      "         0.0067],\n",
      "        [0.0058, 0.0064, 0.0061, 0.0059, 0.0050, 0.0059, 0.0054, 0.0000, 0.0051,\n",
      "         0.0050, 0.0060, 0.0064, 0.0057, 0.0054, 0.0057, 0.0052, 0.0064, 0.0059,\n",
      "         0.0064],\n",
      "        [0.0050, 0.0058, 0.0061, 0.0060, 0.0067, 0.0063, 0.0051, 0.0051, 0.0000,\n",
      "         0.0065, 0.0061, 0.0052, 0.0058, 0.0061, 0.0057, 0.0049, 0.0063, 0.0058,\n",
      "         0.0065],\n",
      "        [0.0052, 0.0056, 0.0061, 0.0054, 0.0051, 0.0049, 0.0056, 0.0050, 0.0065,\n",
      "         0.0000, 0.0067, 0.0058, 0.0062, 0.0060, 0.0052, 0.0056, 0.0060, 0.0057,\n",
      "         0.0054],\n",
      "        [0.0064, 0.0050, 0.0060, 0.0061, 0.0060, 0.0049, 0.0054, 0.0060, 0.0061,\n",
      "         0.0067, 0.0000, 0.0056, 0.0052, 0.0050, 0.0057, 0.0052, 0.0062, 0.0055,\n",
      "         0.0051],\n",
      "        [0.0060, 0.0062, 0.0056, 0.0053, 0.0049, 0.0062, 0.0066, 0.0064, 0.0052,\n",
      "         0.0058, 0.0056, 0.0000, 0.0055, 0.0059, 0.0057, 0.0057, 0.0050, 0.0053,\n",
      "         0.0062],\n",
      "        [0.0055, 0.0052, 0.0064, 0.0053, 0.0060, 0.0059, 0.0055, 0.0057, 0.0058,\n",
      "         0.0062, 0.0052, 0.0055, 0.0000, 0.0051, 0.0056, 0.0049, 0.0056, 0.0051,\n",
      "         0.0051],\n",
      "        [0.0055, 0.0066, 0.0058, 0.0052, 0.0054, 0.0050, 0.0054, 0.0054, 0.0061,\n",
      "         0.0060, 0.0050, 0.0059, 0.0051, 0.0000, 0.0051, 0.0055, 0.0050, 0.0061,\n",
      "         0.0067],\n",
      "        [0.0051, 0.0049, 0.0060, 0.0050, 0.0058, 0.0063, 0.0060, 0.0057, 0.0057,\n",
      "         0.0052, 0.0057, 0.0057, 0.0056, 0.0051, 0.0000, 0.0060, 0.0066, 0.0066,\n",
      "         0.0063],\n",
      "        [0.0066, 0.0057, 0.0052, 0.0054, 0.0049, 0.0062, 0.0065, 0.0052, 0.0049,\n",
      "         0.0056, 0.0052, 0.0057, 0.0049, 0.0055, 0.0060, 0.0000, 0.0058, 0.0051,\n",
      "         0.0055],\n",
      "        [0.0050, 0.0066, 0.0063, 0.0065, 0.0057, 0.0058, 0.0050, 0.0064, 0.0063,\n",
      "         0.0060, 0.0062, 0.0050, 0.0056, 0.0050, 0.0066, 0.0058, 0.0000, 0.0049,\n",
      "         0.0050],\n",
      "        [0.0057, 0.0056, 0.0063, 0.0052, 0.0050, 0.0051, 0.0061, 0.0059, 0.0058,\n",
      "         0.0057, 0.0055, 0.0053, 0.0051, 0.0061, 0.0066, 0.0051, 0.0049, 0.0000,\n",
      "         0.0058],\n",
      "        [0.0061, 0.0055, 0.0054, 0.0060, 0.0058, 0.0063, 0.0067, 0.0064, 0.0065,\n",
      "         0.0054, 0.0051, 0.0062, 0.0051, 0.0067, 0.0063, 0.0055, 0.0050, 0.0058,\n",
      "         0.0000]], grad_fn=<AddBackward0>)\n",
      "nodeInsDel: tensor(0.0050, grad_fn=<SelectBackward>)\n",
      "edge_costs :\n",
      "tensor([[0.0000, 0.0055, 0.0057],\n",
      "        [0.0055, 0.0000, 0.0053],\n",
      "        [0.0057, 0.0053, 0.0000]], grad_fn=<AddBackward0>)\n",
      "edgeInsDel: tensor(0.0064, grad_fn=<SelectBackward>)\n",
      "min_loss =  0.5307437181472778\n",
      "iter_min_loss =  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5302354097366333\n",
      "min_loss =  0.5302354097366333\n",
      "node_costs for min of the loss :  tensor([[0.0000, 0.0056, 0.0057, 0.0057, 0.0064, 0.0050, 0.0056, 0.0057, 0.0048,\n",
      "         0.0051, 0.0065, 0.0059, 0.0053, 0.0053, 0.0050, 0.0067, 0.0048, 0.0057,\n",
      "         0.0060],\n",
      "        [0.0056, 0.0000, 0.0049, 0.0050, 0.0047, 0.0060, 0.0055, 0.0065, 0.0057,\n",
      "         0.0055, 0.0048, 0.0062, 0.0050, 0.0067, 0.0047, 0.0056, 0.0067, 0.0055,\n",
      "         0.0054],\n",
      "        [0.0057, 0.0049, 0.0000, 0.0056, 0.0047, 0.0047, 0.0054, 0.0061, 0.0061,\n",
      "         0.0061, 0.0059, 0.0055, 0.0064, 0.0058, 0.0059, 0.0050, 0.0063, 0.0063,\n",
      "         0.0053],\n",
      "        [0.0057, 0.0050, 0.0056, 0.0000, 0.0047, 0.0066, 0.0055, 0.0059, 0.0060,\n",
      "         0.0052, 0.0061, 0.0052, 0.0051, 0.0050, 0.0048, 0.0052, 0.0065, 0.0050,\n",
      "         0.0060],\n",
      "        [0.0064, 0.0047, 0.0047, 0.0047, 0.0000, 0.0067, 0.0054, 0.0048, 0.0068,\n",
      "         0.0050, 0.0060, 0.0046, 0.0060, 0.0053, 0.0058, 0.0047, 0.0056, 0.0048,\n",
      "         0.0058],\n",
      "        [0.0050, 0.0060, 0.0047, 0.0066, 0.0067, 0.0000, 0.0053, 0.0058, 0.0064,\n",
      "         0.0047, 0.0046, 0.0062, 0.0059, 0.0048, 0.0064, 0.0062, 0.0057, 0.0049,\n",
      "         0.0064],\n",
      "        [0.0056, 0.0055, 0.0054, 0.0055, 0.0054, 0.0053, 0.0000, 0.0053, 0.0050,\n",
      "         0.0055, 0.0053, 0.0067, 0.0054, 0.0053, 0.0060, 0.0066, 0.0048, 0.0061,\n",
      "         0.0068],\n",
      "        [0.0057, 0.0065, 0.0061, 0.0059, 0.0048, 0.0058, 0.0053, 0.0000, 0.0050,\n",
      "         0.0049, 0.0060, 0.0065, 0.0056, 0.0052, 0.0056, 0.0051, 0.0064, 0.0058,\n",
      "         0.0064],\n",
      "        [0.0048, 0.0057, 0.0061, 0.0060, 0.0068, 0.0064, 0.0050, 0.0050, 0.0000,\n",
      "         0.0065, 0.0061, 0.0051, 0.0057, 0.0060, 0.0056, 0.0047, 0.0064, 0.0057,\n",
      "         0.0065],\n",
      "        [0.0051, 0.0055, 0.0061, 0.0052, 0.0050, 0.0047, 0.0055, 0.0049, 0.0065,\n",
      "         0.0000, 0.0068, 0.0057, 0.0062, 0.0059, 0.0050, 0.0055, 0.0060, 0.0056,\n",
      "         0.0053],\n",
      "        [0.0065, 0.0048, 0.0059, 0.0061, 0.0060, 0.0046, 0.0053, 0.0060, 0.0061,\n",
      "         0.0068, 0.0000, 0.0055, 0.0050, 0.0047, 0.0056, 0.0050, 0.0062, 0.0053,\n",
      "         0.0049],\n",
      "        [0.0059, 0.0062, 0.0055, 0.0052, 0.0046, 0.0062, 0.0067, 0.0065, 0.0051,\n",
      "         0.0057, 0.0055, 0.0000, 0.0054, 0.0058, 0.0056, 0.0056, 0.0048, 0.0052,\n",
      "         0.0062],\n",
      "        [0.0053, 0.0050, 0.0064, 0.0051, 0.0060, 0.0059, 0.0054, 0.0056, 0.0057,\n",
      "         0.0062, 0.0050, 0.0054, 0.0000, 0.0049, 0.0055, 0.0047, 0.0055, 0.0049,\n",
      "         0.0049],\n",
      "        [0.0053, 0.0067, 0.0058, 0.0050, 0.0053, 0.0048, 0.0053, 0.0052, 0.0060,\n",
      "         0.0059, 0.0047, 0.0058, 0.0049, 0.0000, 0.0049, 0.0054, 0.0048, 0.0061,\n",
      "         0.0067],\n",
      "        [0.0050, 0.0047, 0.0059, 0.0048, 0.0058, 0.0064, 0.0060, 0.0056, 0.0056,\n",
      "         0.0050, 0.0056, 0.0056, 0.0055, 0.0049, 0.0000, 0.0060, 0.0067, 0.0067,\n",
      "         0.0064],\n",
      "        [0.0067, 0.0056, 0.0050, 0.0052, 0.0047, 0.0062, 0.0066, 0.0051, 0.0047,\n",
      "         0.0055, 0.0050, 0.0056, 0.0047, 0.0054, 0.0060, 0.0000, 0.0058, 0.0049,\n",
      "         0.0054],\n",
      "        [0.0048, 0.0067, 0.0063, 0.0065, 0.0056, 0.0057, 0.0048, 0.0064, 0.0064,\n",
      "         0.0060, 0.0062, 0.0048, 0.0055, 0.0048, 0.0067, 0.0058, 0.0000, 0.0047,\n",
      "         0.0047],\n",
      "        [0.0057, 0.0055, 0.0063, 0.0050, 0.0048, 0.0049, 0.0061, 0.0058, 0.0057,\n",
      "         0.0056, 0.0053, 0.0052, 0.0049, 0.0061, 0.0067, 0.0049, 0.0047, 0.0000,\n",
      "         0.0057],\n",
      "        [0.0060, 0.0054, 0.0053, 0.0060, 0.0058, 0.0064, 0.0068, 0.0064, 0.0065,\n",
      "         0.0053, 0.0049, 0.0062, 0.0049, 0.0067, 0.0064, 0.0054, 0.0047, 0.0057,\n",
      "         0.0000]], grad_fn=<AddBackward0>)\n",
      "2 0.5298945903778076\n",
      "min_loss =  0.5298945903778076\n",
      "node_costs for min of the loss :  tensor([[0.0000, 0.0054, 0.0056, 0.0056, 0.0063, 0.0047, 0.0054, 0.0056, 0.0045,\n",
      "         0.0048, 0.0065, 0.0058, 0.0051, 0.0051, 0.0047, 0.0067, 0.0045, 0.0055,\n",
      "         0.0060],\n",
      "        [0.0054, 0.0000, 0.0046, 0.0047, 0.0044, 0.0059, 0.0053, 0.0065, 0.0055,\n",
      "         0.0053, 0.0045, 0.0061, 0.0047, 0.0068, 0.0044, 0.0054, 0.0067, 0.0053,\n",
      "         0.0051],\n",
      "        [0.0056, 0.0046, 0.0000, 0.0055, 0.0044, 0.0044, 0.0051, 0.0060, 0.0060,\n",
      "         0.0061, 0.0058, 0.0053, 0.0064, 0.0056, 0.0058, 0.0048, 0.0063, 0.0062,\n",
      "         0.0051],\n",
      "        [0.0056, 0.0047, 0.0055, 0.0000, 0.0043, 0.0067, 0.0054, 0.0058, 0.0059,\n",
      "         0.0050, 0.0060, 0.0049, 0.0048, 0.0047, 0.0045, 0.0050, 0.0065, 0.0047,\n",
      "         0.0059],\n",
      "        [0.0063, 0.0044, 0.0044, 0.0043, 0.0000, 0.0068, 0.0052, 0.0044, 0.0068,\n",
      "         0.0047, 0.0059, 0.0043, 0.0059, 0.0051, 0.0056, 0.0044, 0.0054, 0.0045,\n",
      "         0.0056],\n",
      "        [0.0047, 0.0059, 0.0044, 0.0067, 0.0068, 0.0000, 0.0050, 0.0057, 0.0064,\n",
      "         0.0043, 0.0043, 0.0061, 0.0058, 0.0045, 0.0063, 0.0061, 0.0056, 0.0047,\n",
      "         0.0063],\n",
      "        [0.0054, 0.0053, 0.0051, 0.0054, 0.0052, 0.0050, 0.0000, 0.0051, 0.0047,\n",
      "         0.0053, 0.0051, 0.0068, 0.0052, 0.0051, 0.0059, 0.0066, 0.0045, 0.0060,\n",
      "         0.0069],\n",
      "        [0.0056, 0.0065, 0.0060, 0.0058, 0.0044, 0.0057, 0.0051, 0.0000, 0.0047,\n",
      "         0.0045, 0.0059, 0.0065, 0.0054, 0.0050, 0.0054, 0.0048, 0.0064, 0.0057,\n",
      "         0.0064],\n",
      "        [0.0045, 0.0055, 0.0060, 0.0059, 0.0068, 0.0064, 0.0047, 0.0047, 0.0000,\n",
      "         0.0065, 0.0060, 0.0048, 0.0056, 0.0059, 0.0055, 0.0043, 0.0063, 0.0056,\n",
      "         0.0066],\n",
      "        [0.0048, 0.0053, 0.0061, 0.0050, 0.0047, 0.0043, 0.0053, 0.0045, 0.0065,\n",
      "         0.0000, 0.0069, 0.0056, 0.0061, 0.0058, 0.0048, 0.0053, 0.0059, 0.0054,\n",
      "         0.0051],\n",
      "        [0.0065, 0.0045, 0.0058, 0.0060, 0.0059, 0.0043, 0.0051, 0.0059, 0.0060,\n",
      "         0.0069, 0.0000, 0.0053, 0.0047, 0.0044, 0.0054, 0.0047, 0.0062, 0.0051,\n",
      "         0.0046],\n",
      "        [0.0058, 0.0061, 0.0053, 0.0049, 0.0043, 0.0061, 0.0068, 0.0065, 0.0048,\n",
      "         0.0056, 0.0053, 0.0000, 0.0052, 0.0057, 0.0054, 0.0054, 0.0045, 0.0049,\n",
      "         0.0062],\n",
      "        [0.0051, 0.0047, 0.0064, 0.0048, 0.0059, 0.0058, 0.0052, 0.0054, 0.0056,\n",
      "         0.0061, 0.0047, 0.0052, 0.0000, 0.0046, 0.0053, 0.0043, 0.0053, 0.0046,\n",
      "         0.0046],\n",
      "        [0.0051, 0.0068, 0.0056, 0.0047, 0.0051, 0.0045, 0.0051, 0.0050, 0.0059,\n",
      "         0.0058, 0.0044, 0.0057, 0.0046, 0.0000, 0.0046, 0.0052, 0.0045, 0.0060,\n",
      "         0.0068],\n",
      "        [0.0047, 0.0044, 0.0058, 0.0045, 0.0056, 0.0063, 0.0059, 0.0054, 0.0055,\n",
      "         0.0048, 0.0054, 0.0054, 0.0053, 0.0046, 0.0000, 0.0059, 0.0067, 0.0068,\n",
      "         0.0063],\n",
      "        [0.0067, 0.0054, 0.0048, 0.0050, 0.0044, 0.0061, 0.0066, 0.0048, 0.0043,\n",
      "         0.0053, 0.0047, 0.0054, 0.0043, 0.0052, 0.0059, 0.0000, 0.0056, 0.0046,\n",
      "         0.0052],\n",
      "        [0.0045, 0.0067, 0.0063, 0.0065, 0.0054, 0.0056, 0.0045, 0.0064, 0.0063,\n",
      "         0.0059, 0.0062, 0.0045, 0.0053, 0.0045, 0.0067, 0.0056, 0.0000, 0.0044,\n",
      "         0.0044],\n",
      "        [0.0055, 0.0053, 0.0062, 0.0047, 0.0045, 0.0047, 0.0060, 0.0057, 0.0056,\n",
      "         0.0054, 0.0051, 0.0049, 0.0046, 0.0060, 0.0068, 0.0046, 0.0044, 0.0000,\n",
      "         0.0056],\n",
      "        [0.0060, 0.0051, 0.0051, 0.0059, 0.0056, 0.0063, 0.0069, 0.0064, 0.0066,\n",
      "         0.0051, 0.0046, 0.0062, 0.0046, 0.0068, 0.0063, 0.0052, 0.0044, 0.0056,\n",
      "         0.0000]], grad_fn=<AddBackward0>)\n",
      "3 0.5296828746795654\n",
      "min_loss =  0.5296828746795654\n",
      "node_costs for min of the loss :  tensor([[0.0000, 0.0051, 0.0053, 0.0053, 0.0062, 0.0043, 0.0051, 0.0052, 0.0040,\n",
      "         0.0043, 0.0064, 0.0055, 0.0047, 0.0047, 0.0042, 0.0066, 0.0040, 0.0052,\n",
      "         0.0057],\n",
      "        [0.0051, 0.0000, 0.0041, 0.0042, 0.0038, 0.0057, 0.0049, 0.0063, 0.0052,\n",
      "         0.0049, 0.0040, 0.0059, 0.0042, 0.0067, 0.0038, 0.0051, 0.0066, 0.0049,\n",
      "         0.0047],\n",
      "        [0.0053, 0.0041, 0.0000, 0.0051, 0.0039, 0.0038, 0.0047, 0.0058, 0.0058,\n",
      "         0.0059, 0.0055, 0.0050, 0.0062, 0.0053, 0.0056, 0.0043, 0.0061, 0.0060,\n",
      "         0.0047],\n",
      "        [0.0053, 0.0042, 0.0051, 0.0000, 0.0038, 0.0066, 0.0050, 0.0055, 0.0056,\n",
      "         0.0046, 0.0058, 0.0045, 0.0044, 0.0043, 0.0040, 0.0046, 0.0064, 0.0043,\n",
      "         0.0056],\n",
      "        [0.0062, 0.0038, 0.0039, 0.0038, 0.0000, 0.0068, 0.0048, 0.0039, 0.0068,\n",
      "         0.0042, 0.0056, 0.0037, 0.0057, 0.0046, 0.0053, 0.0039, 0.0050, 0.0040,\n",
      "         0.0053],\n",
      "        [0.0043, 0.0057, 0.0038, 0.0066, 0.0068, 0.0000, 0.0046, 0.0054, 0.0062,\n",
      "         0.0038, 0.0037, 0.0059, 0.0055, 0.0039, 0.0062, 0.0059, 0.0052, 0.0042,\n",
      "         0.0062],\n",
      "        [0.0051, 0.0049, 0.0047, 0.0050, 0.0048, 0.0046, 0.0000, 0.0047, 0.0042,\n",
      "         0.0049, 0.0047, 0.0067, 0.0048, 0.0047, 0.0057, 0.0065, 0.0039, 0.0057,\n",
      "         0.0068],\n",
      "        [0.0052, 0.0063, 0.0058, 0.0055, 0.0039, 0.0054, 0.0047, 0.0000, 0.0042,\n",
      "         0.0040, 0.0056, 0.0064, 0.0050, 0.0045, 0.0051, 0.0043, 0.0063, 0.0054,\n",
      "         0.0063],\n",
      "        [0.0040, 0.0052, 0.0058, 0.0056, 0.0068, 0.0062, 0.0042, 0.0042, 0.0000,\n",
      "         0.0064, 0.0058, 0.0043, 0.0053, 0.0057, 0.0051, 0.0038, 0.0062, 0.0053,\n",
      "         0.0065],\n",
      "        [0.0043, 0.0049, 0.0059, 0.0046, 0.0042, 0.0038, 0.0049, 0.0040, 0.0064,\n",
      "         0.0000, 0.0068, 0.0052, 0.0059, 0.0055, 0.0043, 0.0050, 0.0056, 0.0051,\n",
      "         0.0047],\n",
      "        [0.0064, 0.0040, 0.0055, 0.0058, 0.0056, 0.0037, 0.0047, 0.0056, 0.0058,\n",
      "         0.0068, 0.0000, 0.0049, 0.0042, 0.0039, 0.0051, 0.0043, 0.0060, 0.0047,\n",
      "         0.0041],\n",
      "        [0.0055, 0.0059, 0.0050, 0.0045, 0.0037, 0.0059, 0.0067, 0.0064, 0.0043,\n",
      "         0.0052, 0.0049, 0.0000, 0.0048, 0.0054, 0.0050, 0.0051, 0.0039, 0.0045,\n",
      "         0.0060],\n",
      "        [0.0047, 0.0042, 0.0062, 0.0044, 0.0057, 0.0055, 0.0048, 0.0050, 0.0053,\n",
      "         0.0059, 0.0042, 0.0048, 0.0000, 0.0041, 0.0050, 0.0038, 0.0050, 0.0041,\n",
      "         0.0041],\n",
      "        [0.0047, 0.0067, 0.0053, 0.0043, 0.0046, 0.0039, 0.0047, 0.0045, 0.0057,\n",
      "         0.0055, 0.0039, 0.0054, 0.0041, 0.0000, 0.0041, 0.0048, 0.0040, 0.0058,\n",
      "         0.0068],\n",
      "        [0.0042, 0.0038, 0.0056, 0.0040, 0.0053, 0.0062, 0.0057, 0.0051, 0.0051,\n",
      "         0.0043, 0.0051, 0.0050, 0.0050, 0.0041, 0.0000, 0.0057, 0.0067, 0.0067,\n",
      "         0.0062],\n",
      "        [0.0066, 0.0051, 0.0043, 0.0046, 0.0039, 0.0059, 0.0065, 0.0043, 0.0038,\n",
      "         0.0050, 0.0043, 0.0051, 0.0038, 0.0048, 0.0057, 0.0000, 0.0053, 0.0041,\n",
      "         0.0048],\n",
      "        [0.0040, 0.0066, 0.0061, 0.0064, 0.0050, 0.0052, 0.0039, 0.0063, 0.0062,\n",
      "         0.0056, 0.0060, 0.0039, 0.0050, 0.0040, 0.0067, 0.0053, 0.0000, 0.0039,\n",
      "         0.0039],\n",
      "        [0.0052, 0.0049, 0.0060, 0.0043, 0.0040, 0.0042, 0.0057, 0.0054, 0.0053,\n",
      "         0.0051, 0.0047, 0.0045, 0.0041, 0.0058, 0.0067, 0.0041, 0.0039, 0.0000,\n",
      "         0.0053],\n",
      "        [0.0057, 0.0047, 0.0047, 0.0056, 0.0053, 0.0062, 0.0068, 0.0063, 0.0065,\n",
      "         0.0047, 0.0041, 0.0060, 0.0041, 0.0068, 0.0062, 0.0048, 0.0039, 0.0053,\n",
      "         0.0000]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.5295997262001038\n",
      "min_loss =  0.5295997262001038\n",
      "node_costs for min of the loss :  tensor([[0.0000, 0.0044, 0.0046, 0.0046, 0.0057, 0.0035, 0.0044, 0.0046, 0.0031,\n",
      "         0.0035, 0.0059, 0.0049, 0.0039, 0.0039, 0.0034, 0.0062, 0.0032, 0.0045,\n",
      "         0.0051],\n",
      "        [0.0044, 0.0000, 0.0033, 0.0034, 0.0029, 0.0051, 0.0042, 0.0059, 0.0045,\n",
      "         0.0042, 0.0032, 0.0054, 0.0034, 0.0063, 0.0030, 0.0044, 0.0062, 0.0042,\n",
      "         0.0040],\n",
      "        [0.0046, 0.0033, 0.0000, 0.0045, 0.0030, 0.0030, 0.0040, 0.0052, 0.0052,\n",
      "         0.0053, 0.0049, 0.0043, 0.0058, 0.0047, 0.0050, 0.0035, 0.0056, 0.0055,\n",
      "         0.0039],\n",
      "        [0.0046, 0.0034, 0.0045, 0.0000, 0.0029, 0.0062, 0.0043, 0.0049, 0.0050,\n",
      "         0.0038, 0.0052, 0.0037, 0.0036, 0.0034, 0.0032, 0.0038, 0.0060, 0.0034,\n",
      "         0.0050],\n",
      "        [0.0057, 0.0029, 0.0030, 0.0029, 0.0000, 0.0064, 0.0041, 0.0031, 0.0064,\n",
      "         0.0034, 0.0050, 0.0029, 0.0051, 0.0039, 0.0047, 0.0030, 0.0043, 0.0031,\n",
      "         0.0047],\n",
      "        [0.0035, 0.0051, 0.0030, 0.0062, 0.0064, 0.0000, 0.0038, 0.0047, 0.0057,\n",
      "         0.0029, 0.0029, 0.0053, 0.0048, 0.0031, 0.0057, 0.0053, 0.0046, 0.0033,\n",
      "         0.0057],\n",
      "        [0.0044, 0.0042, 0.0040, 0.0043, 0.0041, 0.0038, 0.0000, 0.0039, 0.0033,\n",
      "         0.0042, 0.0039, 0.0064, 0.0040, 0.0039, 0.0051, 0.0061, 0.0031, 0.0052,\n",
      "         0.0065],\n",
      "        [0.0046, 0.0059, 0.0052, 0.0049, 0.0031, 0.0047, 0.0039, 0.0000, 0.0033,\n",
      "         0.0032, 0.0050, 0.0059, 0.0043, 0.0037, 0.0044, 0.0035, 0.0059, 0.0047,\n",
      "         0.0058],\n",
      "        [0.0031, 0.0045, 0.0052, 0.0050, 0.0064, 0.0057, 0.0033, 0.0033, 0.0000,\n",
      "         0.0060, 0.0052, 0.0035, 0.0046, 0.0051, 0.0044, 0.0029, 0.0057, 0.0046,\n",
      "         0.0060],\n",
      "        [0.0035, 0.0042, 0.0053, 0.0038, 0.0034, 0.0029, 0.0042, 0.0032, 0.0060,\n",
      "         0.0000, 0.0065, 0.0046, 0.0054, 0.0049, 0.0035, 0.0043, 0.0050, 0.0044,\n",
      "         0.0039],\n",
      "        [0.0059, 0.0032, 0.0049, 0.0052, 0.0050, 0.0029, 0.0039, 0.0050, 0.0052,\n",
      "         0.0065, 0.0000, 0.0042, 0.0034, 0.0030, 0.0044, 0.0035, 0.0054, 0.0039,\n",
      "         0.0032],\n",
      "        [0.0049, 0.0054, 0.0043, 0.0037, 0.0029, 0.0053, 0.0064, 0.0059, 0.0035,\n",
      "         0.0046, 0.0042, 0.0000, 0.0041, 0.0048, 0.0043, 0.0044, 0.0031, 0.0037,\n",
      "         0.0055],\n",
      "        [0.0039, 0.0034, 0.0058, 0.0036, 0.0051, 0.0048, 0.0040, 0.0043, 0.0046,\n",
      "         0.0054, 0.0034, 0.0041, 0.0000, 0.0033, 0.0043, 0.0029, 0.0043, 0.0032,\n",
      "         0.0033],\n",
      "        [0.0039, 0.0063, 0.0047, 0.0034, 0.0039, 0.0031, 0.0039, 0.0037, 0.0051,\n",
      "         0.0049, 0.0030, 0.0048, 0.0033, 0.0000, 0.0033, 0.0041, 0.0031, 0.0052,\n",
      "         0.0064],\n",
      "        [0.0034, 0.0030, 0.0050, 0.0032, 0.0047, 0.0057, 0.0051, 0.0044, 0.0044,\n",
      "         0.0035, 0.0044, 0.0043, 0.0043, 0.0033, 0.0000, 0.0051, 0.0063, 0.0063,\n",
      "         0.0057],\n",
      "        [0.0062, 0.0044, 0.0035, 0.0038, 0.0030, 0.0053, 0.0061, 0.0035, 0.0029,\n",
      "         0.0043, 0.0035, 0.0044, 0.0029, 0.0041, 0.0051, 0.0000, 0.0047, 0.0033,\n",
      "         0.0041],\n",
      "        [0.0032, 0.0062, 0.0056, 0.0060, 0.0043, 0.0046, 0.0031, 0.0059, 0.0057,\n",
      "         0.0050, 0.0054, 0.0031, 0.0043, 0.0031, 0.0063, 0.0047, 0.0000, 0.0030,\n",
      "         0.0030],\n",
      "        [0.0045, 0.0042, 0.0055, 0.0034, 0.0031, 0.0033, 0.0052, 0.0047, 0.0046,\n",
      "         0.0044, 0.0039, 0.0037, 0.0032, 0.0052, 0.0063, 0.0033, 0.0030, 0.0000,\n",
      "         0.0046],\n",
      "        [0.0051, 0.0040, 0.0039, 0.0050, 0.0047, 0.0057, 0.0065, 0.0058, 0.0060,\n",
      "         0.0039, 0.0032, 0.0055, 0.0033, 0.0064, 0.0057, 0.0041, 0.0030, 0.0046,\n",
      "         0.0000]], grad_fn=<AddBackward0>)\n",
      "5 0.5295218825340271\n",
      "min_loss =  0.5295218825340271\n",
      "node_costs for min of the loss :  tensor([[0.0000, 0.0035, 0.0038, 0.0037, 0.0049, 0.0025, 0.0035, 0.0037, 0.0022,\n",
      "         0.0026, 0.0052, 0.0041, 0.0030, 0.0030, 0.0024, 0.0055, 0.0022, 0.0036,\n",
      "         0.0043],\n",
      "        [0.0035, 0.0000, 0.0023, 0.0024, 0.0020, 0.0042, 0.0033, 0.0051, 0.0036,\n",
      "         0.0033, 0.0022, 0.0046, 0.0024, 0.0056, 0.0020, 0.0035, 0.0055, 0.0033,\n",
      "         0.0031],\n",
      "        [0.0038, 0.0023, 0.0000, 0.0036, 0.0021, 0.0020, 0.0031, 0.0044, 0.0044,\n",
      "         0.0045, 0.0041, 0.0034, 0.0050, 0.0038, 0.0041, 0.0026, 0.0048, 0.0048,\n",
      "         0.0030],\n",
      "        [0.0037, 0.0024, 0.0036, 0.0000, 0.0020, 0.0055, 0.0034, 0.0040, 0.0042,\n",
      "         0.0029, 0.0044, 0.0027, 0.0026, 0.0025, 0.0022, 0.0028, 0.0052, 0.0025,\n",
      "         0.0042],\n",
      "        [0.0049, 0.0020, 0.0021, 0.0020, 0.0000, 0.0057, 0.0031, 0.0021, 0.0057,\n",
      "         0.0024, 0.0042, 0.0019, 0.0043, 0.0030, 0.0038, 0.0020, 0.0034, 0.0022,\n",
      "         0.0038],\n",
      "        [0.0025, 0.0042, 0.0020, 0.0055, 0.0057, 0.0000, 0.0029, 0.0038, 0.0049,\n",
      "         0.0020, 0.0019, 0.0045, 0.0040, 0.0021, 0.0049, 0.0045, 0.0037, 0.0024,\n",
      "         0.0049],\n",
      "        [0.0035, 0.0033, 0.0031, 0.0034, 0.0031, 0.0029, 0.0000, 0.0030, 0.0024,\n",
      "         0.0033, 0.0030, 0.0056, 0.0031, 0.0030, 0.0043, 0.0054, 0.0021, 0.0044,\n",
      "         0.0058],\n",
      "        [0.0037, 0.0051, 0.0044, 0.0040, 0.0021, 0.0038, 0.0030, 0.0000, 0.0024,\n",
      "         0.0022, 0.0042, 0.0051, 0.0034, 0.0028, 0.0035, 0.0026, 0.0051, 0.0039,\n",
      "         0.0050],\n",
      "        [0.0022, 0.0036, 0.0044, 0.0042, 0.0057, 0.0049, 0.0024, 0.0024, 0.0000,\n",
      "         0.0052, 0.0044, 0.0026, 0.0037, 0.0043, 0.0036, 0.0019, 0.0049, 0.0038,\n",
      "         0.0053],\n",
      "        [0.0026, 0.0033, 0.0045, 0.0029, 0.0024, 0.0020, 0.0033, 0.0022, 0.0052,\n",
      "         0.0000, 0.0058, 0.0037, 0.0046, 0.0041, 0.0026, 0.0034, 0.0042, 0.0035,\n",
      "         0.0030],\n",
      "        [0.0052, 0.0022, 0.0041, 0.0044, 0.0042, 0.0019, 0.0030, 0.0042, 0.0044,\n",
      "         0.0058, 0.0000, 0.0033, 0.0025, 0.0021, 0.0035, 0.0025, 0.0046, 0.0030,\n",
      "         0.0023],\n",
      "        [0.0041, 0.0046, 0.0034, 0.0027, 0.0019, 0.0045, 0.0056, 0.0051, 0.0026,\n",
      "         0.0037, 0.0033, 0.0000, 0.0031, 0.0039, 0.0035, 0.0035, 0.0021, 0.0028,\n",
      "         0.0047],\n",
      "        [0.0030, 0.0024, 0.0050, 0.0026, 0.0043, 0.0040, 0.0031, 0.0034, 0.0037,\n",
      "         0.0046, 0.0025, 0.0031, 0.0000, 0.0023, 0.0034, 0.0020, 0.0034, 0.0023,\n",
      "         0.0023],\n",
      "        [0.0030, 0.0056, 0.0038, 0.0025, 0.0030, 0.0021, 0.0030, 0.0028, 0.0043,\n",
      "         0.0041, 0.0021, 0.0039, 0.0023, 0.0000, 0.0023, 0.0031, 0.0022, 0.0044,\n",
      "         0.0057],\n",
      "        [0.0024, 0.0020, 0.0041, 0.0022, 0.0038, 0.0049, 0.0043, 0.0035, 0.0036,\n",
      "         0.0026, 0.0035, 0.0035, 0.0034, 0.0023, 0.0000, 0.0042, 0.0055, 0.0056,\n",
      "         0.0049],\n",
      "        [0.0055, 0.0035, 0.0026, 0.0028, 0.0020, 0.0045, 0.0054, 0.0026, 0.0019,\n",
      "         0.0034, 0.0025, 0.0035, 0.0020, 0.0031, 0.0042, 0.0000, 0.0038, 0.0024,\n",
      "         0.0032],\n",
      "        [0.0022, 0.0055, 0.0048, 0.0052, 0.0034, 0.0037, 0.0021, 0.0051, 0.0049,\n",
      "         0.0042, 0.0046, 0.0021, 0.0034, 0.0022, 0.0055, 0.0038, 0.0000, 0.0021,\n",
      "         0.0021],\n",
      "        [0.0036, 0.0033, 0.0048, 0.0025, 0.0022, 0.0024, 0.0044, 0.0039, 0.0038,\n",
      "         0.0035, 0.0030, 0.0028, 0.0023, 0.0044, 0.0056, 0.0024, 0.0021, 0.0000,\n",
      "         0.0038],\n",
      "        [0.0043, 0.0031, 0.0030, 0.0042, 0.0038, 0.0049, 0.0058, 0.0050, 0.0053,\n",
      "         0.0030, 0.0023, 0.0047, 0.0023, 0.0057, 0.0049, 0.0032, 0.0021, 0.0038,\n",
      "         0.0000]], grad_fn=<AddBackward0>)\n",
      "6 0.529486894607544\n",
      "min_loss =  0.529486894607544\n",
      "node_costs for min of the loss :  tensor([[0.0000, 0.0023, 0.0025, 0.0025, 0.0038, 0.0014, 0.0023, 0.0025, 0.0011,\n",
      "         0.0014, 0.0040, 0.0028, 0.0018, 0.0018, 0.0013, 0.0044, 0.0011, 0.0024,\n",
      "         0.0031],\n",
      "        [0.0023, 0.0000, 0.0012, 0.0013, 0.0010, 0.0030, 0.0021, 0.0040, 0.0024,\n",
      "         0.0021, 0.0011, 0.0033, 0.0013, 0.0045, 0.0010, 0.0023, 0.0044, 0.0021,\n",
      "         0.0019],\n",
      "        [0.0025, 0.0012, 0.0000, 0.0023, 0.0010, 0.0010, 0.0019, 0.0031, 0.0031,\n",
      "         0.0032, 0.0028, 0.0021, 0.0039, 0.0026, 0.0029, 0.0014, 0.0037, 0.0035,\n",
      "         0.0018],\n",
      "        [0.0025, 0.0013, 0.0023, 0.0000, 0.0009, 0.0044, 0.0022, 0.0028, 0.0029,\n",
      "         0.0017, 0.0031, 0.0016, 0.0015, 0.0014, 0.0011, 0.0017, 0.0041, 0.0014,\n",
      "         0.0029],\n",
      "        [0.0038, 0.0010, 0.0010, 0.0009, 0.0000, 0.0046, 0.0019, 0.0010, 0.0046,\n",
      "         0.0013, 0.0029, 0.0009, 0.0030, 0.0018, 0.0026, 0.0010, 0.0022, 0.0011,\n",
      "         0.0026],\n",
      "        [0.0014, 0.0030, 0.0010, 0.0044, 0.0046, 0.0000, 0.0017, 0.0026, 0.0038,\n",
      "         0.0009, 0.0009, 0.0033, 0.0028, 0.0011, 0.0038, 0.0033, 0.0025, 0.0013,\n",
      "         0.0038],\n",
      "        [0.0023, 0.0021, 0.0019, 0.0022, 0.0019, 0.0017, 0.0000, 0.0018, 0.0013,\n",
      "         0.0021, 0.0018, 0.0045, 0.0019, 0.0018, 0.0030, 0.0043, 0.0011, 0.0031,\n",
      "         0.0047],\n",
      "        [0.0025, 0.0040, 0.0031, 0.0028, 0.0010, 0.0026, 0.0018, 0.0000, 0.0013,\n",
      "         0.0012, 0.0029, 0.0040, 0.0022, 0.0017, 0.0023, 0.0015, 0.0040, 0.0026,\n",
      "         0.0039],\n",
      "        [0.0011, 0.0024, 0.0031, 0.0029, 0.0046, 0.0038, 0.0013, 0.0013, 0.0000,\n",
      "         0.0041, 0.0031, 0.0014, 0.0025, 0.0030, 0.0023, 0.0009, 0.0038, 0.0025,\n",
      "         0.0042],\n",
      "        [0.0014, 0.0021, 0.0032, 0.0017, 0.0013, 0.0009, 0.0021, 0.0012, 0.0041,\n",
      "         0.0000, 0.0047, 0.0025, 0.0033, 0.0028, 0.0014, 0.0021, 0.0029, 0.0022,\n",
      "         0.0018],\n",
      "        [0.0040, 0.0011, 0.0028, 0.0031, 0.0029, 0.0009, 0.0018, 0.0029, 0.0031,\n",
      "         0.0047, 0.0000, 0.0021, 0.0013, 0.0010, 0.0023, 0.0014, 0.0034, 0.0018,\n",
      "         0.0012],\n",
      "        [0.0028, 0.0033, 0.0021, 0.0016, 0.0009, 0.0033, 0.0045, 0.0040, 0.0014,\n",
      "         0.0025, 0.0021, 0.0000, 0.0019, 0.0027, 0.0022, 0.0023, 0.0011, 0.0016,\n",
      "         0.0035],\n",
      "        [0.0018, 0.0013, 0.0039, 0.0015, 0.0030, 0.0028, 0.0019, 0.0022, 0.0025,\n",
      "         0.0033, 0.0013, 0.0019, 0.0000, 0.0012, 0.0021, 0.0009, 0.0021, 0.0012,\n",
      "         0.0012],\n",
      "        [0.0018, 0.0045, 0.0026, 0.0014, 0.0018, 0.0011, 0.0018, 0.0017, 0.0030,\n",
      "         0.0028, 0.0010, 0.0027, 0.0012, 0.0000, 0.0012, 0.0019, 0.0011, 0.0031,\n",
      "         0.0046],\n",
      "        [0.0013, 0.0010, 0.0029, 0.0011, 0.0026, 0.0038, 0.0030, 0.0023, 0.0023,\n",
      "         0.0014, 0.0023, 0.0022, 0.0021, 0.0012, 0.0000, 0.0030, 0.0044, 0.0045,\n",
      "         0.0038],\n",
      "        [0.0044, 0.0023, 0.0014, 0.0017, 0.0010, 0.0033, 0.0043, 0.0015, 0.0009,\n",
      "         0.0021, 0.0014, 0.0023, 0.0009, 0.0019, 0.0030, 0.0000, 0.0026, 0.0012,\n",
      "         0.0020],\n",
      "        [0.0011, 0.0044, 0.0037, 0.0041, 0.0022, 0.0025, 0.0011, 0.0040, 0.0038,\n",
      "         0.0029, 0.0034, 0.0011, 0.0021, 0.0011, 0.0044, 0.0026, 0.0000, 0.0010,\n",
      "         0.0010],\n",
      "        [0.0024, 0.0021, 0.0035, 0.0014, 0.0011, 0.0013, 0.0031, 0.0026, 0.0025,\n",
      "         0.0022, 0.0018, 0.0016, 0.0012, 0.0031, 0.0045, 0.0012, 0.0010, 0.0000,\n",
      "         0.0025],\n",
      "        [0.0031, 0.0019, 0.0018, 0.0029, 0.0026, 0.0038, 0.0047, 0.0039, 0.0042,\n",
      "         0.0018, 0.0012, 0.0035, 0.0012, 0.0046, 0.0038, 0.0020, 0.0010, 0.0025,\n",
      "         0.0000]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.5294504761695862\n",
      "min_loss =  0.5294504761695862\n",
      "node_costs for min of the loss :  tensor([[0.0000, 0.0010, 0.0012, 0.0012, 0.0024, 0.0004, 0.0010, 0.0012, 0.0003,\n",
      "         0.0005, 0.0026, 0.0015, 0.0007, 0.0007, 0.0004, 0.0029, 0.0003, 0.0011,\n",
      "         0.0016],\n",
      "        [0.0010, 0.0000, 0.0003, 0.0004, 0.0002, 0.0016, 0.0009, 0.0026, 0.0011,\n",
      "         0.0009, 0.0003, 0.0018, 0.0004, 0.0031, 0.0002, 0.0010, 0.0029, 0.0009,\n",
      "         0.0007],\n",
      "        [0.0012, 0.0003, 0.0000, 0.0011, 0.0002, 0.0002, 0.0007, 0.0017, 0.0017,\n",
      "         0.0018, 0.0015, 0.0009, 0.0025, 0.0012, 0.0015, 0.0004, 0.0023, 0.0020,\n",
      "         0.0007],\n",
      "        [0.0012, 0.0004, 0.0011, 0.0000, 0.0002, 0.0029, 0.0010, 0.0014, 0.0015,\n",
      "         0.0006, 0.0017, 0.0006, 0.0005, 0.0004, 0.0003, 0.0006, 0.0027, 0.0004,\n",
      "         0.0015],\n",
      "        [0.0024, 0.0002, 0.0002, 0.0002, 0.0000, 0.0031, 0.0008, 0.0002, 0.0032,\n",
      "         0.0004, 0.0015, 0.0002, 0.0016, 0.0007, 0.0013, 0.0002, 0.0010, 0.0003,\n",
      "         0.0012],\n",
      "        [0.0004, 0.0016, 0.0002, 0.0029, 0.0031, 0.0000, 0.0007, 0.0013, 0.0024,\n",
      "         0.0002, 0.0002, 0.0018, 0.0014, 0.0002, 0.0024, 0.0018, 0.0012, 0.0004,\n",
      "         0.0024],\n",
      "        [0.0010, 0.0009, 0.0007, 0.0010, 0.0008, 0.0007, 0.0000, 0.0007, 0.0004,\n",
      "         0.0009, 0.0007, 0.0031, 0.0008, 0.0007, 0.0016, 0.0028, 0.0002, 0.0016,\n",
      "         0.0032],\n",
      "        [0.0012, 0.0026, 0.0017, 0.0014, 0.0002, 0.0013, 0.0007, 0.0000, 0.0004,\n",
      "         0.0003, 0.0015, 0.0026, 0.0010, 0.0006, 0.0010, 0.0005, 0.0026, 0.0013,\n",
      "         0.0025],\n",
      "        [0.0003, 0.0011, 0.0017, 0.0015, 0.0032, 0.0024, 0.0004, 0.0004, 0.0000,\n",
      "         0.0027, 0.0017, 0.0005, 0.0012, 0.0016, 0.0011, 0.0002, 0.0024, 0.0012,\n",
      "         0.0027],\n",
      "        [0.0005, 0.0009, 0.0018, 0.0006, 0.0004, 0.0002, 0.0009, 0.0003, 0.0027,\n",
      "         0.0000, 0.0032, 0.0012, 0.0018, 0.0014, 0.0004, 0.0009, 0.0015, 0.0010,\n",
      "         0.0007],\n",
      "        [0.0026, 0.0003, 0.0015, 0.0017, 0.0015, 0.0002, 0.0007, 0.0015, 0.0017,\n",
      "         0.0032, 0.0000, 0.0009, 0.0004, 0.0002, 0.0010, 0.0004, 0.0019, 0.0007,\n",
      "         0.0003],\n",
      "        [0.0015, 0.0018, 0.0009, 0.0006, 0.0002, 0.0018, 0.0031, 0.0026, 0.0005,\n",
      "         0.0012, 0.0009, 0.0000, 0.0008, 0.0013, 0.0010, 0.0010, 0.0002, 0.0006,\n",
      "         0.0019],\n",
      "        [0.0007, 0.0004, 0.0025, 0.0005, 0.0016, 0.0014, 0.0008, 0.0010, 0.0012,\n",
      "         0.0018, 0.0004, 0.0008, 0.0000, 0.0003, 0.0009, 0.0002, 0.0009, 0.0003,\n",
      "         0.0003],\n",
      "        [0.0007, 0.0031, 0.0012, 0.0004, 0.0007, 0.0002, 0.0007, 0.0006, 0.0016,\n",
      "         0.0014, 0.0002, 0.0013, 0.0003, 0.0000, 0.0003, 0.0008, 0.0003, 0.0017,\n",
      "         0.0031],\n",
      "        [0.0004, 0.0002, 0.0015, 0.0003, 0.0013, 0.0024, 0.0016, 0.0010, 0.0011,\n",
      "         0.0004, 0.0010, 0.0010, 0.0009, 0.0003, 0.0000, 0.0016, 0.0030, 0.0031,\n",
      "         0.0024],\n",
      "        [0.0029, 0.0010, 0.0004, 0.0006, 0.0002, 0.0018, 0.0028, 0.0005, 0.0002,\n",
      "         0.0009, 0.0004, 0.0010, 0.0002, 0.0008, 0.0016, 0.0000, 0.0012, 0.0003,\n",
      "         0.0008],\n",
      "        [0.0003, 0.0029, 0.0023, 0.0027, 0.0010, 0.0012, 0.0002, 0.0026, 0.0024,\n",
      "         0.0015, 0.0019, 0.0002, 0.0009, 0.0003, 0.0030, 0.0012, 0.0000, 0.0002,\n",
      "         0.0002],\n",
      "        [0.0011, 0.0009, 0.0020, 0.0004, 0.0003, 0.0004, 0.0016, 0.0013, 0.0012,\n",
      "         0.0010, 0.0007, 0.0006, 0.0003, 0.0017, 0.0031, 0.0003, 0.0002, 0.0000,\n",
      "         0.0012],\n",
      "        [0.0016, 0.0007, 0.0007, 0.0015, 0.0012, 0.0024, 0.0032, 0.0025, 0.0027,\n",
      "         0.0007, 0.0003, 0.0019, 0.0003, 0.0031, 0.0024, 0.0008, 0.0002, 0.0012,\n",
      "         0.0000]], grad_fn=<AddBackward0>)\n",
      "8 0.5294113755226135\n",
      "min_loss =  0.5294113755226135\n",
      "node_costs for min of the loss :  tensor([[0.0000e+00, 2.0679e-04, 3.0307e-04, 2.9324e-04, 1.1671e-03, 9.3318e-06,\n",
      "         2.2038e-04, 2.8181e-04, 1.5969e-06, 1.4773e-05, 1.3205e-03, 4.2804e-04,\n",
      "         8.0426e-05, 8.0341e-05, 3.3407e-06, 1.5444e-03, 6.0227e-07, 2.4309e-04,\n",
      "         5.3121e-04],\n",
      "        [2.0679e-04, 0.0000e+00, 6.5142e-07, 3.9636e-06, 1.5739e-05, 4.9424e-04,\n",
      "         1.5326e-04, 1.2805e-03, 2.5549e-04, 1.5355e-04, 1.1570e-06, 6.4493e-04,\n",
      "         4.0730e-06, 1.6296e-03, 1.3893e-05, 2.0637e-04, 1.5450e-03, 1.5782e-04,\n",
      "         9.3846e-05],\n",
      "        [3.0307e-04, 6.5142e-07, 0.0000e+00, 2.3299e-04, 7.3224e-06, 1.4922e-05,\n",
      "         9.2027e-05, 5.6421e-04, 5.4928e-04, 6.1430e-04, 4.2700e-04, 1.6908e-04,\n",
      "         1.2006e-03, 3.1380e-04, 4.4336e-04, 1.2345e-05, 1.0977e-03, 7.3792e-04,\n",
      "         7.5808e-05],\n",
      "        [2.9324e-04, 3.9636e-06, 2.3299e-04, 0.0000e+00, 1.9694e-05, 1.5297e-03,\n",
      "         1.8128e-04, 3.9728e-04, 4.6929e-04, 5.5716e-05, 5.5212e-04, 3.4509e-05,\n",
      "         1.9598e-05, 7.9449e-06, 5.3375e-07, 5.1019e-05, 1.3670e-03, 7.6460e-06,\n",
      "         4.6345e-04],\n",
      "        [1.1671e-03, 1.5739e-05, 7.3224e-06, 1.9694e-05, 0.0000e+00, 1.6724e-03,\n",
      "         1.1145e-04, 6.1850e-06, 1.7113e-03, 3.0896e-06, 4.6638e-04, 2.6758e-05,\n",
      "         5.1083e-04, 7.1872e-05, 3.2312e-04, 1.1083e-05, 1.8912e-04, 1.5128e-06,\n",
      "         3.1431e-04],\n",
      "        [9.3318e-06, 4.9424e-04, 1.4922e-05, 1.5297e-03, 1.6724e-03, 0.0000e+00,\n",
      "         6.3118e-05, 3.3168e-04, 1.1781e-03, 1.7262e-05, 2.7075e-05, 6.2608e-04,\n",
      "         3.9063e-04, 3.9012e-06, 1.1668e-03, 6.2704e-04, 2.7306e-04, 2.0595e-06,\n",
      "         1.1695e-03],\n",
      "        [2.2038e-04, 1.5326e-04, 9.2027e-05, 1.8128e-04, 1.1145e-04, 6.3118e-05,\n",
      "         0.0000e+00, 7.2870e-05, 2.2979e-06, 1.5869e-04, 7.9403e-05, 1.6374e-03,\n",
      "         1.0603e-04, 7.3962e-05, 5.1043e-04, 1.4742e-03, 3.6981e-06, 5.3948e-04,\n",
      "         1.7350e-03],\n",
      "        [2.8181e-04, 1.2805e-03, 5.6421e-04, 3.9728e-04, 6.1850e-06, 3.3168e-04,\n",
      "         7.2870e-05, 0.0000e+00, 2.2291e-06, 3.5787e-07, 4.6975e-04, 1.3121e-03,\n",
      "         1.9325e-04, 4.5605e-05, 2.1311e-04, 1.7120e-05, 1.2733e-03, 3.3689e-04,\n",
      "         1.2414e-03],\n",
      "        [1.5969e-06, 2.5549e-04, 5.4928e-04, 4.6929e-04, 1.7113e-03, 1.1781e-03,\n",
      "         2.2979e-06, 2.2291e-06, 0.0000e+00, 1.3797e-03, 5.6178e-04, 1.4117e-05,\n",
      "         2.9293e-04, 5.2040e-04, 2.2911e-04, 2.2736e-05, 1.1704e-03, 2.9526e-04,\n",
      "         1.4011e-03],\n",
      "        [1.4773e-05, 1.5355e-04, 6.1430e-04, 5.5716e-05, 3.0896e-06, 1.7262e-05,\n",
      "         1.5869e-04, 3.5787e-07, 1.3797e-03, 0.0000e+00, 1.7359e-03, 2.7506e-04,\n",
      "         6.5119e-04, 4.2196e-04, 1.2079e-05, 1.6926e-04, 4.5609e-04, 2.0085e-04,\n",
      "         7.9815e-05],\n",
      "        [1.3205e-03, 1.1570e-06, 4.2700e-04, 5.5212e-04, 4.6638e-04, 2.7075e-05,\n",
      "         7.9403e-05, 4.6975e-04, 5.6178e-04, 1.7359e-03, 0.0000e+00, 1.4107e-04,\n",
      "         6.0353e-06, 7.3139e-06, 2.0674e-04, 9.0933e-06, 6.7720e-04, 8.4081e-05,\n",
      "         3.0658e-08],\n",
      "        [4.2804e-04, 6.4493e-04, 1.6908e-04, 3.4509e-05, 2.6758e-05, 6.2608e-04,\n",
      "         1.6374e-03, 1.3121e-03, 1.4117e-05, 2.7506e-04, 1.4107e-04, 0.0000e+00,\n",
      "         1.1099e-04, 3.5668e-04, 1.9588e-04, 2.1801e-04, 4.4705e-06, 3.7619e-05,\n",
      "         7.1717e-04],\n",
      "        [8.0426e-05, 4.0730e-06, 1.2006e-03, 1.9598e-05, 5.1083e-04, 3.9063e-04,\n",
      "         1.0603e-04, 1.9325e-04, 2.9293e-04, 6.5119e-04, 6.0353e-06, 1.1099e-04,\n",
      "         0.0000e+00, 2.5963e-07, 1.6865e-04, 2.0066e-05, 1.6936e-04, 2.3700e-09,\n",
      "         4.1949e-07],\n",
      "        [8.0341e-05, 1.6296e-03, 3.1380e-04, 7.9449e-06, 7.1872e-05, 3.9012e-06,\n",
      "         7.3962e-05, 4.5605e-05, 5.2040e-04, 4.2196e-04, 7.3139e-06, 3.5668e-04,\n",
      "         2.5963e-07, 0.0000e+00, 2.7304e-07, 1.1195e-04, 2.3182e-06, 5.5580e-04,\n",
      "         1.6768e-03],\n",
      "        [3.3407e-06, 1.3893e-05, 4.4336e-04, 5.3375e-07, 3.2312e-04, 1.1668e-03,\n",
      "         5.1043e-04, 2.1311e-04, 2.2911e-04, 1.2079e-05, 2.0674e-04, 1.9588e-04,\n",
      "         1.6865e-04, 2.7304e-07, 0.0000e+00, 4.9285e-04, 1.5802e-03, 1.6266e-03,\n",
      "         1.1598e-03],\n",
      "        [1.5444e-03, 2.0637e-04, 1.2345e-05, 5.1019e-05, 1.1083e-05, 6.2704e-04,\n",
      "         1.4742e-03, 1.7120e-05, 2.2736e-05, 1.6926e-04, 9.0933e-06, 2.1801e-04,\n",
      "         2.0066e-05, 1.1195e-04, 4.9285e-04, 0.0000e+00, 3.2020e-04, 8.7002e-07,\n",
      "         1.2536e-04],\n",
      "        [6.0227e-07, 1.5450e-03, 1.0977e-03, 1.3670e-03, 1.8912e-04, 2.7306e-04,\n",
      "         3.6981e-06, 1.2733e-03, 1.1704e-03, 4.5609e-04, 6.7720e-04, 4.4705e-06,\n",
      "         1.6936e-04, 2.3182e-06, 1.5802e-03, 3.2020e-04, 0.0000e+00, 9.8799e-06,\n",
      "         8.2147e-06],\n",
      "        [2.4309e-04, 1.5782e-04, 7.3792e-04, 7.6460e-06, 1.5128e-06, 2.0595e-06,\n",
      "         5.3948e-04, 3.3689e-04, 2.9526e-04, 2.0085e-04, 8.4081e-05, 3.7619e-05,\n",
      "         2.3700e-09, 5.5580e-04, 1.6266e-03, 8.7002e-07, 9.8799e-06, 0.0000e+00,\n",
      "         3.0103e-04],\n",
      "        [5.3121e-04, 9.3846e-05, 7.5808e-05, 4.6345e-04, 3.1431e-04, 1.1695e-03,\n",
      "         1.7350e-03, 1.2414e-03, 1.4011e-03, 7.9815e-05, 3.0658e-08, 7.1717e-04,\n",
      "         4.1949e-07, 1.6768e-03, 1.1598e-03, 1.2536e-04, 8.2147e-06, 3.0103e-04,\n",
      "         0.0000e+00]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.5293681025505066\n",
      "min_loss =  0.5293681025505066\n",
      "node_costs for min of the loss :  tensor([[0.0000e+00, 2.9183e-06, 1.4222e-06, 8.4572e-07, 3.6989e-04, 1.5730e-04,\n",
      "         1.5952e-06, 3.5623e-07, 2.7777e-04, 1.3896e-04, 4.5536e-04, 1.8798e-05,\n",
      "         4.7447e-05, 4.7510e-05, 1.8808e-04, 5.8586e-04, 2.6247e-04, 3.0094e-07,\n",
      "         4.3517e-05],\n",
      "        [2.9183e-06, 0.0000e+00, 2.1577e-04, 1.8383e-04, 3.7044e-04, 3.3802e-05,\n",
      "         1.3129e-05, 4.3274e-04, 2.9705e-08, 1.3048e-05, 2.7182e-04, 7.8282e-05,\n",
      "         1.8312e-04, 6.3705e-04, 3.6168e-04, 2.9664e-06, 5.8622e-04, 1.1892e-05,\n",
      "         3.8440e-05],\n",
      "        [1.4222e-06, 2.1577e-04, 0.0000e+00, 7.4318e-07, 3.2556e-04, 3.6662e-04,\n",
      "         3.9567e-05, 5.2893e-05, 4.8571e-05, 6.8265e-05, 1.8588e-05, 9.1616e-06,\n",
      "         3.8826e-04, 2.2057e-06, 2.1970e-05, 1.4649e-04, 3.3247e-04, 1.1119e-04,\n",
      "         5.0953e-05],\n",
      "        [8.4572e-07, 1.8383e-04, 7.4318e-07, 0.0000e+00, 3.8792e-04, 5.7711e-04,\n",
      "         6.6852e-06, 1.3031e-05, 2.7764e-05, 6.9331e-05, 4.9384e-05, 9.6960e-05,\n",
      "         1.2612e-04, 1.6301e-04, 2.6107e-04, 7.4547e-05, 4.8196e-04, 1.6432e-04,\n",
      "         2.6414e-05],\n",
      "        [3.6989e-04, 3.7044e-04, 3.2556e-04, 3.8792e-04, 0.0000e+00, 6.6307e-04,\n",
      "         2.8816e-05, 3.1806e-04, 6.8681e-04, 1.8992e-04, 2.7087e-05, 4.1603e-04,\n",
      "         3.8053e-05, 5.4128e-05, 3.0107e-06, 3.4737e-04, 5.3343e-06, 2.7670e-04,\n",
      "         2.2466e-06],\n",
      "        [1.5730e-04, 3.3802e-05, 3.6662e-04, 5.7711e-04, 6.6307e-04, 0.0000e+00,\n",
      "         6.1891e-05, 3.8492e-06, 3.7591e-04, 3.7736e-04, 4.1722e-04, 7.2064e-05,\n",
      "         1.1897e-05, 3.0087e-04, 3.6971e-04, 7.2378e-05, 1.1929e-07, 1.9851e-04,\n",
      "         3.7117e-04],\n",
      "        [1.5952e-06, 1.3129e-05, 3.9567e-05, 6.6852e-06, 2.8816e-05, 6.1891e-05,\n",
      "         0.0000e+00, 5.3306e-05, 1.9634e-04, 1.1665e-05, 4.8204e-05, 6.4176e-04,\n",
      "         3.1545e-05, 5.2419e-05, 3.7949e-05, 5.4426e-04, 2.9915e-04, 4.5806e-05,\n",
      "         7.0142e-04],\n",
      "        [3.5623e-07, 4.3274e-04, 5.2893e-05, 1.3031e-05, 3.1806e-04, 3.8492e-06,\n",
      "         5.3306e-05, 0.0000e+00, 1.9695e-04, 2.5700e-04, 2.7871e-05, 4.5056e-04,\n",
      "         4.6950e-06, 8.1119e-05, 2.2489e-06, 1.3241e-04, 4.2865e-04, 4.4033e-06,\n",
      "         4.1083e-04],\n",
      "        [2.7777e-04, 2.9705e-08, 4.8571e-05, 2.7764e-05, 6.8681e-04, 3.7591e-04,\n",
      "         1.9634e-04, 1.9695e-04, 0.0000e+00, 4.8927e-04, 5.2182e-05, 1.4091e-04,\n",
      "         8.2985e-07, 4.0585e-05, 9.6886e-07, 4.0044e-04, 3.7168e-04, 9.5283e-07,\n",
      "         5.0163e-04],\n",
      "        [1.3896e-04, 1.3048e-05, 6.8265e-05, 6.9331e-05, 1.8992e-04, 3.7736e-04,\n",
      "         1.1665e-05, 2.5700e-04, 4.8927e-04, 0.0000e+00, 7.0194e-04, 1.6255e-07,\n",
      "         8.0383e-05, 1.7591e-05, 1.4738e-04, 9.1222e-06, 2.4750e-05, 3.6390e-06,\n",
      "         4.7898e-05],\n",
      "        [4.5536e-04, 2.7182e-04, 1.8588e-05, 4.9384e-05, 2.7087e-05, 4.1722e-04,\n",
      "         4.8204e-05, 2.7871e-05, 5.2182e-05, 7.0194e-04, 0.0000e+00, 1.6847e-05,\n",
      "         1.7196e-04, 3.2550e-04, 2.9237e-06, 1.5824e-04, 8.9296e-05, 4.4828e-05,\n",
      "         2.4421e-04],\n",
      "        [1.8798e-05, 7.8282e-05, 9.1616e-06, 9.6960e-05, 4.1603e-04, 7.2064e-05,\n",
      "         6.4176e-04, 4.5056e-04, 1.4091e-04, 1.6255e-07, 1.6847e-05, 0.0000e+00,\n",
      "         2.9041e-05, 6.7997e-06, 4.3110e-06, 1.7950e-06, 3.0550e-04, 9.2144e-05,\n",
      "         1.0354e-04],\n",
      "        [4.7447e-05, 1.8312e-04, 3.8826e-04, 1.2612e-04, 3.8053e-05, 1.1897e-05,\n",
      "         3.1545e-05, 4.6950e-06, 8.2985e-07, 8.0383e-05, 1.7196e-04, 2.9041e-05,\n",
      "         0.0000e+00, 2.2420e-04, 9.2583e-06, 3.8949e-04, 9.0989e-06, 2.4045e-04,\n",
      "         2.2027e-04],\n",
      "        [4.7510e-05, 6.3705e-04, 2.2057e-06, 1.6301e-04, 5.4128e-05, 3.0087e-04,\n",
      "         5.2419e-05, 8.1119e-05, 4.0585e-05, 1.7591e-05, 3.2550e-04, 6.7997e-06,\n",
      "         2.2420e-04, 0.0000e+00, 2.2383e-04, 2.8570e-05, 2.8607e-04, 5.0443e-05,\n",
      "         6.6573e-04],\n",
      "        [1.8808e-04, 3.6168e-04, 2.1970e-05, 2.6107e-04, 3.0107e-06, 3.6971e-04,\n",
      "         3.7949e-05, 2.2489e-06, 9.6886e-07, 1.4738e-04, 2.9237e-06, 4.3110e-06,\n",
      "         9.2583e-06, 2.2383e-04, 0.0000e+00, 3.3454e-05, 6.0727e-04, 6.3522e-04,\n",
      "         3.6592e-04],\n",
      "        [5.8586e-04, 2.9664e-06, 1.4649e-04, 7.4547e-05, 3.4737e-04, 7.2378e-05,\n",
      "         5.4426e-04, 1.3241e-04, 4.0044e-04, 9.1222e-06, 1.5824e-04, 1.7950e-06,\n",
      "         3.8949e-04, 2.8570e-05, 3.3454e-05, 0.0000e+00, 2.7470e-06, 2.1226e-04,\n",
      "         2.2621e-05],\n",
      "        [2.6247e-04, 5.8622e-04, 3.3247e-04, 4.8196e-04, 5.3343e-06, 1.1929e-07,\n",
      "         2.9915e-04, 4.2865e-04, 3.7168e-04, 2.4750e-05, 8.9296e-05, 3.0550e-04,\n",
      "         9.0989e-06, 2.8607e-04, 6.0727e-04, 2.7470e-06, 0.0000e+00, 3.4079e-04,\n",
      "         3.3110e-04],\n",
      "        [3.0094e-07, 1.1892e-05, 1.1119e-04, 1.6432e-04, 2.7670e-04, 1.9851e-04,\n",
      "         4.5806e-05, 4.4033e-06, 9.5283e-07, 3.6390e-06, 4.4828e-05, 9.2144e-05,\n",
      "         2.4045e-04, 5.0443e-05, 6.3522e-04, 2.1226e-04, 3.4079e-04, 0.0000e+00,\n",
      "         1.2912e-06],\n",
      "        [4.3517e-05, 3.8440e-05, 5.0953e-05, 2.6414e-05, 2.2466e-06, 3.7117e-04,\n",
      "         7.0142e-04, 4.1083e-04, 5.0163e-04, 4.7898e-05, 2.4421e-04, 1.0354e-04,\n",
      "         2.2027e-04, 6.6573e-04, 3.6592e-04, 2.2621e-05, 3.3110e-04, 1.2912e-06,\n",
      "         0.0000e+00]], grad_fn=<AddBackward0>)\n",
      "10 0.5293187499046326\n",
      "min_loss =  0.5293187499046326\n",
      "node_costs for min of the loss :  tensor([[0.0000e+00, 2.1417e-04, 1.4265e-04, 1.4876e-04, 4.2080e-05, 6.0872e-04,\n",
      "         2.0225e-04, 1.5615e-04, 8.1159e-04, 5.7478e-04, 7.1602e-05, 8.1477e-05,\n",
      "         3.7777e-04, 3.7794e-04, 6.6344e-04, 1.2428e-04, 7.8725e-04, 1.8384e-04,\n",
      "         4.7986e-05],\n",
      "        [2.1417e-04, 0.0000e+00, 7.1073e-04, 6.5603e-04, 9.5320e-04, 5.8584e-05,\n",
      "         2.6930e-04, 6.3340e-05, 1.7450e-04, 2.6896e-04, 8.0216e-04, 2.3394e-05,\n",
      "         6.5480e-04, 1.4686e-04, 9.4018e-04, 2.1455e-04, 1.2443e-04, 2.6400e-04,\n",
      "         3.5339e-04],\n",
      "        [1.4265e-04, 7.1073e-04, 0.0000e+00, 1.9181e-04, 8.8574e-04, 9.4753e-04,\n",
      "         3.5654e-04, 3.9683e-05, 4.3312e-05, 2.8949e-05, 8.1884e-05, 2.5145e-04,\n",
      "         4.8013e-05, 1.3623e-04, 7.5691e-05, 5.8886e-04, 3.0807e-05, 1.0630e-05,\n",
      "         3.8683e-04],\n",
      "        [1.4876e-04, 6.5603e-04, 1.9181e-04, 0.0000e+00, 9.7899e-04, 1.2052e-04,\n",
      "         2.3864e-04, 9.4093e-05, 6.6583e-05, 4.3135e-04, 4.2605e-05, 4.9183e-04,\n",
      "         5.5029e-04, 6.1907e-04, 7.8500e-04, 4.4327e-04, 8.1684e-05, 6.2143e-04,\n",
      "         6.8563e-05],\n",
      "        [4.2080e-05, 9.5320e-04, 8.8574e-04, 9.7899e-04, 0.0000e+00, 1.5868e-04,\n",
      "         3.2499e-04, 8.7428e-04, 1.6966e-04, 6.6663e-04, 6.7565e-05, 1.0199e-03,\n",
      "         5.3650e-05, 3.9485e-04, 1.3087e-04, 9.1877e-04, 2.3080e-04, 8.0990e-04,\n",
      "         1.3594e-04],\n",
      "        [6.0872e-04, 5.8584e-05, 9.4753e-04, 1.2052e-04, 1.5868e-04, 0.0000e+00,\n",
      "         4.1385e-04, 1.2610e-04, 4.3998e-05, 9.6344e-04, 1.0217e-03, 2.6727e-05,\n",
      "         9.7008e-05, 8.4777e-04, 4.2021e-05, 2.6550e-05, 1.6204e-04, 6.8144e-04,\n",
      "         4.2484e-05],\n",
      "        [2.0225e-04, 2.6930e-04, 3.5654e-04, 2.3864e-04, 3.2499e-04, 4.1385e-04,\n",
      "         0.0000e+00, 3.9279e-04, 6.7772e-04, 2.6301e-04, 3.7975e-04, 1.4898e-04,\n",
      "         3.3335e-04, 3.9055e-04, 5.3765e-05, 1.0666e-04, 8.4510e-04, 4.5808e-05,\n",
      "         1.7649e-04],\n",
      "        [1.5615e-04, 6.3340e-05, 3.9683e-05, 9.4093e-05, 8.7428e-04, 1.2610e-04,\n",
      "         3.9279e-04, 0.0000e+00, 6.7877e-04, 7.7846e-04, 6.6429e-05, 6.9824e-05,\n",
      "         2.2679e-04, 4.5791e-04, 2.0854e-04, 5.6237e-04, 6.1879e-05, 1.2327e-04,\n",
      "         5.5628e-05],\n",
      "        [8.1159e-04, 1.7450e-04, 4.3312e-05, 6.6583e-05, 1.6966e-04, 4.3998e-05,\n",
      "         6.7772e-04, 6.7877e-04, 0.0000e+00, 8.4517e-05, 4.0259e-05, 5.7845e-04,\n",
      "         1.4896e-04, 5.0939e-05, 1.9496e-04, 9.9730e-04, 4.2647e-05, 1.4748e-04,\n",
      "         8.9371e-05],\n",
      "        [5.7478e-04, 2.6896e-04, 2.8949e-05, 4.3135e-04, 6.6663e-04, 9.6344e-04,\n",
      "         2.6301e-04, 7.7846e-04, 8.4517e-05, 0.0000e+00, 1.7674e-04, 1.6068e-04,\n",
      "         2.2346e-05, 8.3865e-05, 5.9050e-04, 2.5126e-04, 7.1116e-05, 2.1961e-04,\n",
      "         3.7895e-04],\n",
      "        [7.1602e-05, 8.0216e-04, 8.1884e-05, 4.2605e-05, 6.7565e-05, 1.0217e-03,\n",
      "         3.7975e-04, 6.6429e-05, 4.0259e-05, 1.7674e-04, 0.0000e+00, 2.8413e-04,\n",
      "         6.3511e-04, 8.8566e-04, 2.1421e-04, 6.1044e-04, 1.8297e-05, 3.7086e-04,\n",
      "         7.5775e-04],\n",
      "        [8.1477e-05, 2.3394e-05, 2.5145e-04, 4.9183e-04, 1.0199e-03, 2.6727e-05,\n",
      "         1.4898e-04, 6.9824e-05, 5.7845e-04, 1.6068e-04, 2.8413e-04, 0.0000e+00,\n",
      "         3.2569e-04, 1.1300e-04, 2.2427e-04, 2.0428e-04, 8.5494e-04, 4.8170e-04,\n",
      "         1.2983e-05],\n",
      "        [3.7777e-04, 6.5480e-04, 4.8013e-05, 5.5029e-04, 5.3650e-05, 9.7008e-05,\n",
      "         3.3335e-04, 2.2679e-04, 1.4896e-04, 2.2346e-05, 6.3511e-04, 3.2569e-04,\n",
      "         0.0000e+00, 7.2481e-04, 2.5192e-04, 9.8129e-04, 2.5114e-04, 7.5161e-04,\n",
      "         7.1826e-04],\n",
      "        [3.7794e-04, 1.4686e-04, 1.3623e-04, 6.1907e-04, 3.9485e-04, 8.4777e-04,\n",
      "         3.9055e-04, 4.5791e-04, 5.0939e-05, 8.3865e-05, 8.8566e-04, 1.1300e-04,\n",
      "         7.2481e-04, 0.0000e+00, 7.2420e-04, 3.2423e-04, 8.2467e-04, 4.1701e-05,\n",
      "         1.5990e-04],\n",
      "        [6.6344e-04, 9.4018e-04, 7.5691e-05, 7.8500e-04, 1.3087e-04, 4.2021e-05,\n",
      "         5.3765e-05, 2.0854e-04, 1.9496e-04, 5.9050e-04, 2.1421e-04, 2.2427e-04,\n",
      "         2.5192e-04, 7.2420e-04, 0.0000e+00, 5.9012e-05, 1.3361e-04, 1.4604e-04,\n",
      "         4.0830e-05],\n",
      "        [1.2428e-04, 2.1455e-04, 5.8886e-04, 4.4327e-04, 9.1877e-04, 2.6550e-05,\n",
      "         1.0666e-04, 5.6237e-04, 9.9730e-04, 2.5126e-04, 6.1044e-04, 2.0428e-04,\n",
      "         9.8129e-04, 3.2423e-04, 5.9012e-05, 0.0000e+00, 1.3253e-04, 7.0482e-04,\n",
      "         3.0487e-04],\n",
      "        [7.8725e-04, 1.2443e-04, 3.0807e-05, 8.1684e-05, 2.3080e-04, 1.6204e-04,\n",
      "         8.4510e-04, 6.1879e-05, 4.2647e-05, 7.1116e-05, 1.8297e-05, 8.5494e-04,\n",
      "         2.5114e-04, 8.2467e-04, 1.3361e-04, 1.3253e-04, 0.0000e+00, 9.0885e-04,\n",
      "         8.9417e-04],\n",
      "        [1.8384e-04, 2.6400e-04, 1.0630e-05, 6.2143e-04, 8.0990e-04, 6.8144e-04,\n",
      "         4.5808e-05, 1.2327e-04, 1.4748e-04, 2.1961e-04, 3.7086e-04, 4.8170e-04,\n",
      "         7.5161e-04, 4.1701e-05, 1.4604e-04, 7.0482e-04, 9.0885e-04, 0.0000e+00,\n",
      "         1.4390e-04],\n",
      "        [4.7986e-05, 3.5339e-04, 3.8683e-04, 6.8563e-05, 1.3594e-04, 4.2484e-05,\n",
      "         1.7649e-04, 5.5628e-05, 8.9371e-05, 3.7895e-04, 7.5775e-04, 1.2983e-05,\n",
      "         7.1826e-04, 1.5990e-04, 4.0830e-05, 3.0487e-04, 8.9417e-04, 1.4390e-04,\n",
      "         0.0000e+00]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.5409431457519531\n",
      "min_loss =  0.5293187499046326\n",
      "12 0.5296047925949097\n",
      "min_loss =  0.5293187499046326\n",
      "13 0.5294532179832458\n",
      "min_loss =  0.5293187499046326\n",
      "14 0.5294163823127747\n",
      "min_loss =  0.5293187499046326\n",
      "15 0.5294631123542786\n",
      "min_loss =  0.5293187499046326\n",
      "16 0.5295045971870422\n",
      "min_loss =  0.5293187499046326\n",
      "17 0.5295407772064209\n",
      "min_loss =  0.5293187499046326\n",
      "18 0.5295719504356384\n",
      "min_loss =  0.5293187499046326\n",
      "19 0.5295981764793396\n",
      "min_loss =  0.5293187499046326\n",
      "20 0.5296202301979065\n",
      "min_loss =  0.5293187499046326\n",
      "21 0.5296381115913391\n",
      "min_loss =  0.5293187499046326\n",
      "22 0.5296524167060852\n",
      "min_loss =  0.5293187499046326\n",
      "23 0.5296634435653687\n",
      "min_loss =  0.5293187499046326\n",
      "24 0.5296717286109924\n",
      "min_loss =  0.5293187499046326\n",
      "25 0.5296773314476013\n",
      "min_loss =  0.5293187499046326\n",
      "26 0.5296807885169983\n",
      "min_loss =  0.5293187499046326\n",
      "27 0.5296822786331177\n",
      "min_loss =  0.5293187499046326\n",
      "28 0.5296820998191833\n",
      "min_loss =  0.5293187499046326\n",
      "29 0.5296804904937744\n",
      "min_loss =  0.5293187499046326\n",
      "30 0.5296777486801147\n",
      "min_loss =  0.5293187499046326\n",
      "31 0.5296739339828491\n",
      "min_loss =  0.5293187499046326\n",
      "32 0.5296694040298462\n",
      "min_loss =  0.5293187499046326\n",
      "33 0.5296642780303955\n",
      "min_loss =  0.5293187499046326\n",
      "34 0.5296772718429565\n",
      "min_loss =  0.5293187499046326\n",
      "35 0.5296593904495239\n",
      "min_loss =  0.5293187499046326\n",
      "36 0.5296591520309448\n",
      "min_loss =  0.5293187499046326\n",
      "37 0.5296586751937866\n",
      "min_loss =  0.5293187499046326\n",
      "38 0.5296564698219299\n",
      "min_loss =  0.5293187499046326\n",
      "39 0.5296542048454285\n",
      "min_loss =  0.5293187499046326\n",
      "40 0.5296512246131897\n",
      "min_loss =  0.5293187499046326\n",
      "41 0.5296476483345032\n",
      "min_loss =  0.5293187499046326\n",
      "42 0.5296433568000793\n",
      "min_loss =  0.5293187499046326\n",
      "43 0.5296387672424316\n",
      "min_loss =  0.5293187499046326\n",
      "44 0.5296338200569153\n",
      "min_loss =  0.5293187499046326\n",
      "45 0.529628574848175\n",
      "min_loss =  0.5293187499046326\n",
      "46 0.52962327003479\n",
      "min_loss =  0.5293187499046326\n",
      "47 0.5296178460121155\n",
      "min_loss =  0.5293187499046326\n",
      "48 0.5296202301979065\n",
      "min_loss =  0.5293187499046326\n",
      "49 0.5296129584312439\n",
      "min_loss =  0.5293187499046326\n",
      "50 0.5296085476875305\n",
      "min_loss =  0.5293187499046326\n",
      "51 0.5296087861061096\n",
      "min_loss =  0.5293187499046326\n",
      "52 0.5296065211296082\n",
      "min_loss =  0.5293187499046326\n",
      "53 0.5296059250831604\n",
      "min_loss =  0.5293187499046326\n",
      "54 0.5296050906181335\n",
      "min_loss =  0.5293187499046326\n",
      "55 0.5296034812927246\n",
      "min_loss =  0.5293187499046326\n",
      "56 0.5296030044555664\n",
      "min_loss =  0.5293187499046326\n",
      "57 0.5296012759208679\n",
      "min_loss =  0.5293187499046326\n",
      "58 0.5296010971069336\n",
      "min_loss =  0.5293187499046326\n",
      "59 0.5296006202697754\n",
      "min_loss =  0.5293187499046326\n",
      "60 0.5296005010604858\n",
      "min_loss =  0.5293187499046326\n",
      "61 0.5295994281768799\n",
      "min_loss =  0.5293187499046326\n",
      "62 0.5295988321304321\n",
      "min_loss =  0.5293187499046326\n",
      "63 0.5295978784561157\n",
      "min_loss =  0.5293187499046326\n",
      "64 0.5295968651771545\n",
      "min_loss =  0.5293187499046326\n",
      "65 0.5295965671539307\n",
      "min_loss =  0.5293187499046326\n",
      "66 0.5295954346656799\n",
      "min_loss =  0.5293187499046326\n",
      "67 0.5295951962471008\n",
      "min_loss =  0.5293187499046326\n",
      "68 0.5295944213867188\n",
      "min_loss =  0.5293187499046326\n",
      "69 0.5295939445495605\n",
      "min_loss =  0.5293187499046326\n",
      "70 0.5295943021774292\n",
      "min_loss =  0.5293187499046326\n",
      "71 0.5295944213867188\n",
      "min_loss =  0.5293187499046326\n",
      "72 0.5295960307121277\n",
      "min_loss =  0.5293187499046326\n",
      "73 0.5295941829681396\n",
      "min_loss =  0.5293187499046326\n",
      "74 0.5295939445495605\n",
      "min_loss =  0.5293187499046326\n",
      "75 0.5295931696891785\n",
      "min_loss =  0.5293187499046326\n",
      "76 0.5295918583869934\n",
      "min_loss =  0.5293187499046326\n",
      "77 0.5295900702476501\n",
      "min_loss =  0.5293187499046326\n",
      "78 0.5295911431312561\n",
      "min_loss =  0.5293187499046326\n",
      "79 0.5295870304107666\n",
      "min_loss =  0.5293187499046326\n",
      "80 0.5295857787132263\n",
      "min_loss =  0.5293187499046326\n",
      "81 0.5295853614807129\n",
      "min_loss =  0.5293187499046326\n",
      "82 0.5295836329460144\n",
      "min_loss =  0.5293187499046326\n",
      "83 0.5295833349227905\n",
      "min_loss =  0.5293187499046326\n",
      "84 0.5295820236206055\n",
      "min_loss =  0.5293187499046326\n",
      "85 0.5295808911323547\n",
      "min_loss =  0.5293187499046326\n",
      "86 0.5295795202255249\n",
      "min_loss =  0.5293187499046326\n",
      "87 0.5295783877372742\n",
      "min_loss =  0.5293187499046326\n",
      "88 0.5295756459236145\n",
      "min_loss =  0.5293187499046326\n",
      "89 0.5295751094818115\n",
      "min_loss =  0.5293187499046326\n",
      "90 0.5295714735984802\n",
      "min_loss =  0.5293187499046326\n",
      "91 0.5295709371566772\n",
      "min_loss =  0.5293187499046326\n",
      "92 0.5295718908309937\n",
      "min_loss =  0.5293187499046326\n",
      "93 0.5295675992965698\n",
      "min_loss =  0.5293187499046326\n",
      "94 0.5295678973197937\n",
      "min_loss =  0.5293187499046326\n",
      "95 0.5295665860176086\n",
      "min_loss =  0.5293187499046326\n",
      "96 0.5295655727386475\n",
      "min_loss =  0.5293187499046326\n",
      "97 0.529564619064331\n",
      "min_loss =  0.5293187499046326\n",
      "98 0.5295631885528564\n",
      "min_loss =  0.5293187499046326\n",
      "99 0.5295659303665161\n",
      "min_loss =  0.5293187499046326\n",
      "Distances:  tensor([0.2767, 0.2958, 0.2833, 0.2958, 0.3032, 0.2485, 0.2655, 0.3309, 0.2170,\n",
      "        0.2211, 0.2211, 0.3089, 0.2132, 0.2655, 0.3290, 0.3095, 0.3290, 0.3292,\n",
      "        0.2806, 0.2977, 0.3732, 0.2351, 0.2413, 0.2413, 0.3449, 0.2309, 0.2977,\n",
      "        0.3037, 0.3090, 0.3093, 0.2676, 0.2783, 0.3457, 0.2256, 0.2319, 0.2319,\n",
      "        0.3294, 0.2216, 0.2783, 0.3292, 0.3294, 0.2806, 0.2977, 0.3733, 0.2352,\n",
      "        0.2413, 0.2413, 0.3451, 0.2311, 0.2977, 0.3093, 0.2678, 0.2783, 0.3462,\n",
      "        0.2253, 0.2318, 0.2318, 0.3296, 0.2213, 0.2783, 0.2678, 0.2787, 0.3466,\n",
      "        0.2258, 0.2321, 0.2321, 0.3302, 0.2219, 0.2786, 0.3274, 0.4003, 0.2548,\n",
      "        0.2672, 0.2672, 0.3817, 0.2506, 0.3274, 0.3886, 0.2445, 0.2565, 0.2565,\n",
      "        0.3703, 0.2402, 0.3091, 0.2031, 0.2114, 0.2114, 0.2950, 0.1997, 0.2471,\n",
      "        0.3271, 0.3271, 0.5145, 0.3097, 0.4166, 0.3095, 0.4848, 0.3010, 0.4028,\n",
      "        0.4848, 0.3010, 0.4028, 0.2129, 0.2654, 0.4164], grad_fn=<CopySlices>)\n",
      "Loss Triangular: 8.30290991871152e-06\n",
      "node_costs :\n",
      "tensor([[0.0000e+00, 4.3556e-04, 3.7324e-03, 2.8347e-03, 8.8247e-07, 4.8349e-03,\n",
      "         9.3781e-04, 2.4580e-03, 5.8074e-03, 4.6571e-03, 2.0215e-03, 5.5094e-03,\n",
      "         3.7115e-04, 3.7162e-04, 5.1114e-03, 3.5778e-03, 5.6977e-03, 1.4811e-03,\n",
      "         8.4368e-04],\n",
      "        [4.3556e-04, 0.0000e+00, 5.3413e-03, 5.0746e-03, 2.4507e-03, 1.0453e-03,\n",
      "         5.0015e-06, 3.7467e-03, 1.7875e-03, 4.8512e-06, 5.7651e-03, 3.6666e-04,\n",
      "         5.0685e-03, 2.6855e-03, 2.4166e-03, 4.3365e-04, 3.5710e-03, 2.9057e-06,\n",
      "         3.0178e-04],\n",
      "        [3.7324e-03, 5.3413e-03, 0.0000e+00, 1.2090e-03, 2.2728e-03, 2.4359e-03,\n",
      "         3.1053e-04, 6.8349e-04, 7.5373e-04, 4.7465e-04, 5.4963e-03, 1.7040e-07,\n",
      "         1.3675e-03, 4.5733e-03, 1.3630e-03, 4.7315e-03, 1.8255e-03, 1.3949e-06,\n",
      "         3.9777e-04],\n",
      "        [2.8347e-03, 5.0746e-03, 1.2090e-03, 0.0000e+00, 2.5178e-03, 3.7473e-03,\n",
      "         2.3090e-04, 5.7684e-03, 1.1951e-03, 3.8422e-03, 7.4006e-04, 4.1997e-03,\n",
      "         4.5256e-03, 4.8881e-03, 5.6875e-03, 3.9144e-03, 5.9416e-03, 4.9001e-03,\n",
      "         1.2319e-03],\n",
      "        [8.8247e-07, 2.4507e-03, 2.2728e-03, 2.5178e-03, 0.0000e+00, 2.2940e-03,\n",
      "         1.6041e-04, 2.2421e-03, 1.9708e-03, 5.1272e-03, 1.2134e-03, 2.6232e-03,\n",
      "         9.5188e-04, 4.2172e-04, 4.6961e-03, 2.3603e-03, 2.5859e-04, 5.7998e-03,\n",
      "         4.5800e-03],\n",
      "        [4.8349e-03, 1.0453e-03, 2.4359e-03, 3.7473e-03, 2.2940e-03, 0.0000e+00,\n",
      "         4.7960e-04, 5.3219e-03, 7.5321e-04, 2.4774e-03, 2.6277e-03, 4.3138e-04,\n",
      "         5.6803e-03, 5.9673e-03, 8.6053e-07, 4.2794e-04, 2.1572e-03, 5.1998e-03,\n",
      "         2.0553e-05],\n",
      "        [9.3781e-04, 5.0015e-06, 3.1053e-04, 2.3090e-04, 1.6041e-04, 4.7960e-04,\n",
      "         0.0000e+00, 4.1553e-04, 5.1817e-03, 2.5733e-06, 3.7691e-04, 2.6116e-03,\n",
      "         1.7882e-04, 4.0885e-04, 9.5408e-04, 4.4310e-03, 5.9556e-03, 8.0183e-04,\n",
      "         1.7875e-03],\n",
      "        [2.4580e-03, 3.7467e-03, 6.8349e-04, 5.7684e-03, 2.2421e-03, 5.3219e-03,\n",
      "         4.1553e-04, 0.0000e+00, 5.1868e-03, 5.6577e-03, 1.1923e-03, 1.9931e-03,\n",
      "         2.7361e-04, 4.0020e-03, 7.4317e-04, 4.5908e-03, 3.7140e-03, 5.3930e-03,\n",
      "         5.4784e-03],\n",
      "        [5.8074e-03, 1.7875e-03, 7.5373e-04, 1.1951e-03, 1.9708e-03, 7.5321e-04,\n",
      "         5.1817e-03, 5.1868e-03, 0.0000e+00, 5.7494e-03, 6.9466e-04, 4.6766e-03,\n",
      "         2.5699e-03, 9.0021e-04, 9.9611e-04, 2.5651e-03, 2.0239e-05, 2.8563e-03,\n",
      "         5.4335e-03],\n",
      "        [4.6571e-03, 4.8512e-06, 4.7465e-04, 3.8422e-03, 5.1272e-03, 2.4774e-03,\n",
      "         2.5733e-06, 5.6577e-03, 5.7494e-03, 0.0000e+00, 1.7812e-03, 2.3906e-03,\n",
      "         3.4639e-04, 5.4333e-03, 4.7401e-03, 1.5420e-07, 1.2791e-03, 3.0212e-04,\n",
      "         3.7458e-04],\n",
      "        [2.0215e-03, 5.7651e-03, 5.4963e-03, 7.4006e-04, 1.2134e-03, 2.6277e-03,\n",
      "         3.7691e-04, 1.1923e-03, 6.9466e-04, 1.7812e-03, 0.0000e+00, 3.9657e-05,\n",
      "         4.9697e-03, 2.2725e-03, 4.3535e-04, 4.8437e-03, 2.6864e-04, 3.5112e-04,\n",
      "         5.5624e-03],\n",
      "        [5.5094e-03, 3.6666e-04, 1.7040e-07, 4.1997e-03, 2.6232e-03, 4.3138e-04,\n",
      "         2.6116e-03, 1.9931e-03, 4.6766e-03, 2.3906e-03, 3.9657e-05, 0.0000e+00,\n",
      "         1.6192e-04, 5.6649e-03, 2.8339e-04, 9.2213e-04, 2.1903e-03, 4.1414e-03,\n",
      "         8.1814e-06],\n",
      "        [3.7115e-04, 5.0685e-03, 1.3675e-03, 4.5256e-03, 9.5188e-04, 5.6803e-03,\n",
      "         1.7882e-04, 2.7361e-04, 2.5699e-03, 3.4639e-04, 4.9697e-03, 1.6192e-04,\n",
      "         0.0000e+00, 5.4083e-03, 2.1334e-07, 2.5237e-03, 1.4503e-07, 5.5340e-03,\n",
      "         5.3772e-03],\n",
      "        [3.7162e-04, 2.6855e-03, 4.5733e-03, 4.8881e-03, 4.2172e-04, 5.9673e-03,\n",
      "         4.0885e-04, 4.0020e-03, 9.0021e-04, 5.4333e-03, 2.2725e-03, 5.6649e-03,\n",
      "         5.4083e-03, 0.0000e+00, 5.4054e-03, 1.5875e-04, 5.8656e-03, 7.2259e-04,\n",
      "         2.2562e-03],\n",
      "        [5.1114e-03, 2.4166e-03, 1.3630e-03, 5.6875e-03, 4.6961e-03, 8.6053e-07,\n",
      "         9.5408e-04, 7.4317e-04, 9.9611e-04, 4.7401e-03, 4.3535e-04, 2.8339e-04,\n",
      "         2.1334e-07, 5.4054e-03, 0.0000e+00, 1.0534e-03, 3.1843e-03, 2.7146e-03,\n",
      "         1.3437e-04],\n",
      "        [3.5778e-03, 4.3365e-04, 4.7315e-03, 3.9144e-03, 2.3603e-03, 4.2794e-04,\n",
      "         4.4310e-03, 4.5908e-03, 2.5651e-03, 1.5420e-07, 4.8437e-03, 9.2213e-04,\n",
      "         2.5237e-03, 1.5875e-04, 1.0534e-03, 0.0000e+00, 4.6577e-03, 5.3130e-03,\n",
      "         1.1887e-04],\n",
      "        [5.6977e-03, 3.5710e-03, 1.8255e-03, 5.9416e-03, 2.5859e-04, 2.1572e-03,\n",
      "         5.9556e-03, 3.7140e-03, 2.0239e-05, 1.2791e-03, 2.6864e-04, 2.1903e-03,\n",
      "         1.4503e-07, 5.8656e-03, 3.1843e-03, 4.6577e-03, 0.0000e+00, 2.3341e-03,\n",
      "         2.2952e-03],\n",
      "        [1.4811e-03, 2.9057e-06, 1.3949e-06, 4.9001e-03, 5.7998e-03, 5.1998e-03,\n",
      "         8.0183e-04, 5.3930e-03, 2.8563e-03, 3.0212e-04, 3.5112e-04, 4.1414e-03,\n",
      "         5.5340e-03, 7.2259e-04, 2.7146e-03, 5.3130e-03, 2.3341e-03, 0.0000e+00,\n",
      "         3.7078e-03],\n",
      "        [8.4368e-04, 3.0178e-04, 3.9777e-04, 1.2319e-03, 4.5800e-03, 2.0553e-05,\n",
      "         1.7875e-03, 5.4784e-03, 5.4335e-03, 3.7458e-04, 5.5624e-03, 8.1814e-06,\n",
      "         5.3772e-03, 2.2562e-03, 1.3437e-04, 1.1887e-04, 2.2952e-03, 3.7078e-03,\n",
      "         0.0000e+00]], grad_fn=<AddBackward0>)\n",
      "nodeInsDel: tensor(0.0028, grad_fn=<SelectBackward>)\n",
      "edge_costs :\n",
      "tensor([[0.0000, 0.1701, 0.0231],\n",
      "        [0.1701, 0.0000, 0.1240],\n",
      "        [0.0231, 0.1240, 0.0000]], grad_fn=<AddBackward0>)\n",
      "edgeInsDel: tensor(0.2463, grad_fn=<SelectBackward>)\n",
      "min_loss =  0.5293187499046326\n",
      "iter_min_loss =  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.5295639634132385\n",
      "min_loss =  0.5293187499046326\n",
      "101 0.5295643210411072\n",
      "min_loss =  0.5293187499046326\n",
      "102 0.5295654535293579\n",
      "min_loss =  0.5293187499046326\n",
      "103 0.5295692086219788\n",
      "min_loss =  0.5293187499046326\n",
      "104 0.5295679569244385\n",
      "min_loss =  0.5293187499046326\n",
      "105 0.5295689702033997\n",
      "min_loss =  0.5293187499046326\n",
      "106 0.5295735597610474\n",
      "min_loss =  0.5293187499046326\n",
      "107 0.5295698046684265\n",
      "min_loss =  0.5293187499046326\n",
      "108 0.5295696258544922\n",
      "min_loss =  0.5293187499046326\n",
      "109 0.5295686721801758\n",
      "min_loss =  0.5293187499046326\n",
      "110 0.529567301273346\n",
      "min_loss =  0.5293187499046326\n",
      "111 0.5295652747154236\n",
      "min_loss =  0.5293187499046326\n",
      "112 0.5295681953430176\n",
      "min_loss =  0.5293187499046326\n",
      "113 0.5295624732971191\n",
      "min_loss =  0.5293187499046326\n",
      "114 0.5295615792274475\n",
      "min_loss =  0.5293187499046326\n",
      "115 0.5295600891113281\n",
      "min_loss =  0.5293187499046326\n",
      "116 0.5295580625534058\n",
      "min_loss =  0.5293187499046326\n",
      "117 0.5295556783676147\n",
      "min_loss =  0.5293187499046326\n",
      "118 0.5295528769493103\n",
      "min_loss =  0.5293187499046326\n",
      "119 0.5295538902282715\n",
      "min_loss =  0.5293187499046326\n",
      "120 0.5295482277870178\n",
      "min_loss =  0.5293187499046326\n",
      "121 0.5295462012290955\n",
      "min_loss =  0.5293187499046326\n",
      "122 0.5295479893684387\n",
      "min_loss =  0.5293187499046326\n",
      "123 0.5295437574386597\n",
      "min_loss =  0.5293187499046326\n",
      "124 0.5295430421829224\n",
      "min_loss =  0.5293187499046326\n",
      "125 0.5295419692993164\n",
      "min_loss =  0.5293187499046326\n",
      "126 0.5295405387878418\n",
      "min_loss =  0.5293187499046326\n",
      "127 0.5295423865318298\n",
      "min_loss =  0.5293187499046326\n",
      "128 0.5295396447181702\n",
      "min_loss =  0.5293187499046326\n",
      "129 0.5295400619506836\n",
      "min_loss =  0.5293187499046326\n",
      "130 0.5295398235321045\n",
      "min_loss =  0.5293187499046326\n",
      "131 0.5295391082763672\n",
      "min_loss =  0.5293187499046326\n",
      "132 0.5295379757881165\n",
      "min_loss =  0.5293187499046326\n",
      "133 0.5295370221138\n",
      "min_loss =  0.5293187499046326\n",
      "134 0.5295373201370239\n",
      "min_loss =  0.5293187499046326\n",
      "135 0.5295349359512329\n",
      "min_loss =  0.5293187499046326\n",
      "136 0.529534101486206\n",
      "min_loss =  0.5293187499046326\n",
      "137 0.5295343995094299\n",
      "min_loss =  0.5293187499046326\n",
      "138 0.529533326625824\n",
      "min_loss =  0.5293187499046326\n",
      "139 0.5295321941375732\n",
      "min_loss =  0.5293187499046326\n",
      "140 0.5295311808586121\n",
      "min_loss =  0.5293187499046326\n",
      "141 0.5295299887657166\n",
      "min_loss =  0.5293187499046326\n",
      "142 0.5295283198356628\n",
      "min_loss =  0.5293187499046326\n",
      "143 0.5295268297195435\n",
      "min_loss =  0.5293187499046326\n",
      "144 0.5295251607894897\n",
      "min_loss =  0.5293187499046326\n",
      "145 0.5295242667198181\n",
      "min_loss =  0.5293187499046326\n",
      "146 0.5295225381851196\n",
      "min_loss =  0.5293187499046326\n",
      "147 0.5295217037200928\n",
      "min_loss =  0.5293187499046326\n",
      "148 0.5295206904411316\n",
      "min_loss =  0.5293187499046326\n",
      "149 0.5295195579528809\n",
      "min_loss =  0.5293187499046326\n",
      "150 0.5295172333717346\n",
      "min_loss =  0.5293187499046326\n",
      "151 0.5295159816741943\n",
      "min_loss =  0.5293187499046326\n",
      "152 0.5295146107673645\n",
      "min_loss =  0.5293187499046326\n",
      "153 0.5295202732086182\n",
      "min_loss =  0.5293187499046326\n",
      "154 0.529517412185669\n",
      "min_loss =  0.5293187499046326\n",
      "155 0.5295208692550659\n",
      "min_loss =  0.5293187499046326\n",
      "156 0.529523491859436\n",
      "min_loss =  0.5293187499046326\n",
      "157 0.5295250415802002\n",
      "min_loss =  0.5293187499046326\n",
      "158 0.5295317769050598\n",
      "min_loss =  0.5293187499046326\n",
      "159 0.5295243859291077\n",
      "min_loss =  0.5293187499046326\n",
      "160 0.5295225381851196\n",
      "min_loss =  0.5293187499046326\n",
      "161 0.5295198559761047\n",
      "min_loss =  0.5293187499046326\n",
      "162 0.529516875743866\n",
      "min_loss =  0.5293187499046326\n",
      "163 0.5295134782791138\n",
      "min_loss =  0.5293187499046326\n",
      "164 0.5295134782791138\n",
      "min_loss =  0.5293187499046326\n",
      "165 0.5295083522796631\n",
      "min_loss =  0.5293187499046326\n",
      "166 0.5295058488845825\n",
      "min_loss =  0.5293187499046326\n",
      "167 0.5295037627220154\n",
      "min_loss =  0.5293187499046326\n",
      "168 0.5295054912567139\n",
      "min_loss =  0.5293187499046326\n",
      "169 0.5295017957687378\n",
      "min_loss =  0.5293187499046326\n",
      "170 0.5294996500015259\n",
      "min_loss =  0.5293187499046326\n",
      "171 0.5295009613037109\n",
      "min_loss =  0.5293187499046326\n",
      "172 0.5294980406761169\n",
      "min_loss =  0.5293187499046326\n",
      "173 0.529498279094696\n",
      "min_loss =  0.5293187499046326\n",
      "174 0.5294966101646423\n",
      "min_loss =  0.5293187499046326\n",
      "175 0.5294957756996155\n",
      "min_loss =  0.5293187499046326\n",
      "176 0.5294942855834961\n",
      "min_loss =  0.5293187499046326\n",
      "177 0.5294939875602722\n",
      "min_loss =  0.5293187499046326\n",
      "178 0.5294895172119141\n",
      "min_loss =  0.5293187499046326\n",
      "179 0.5294886231422424\n",
      "min_loss =  0.5293187499046326\n",
      "180 0.5294856429100037\n",
      "min_loss =  0.5293187499046326\n",
      "181 0.5294842720031738\n",
      "min_loss =  0.5293187499046326\n",
      "182 0.5294825434684753\n",
      "min_loss =  0.5293187499046326\n",
      "183 0.5294801592826843\n",
      "min_loss =  0.5293187499046326\n",
      "184 0.5294781923294067\n",
      "min_loss =  0.5293187499046326\n",
      "185 0.5294749736785889\n",
      "min_loss =  0.5293187499046326\n",
      "186 0.5294764637947083\n",
      "min_loss =  0.5293187499046326\n",
      "187 0.5294715166091919\n",
      "min_loss =  0.5293187499046326\n",
      "188 0.5294686555862427\n",
      "min_loss =  0.5293187499046326\n",
      "189 0.529466986656189\n",
      "min_loss =  0.5293187499046326\n",
      "190 0.5294657945632935\n",
      "min_loss =  0.5293187499046326\n",
      "191 0.5294640064239502\n",
      "min_loss =  0.5293187499046326\n",
      "192 0.5294626355171204\n",
      "min_loss =  0.5293187499046326\n",
      "193 0.5294614434242249\n",
      "min_loss =  0.5293187499046326\n",
      "194 0.5294598340988159\n",
      "min_loss =  0.5293187499046326\n",
      "195 0.5294591188430786\n",
      "min_loss =  0.5293187499046326\n",
      "196 0.5294567942619324\n",
      "min_loss =  0.5293187499046326\n",
      "197 0.529455304145813\n",
      "min_loss =  0.5293187499046326\n",
      "198 0.5294526219367981\n",
      "min_loss =  0.5293187499046326\n",
      "199 0.5294536352157593\n",
      "min_loss =  0.5293187499046326\n",
      "Distances:  tensor([0.2788, 0.2978, 0.2855, 0.2978, 0.3055, 0.2505, 0.2673, 0.3332, 0.2189,\n",
      "        0.2228, 0.2228, 0.3108, 0.2149, 0.2672, 0.3312, 0.3116, 0.3312, 0.3317,\n",
      "        0.2827, 0.2997, 0.3755, 0.2370, 0.2432, 0.2432, 0.3472, 0.2328, 0.2996,\n",
      "        0.3058, 0.3106, 0.3113, 0.2695, 0.2800, 0.3479, 0.2274, 0.2335, 0.2335,\n",
      "        0.3315, 0.2232, 0.2799, 0.3313, 0.3318, 0.2827, 0.2997, 0.3757, 0.2372,\n",
      "        0.2431, 0.2431, 0.3474, 0.2329, 0.2996, 0.3113, 0.2697, 0.2800, 0.3483,\n",
      "        0.2271, 0.2335, 0.2335, 0.3317, 0.2230, 0.2799, 0.2701, 0.2807, 0.3492,\n",
      "        0.2279, 0.2340, 0.2341, 0.3327, 0.2238, 0.2806, 0.3292, 0.4024, 0.2566,\n",
      "        0.2690, 0.2690, 0.3837, 0.2522, 0.3291, 0.3905, 0.2462, 0.2581, 0.2581,\n",
      "        0.3721, 0.2417, 0.3105, 0.2051, 0.2133, 0.2133, 0.2974, 0.2014, 0.2489,\n",
      "        0.3287, 0.3287, 0.5168, 0.3111, 0.4181, 0.3109, 0.4868, 0.3025, 0.4042,\n",
      "        0.4868, 0.3025, 0.4042, 0.2147, 0.2672, 0.4177], grad_fn=<CopySlices>)\n",
      "Loss Triangular: 6.471678716479801e-06\n",
      "node_costs :\n",
      "tensor([[0.0000e+00, 5.0070e-04, 1.5207e-05, 3.3573e-03, 5.0003e-03, 4.4948e-03,\n",
      "         1.0749e-03, 2.8812e-03, 2.5353e-03, 1.8365e-03, 1.0250e-03, 3.5289e-03,\n",
      "         3.2888e-04, 3.2932e-04, 4.7426e-03, 3.0368e-03, 2.6124e-03, 1.7020e-03,\n",
      "         7.5136e-04],\n",
      "        [5.0070e-04, 0.0000e+00, 4.3216e-03, 2.9754e-03, 2.3317e-03, 9.3625e-04,\n",
      "         1.3878e-06, 3.8726e-03, 2.0639e-03, 1.3110e-06, 2.5649e-03, 3.1954e-04,\n",
      "         4.6549e-03, 2.2861e-03, 2.2982e-03, 4.9871e-04, 3.0312e-03, 4.3363e-07,\n",
      "         2.6455e-04],\n",
      "        [1.5207e-05, 4.3216e-03, 0.0000e+00, 1.3844e-03, 2.1567e-03, 2.3171e-03,\n",
      "         2.7265e-04, 6.0536e-04, 6.6927e-04, 4.1646e-04, 3.5116e-03, 3.6292e-07,\n",
      "         2.6850e-03, 2.7212e-03, 1.2297e-03, 1.7949e-03, 1.7563e-03, 5.5851e-07,\n",
      "         3.5368e-04],\n",
      "        [3.3573e-03, 2.9754e-03, 1.3844e-03, 0.0000e+00, 2.3978e-03, 3.1793e-03,\n",
      "         2.7628e-04, 2.5253e-03, 1.0743e-03, 3.6542e-03, 6.5683e-04, 4.0110e-03,\n",
      "         4.3377e-03, 4.3625e-03, 4.5015e-03, 3.7262e-03, 1.6109e-03, 4.3329e-03,\n",
      "         1.1082e-03],\n",
      "        [5.0003e-03, 2.3317e-03, 2.1567e-03, 2.3978e-03, 0.0000e+00, 1.9559e-03,\n",
      "         1.3390e-04, 2.1266e-03, 1.6831e-03, 4.7036e-03, 1.0911e-03, 2.5019e-03,\n",
      "         8.5042e-04, 3.7604e-04, 4.4047e-03, 2.2427e-03, 3.0560e-04, 2.5406e-03,\n",
      "         4.2945e-03],\n",
      "        [4.4948e-03, 9.3625e-04, 2.3171e-03, 3.1793e-03, 1.9559e-03, 0.0000e+00,\n",
      "         4.3024e-04, 4.2923e-03, 3.0119e-03, 2.3580e-03, 2.5063e-03, 3.7756e-04,\n",
      "         3.1619e-03, 2.4244e-03, 5.0015e-03, 3.7446e-04, 2.5021e-03, 3.0046e-04,\n",
      "         1.1120e-03],\n",
      "        [1.0749e-03, 1.3878e-06, 2.7265e-04, 2.7628e-04, 1.3390e-04, 4.3024e-04,\n",
      "         0.0000e+00, 3.7026e-04, 3.0243e-04, 3.1401e-07, 3.3424e-04, 2.2238e-03,\n",
      "         1.5050e-04, 3.6402e-04, 8.5243e-04, 3.7536e-03, 2.4324e-03, 7.1314e-04,\n",
      "         1.5280e-03],\n",
      "        [2.8812e-03, 3.8726e-03, 6.0536e-04, 2.5253e-03, 2.1266e-03, 4.2923e-03,\n",
      "         3.7026e-04, 0.0000e+00, 3.0188e-04, 4.5629e-03, 1.0716e-03, 9.9333e-04,\n",
      "         3.2144e-04, 3.8135e-03, 8.5117e-04, 4.4031e-03, 2.3018e-03, 4.3496e-03,\n",
      "         2.1538e-03],\n",
      "        [2.5353e-03, 2.0639e-03, 6.6927e-04, 1.0743e-03, 1.6831e-03, 3.0119e-03,\n",
      "         3.0243e-04, 3.0188e-04, 0.0000e+00, 1.6873e-03, 6.1552e-04, 1.8256e-03,\n",
      "         2.9978e-03, 8.0307e-04, 1.1352e-03, 2.4445e-03, 1.1093e-03, 3.3799e-03,\n",
      "         4.2660e-04],\n",
      "        [1.8365e-03, 1.3110e-06, 4.1646e-04, 3.6542e-03, 4.7036e-03, 2.3580e-03,\n",
      "         3.1401e-07, 4.5629e-03, 1.6873e-03, 0.0000e+00, 1.5226e-03, 2.8109e-03,\n",
      "         3.0142e-04, 4.5355e-03, 1.7901e-03, 3.8694e-07, 1.1519e-03, 3.5133e-04,\n",
      "         3.3207e-04],\n",
      "        [1.0250e-03, 2.5649e-03, 3.5116e-03, 6.5683e-04, 1.0911e-03, 2.5063e-03,\n",
      "         3.3424e-04, 1.0716e-03, 6.1552e-04, 1.5226e-03, 0.0000e+00, 2.7526e-05,\n",
      "         4.5353e-03, 2.1565e-03, 5.0047e-04, 4.4726e-03, 2.3216e-04, 3.1026e-04,\n",
      "         4.7634e-03],\n",
      "        [3.5289e-03, 3.1954e-04, 3.6292e-07, 4.0110e-03, 2.5019e-03, 3.7756e-04,\n",
      "         2.2238e-03, 9.9333e-04, 1.8256e-03, 2.8109e-03, 2.7526e-05, 0.0000e+00,\n",
      "         1.3526e-04, 4.0644e-03, 3.3170e-04, 1.0587e-03, 2.0757e-03, 3.9527e-03,\n",
      "         5.4908e-06],\n",
      "        [3.2888e-04, 4.6549e-03, 2.6850e-03, 4.3377e-03, 8.5042e-04, 3.1619e-03,\n",
      "         1.5050e-04, 3.2144e-04, 2.9978e-03, 3.0142e-04, 4.5353e-03, 1.3526e-04,\n",
      "         0.0000e+00, 4.1713e-03, 3.0751e-07, 2.4037e-03, 4.0146e-07, 4.8247e-03,\n",
      "         4.2405e-03],\n",
      "        [3.2932e-04, 2.2861e-03, 2.7212e-03, 4.3625e-03, 3.7604e-04, 2.4244e-03,\n",
      "         3.6402e-04, 3.8135e-03, 8.0307e-04, 4.5355e-03, 2.1565e-03, 4.0644e-03,\n",
      "         4.1713e-03, 0.0000e+00, 4.1777e-03, 1.3241e-04, 2.4947e-03, 6.4092e-04,\n",
      "         1.9241e-03],\n",
      "        [4.7426e-03, 2.2982e-03, 1.2297e-03, 4.5015e-03, 4.4047e-03, 5.0015e-03,\n",
      "         8.5243e-04, 8.5117e-04, 1.1352e-03, 1.7901e-03, 5.0047e-04, 3.3170e-04,\n",
      "         3.0751e-07, 4.1777e-03, 0.0000e+00, 9.4366e-04, 2.7060e-03, 2.3106e-03,\n",
      "         2.0283e-03],\n",
      "        [3.0368e-03, 4.9871e-04, 1.7949e-03, 3.7262e-03, 2.2427e-03, 3.7446e-04,\n",
      "         3.7536e-03, 4.4031e-03, 2.4445e-03, 3.8694e-07, 4.4726e-03, 1.0587e-03,\n",
      "         2.4037e-03, 1.3241e-04, 9.4366e-04, 0.0000e+00, 4.3686e-03, 4.3863e-03,\n",
      "         9.6815e-05],\n",
      "        [2.6124e-03, 3.0312e-03, 1.7563e-03, 1.6109e-03, 3.0560e-04, 2.5021e-03,\n",
      "         2.4324e-03, 2.3018e-03, 1.1093e-03, 1.1519e-03, 2.3216e-04, 2.0757e-03,\n",
      "         4.0146e-07, 2.4947e-03, 2.7060e-03, 4.3686e-03, 0.0000e+00, 2.2170e-03,\n",
      "         2.1787e-03],\n",
      "        [1.7020e-03, 4.3363e-07, 5.5851e-07, 4.3329e-03, 2.5406e-03, 3.0046e-04,\n",
      "         7.1314e-04, 4.3496e-03, 3.3799e-03, 3.5133e-04, 3.1026e-04, 3.9527e-03,\n",
      "         4.8247e-03, 6.4092e-04, 2.3106e-03, 4.3863e-03, 2.2170e-03, 0.0000e+00,\n",
      "         1.5720e-05],\n",
      "        [7.5136e-04, 2.6455e-04, 3.5368e-04, 1.1082e-03, 4.2945e-03, 1.1120e-03,\n",
      "         1.5280e-03, 2.1538e-03, 4.2660e-04, 3.3207e-04, 4.7634e-03, 5.4908e-06,\n",
      "         4.2405e-03, 1.9241e-03, 2.0283e-03, 9.6815e-05, 2.1787e-03, 1.5720e-05,\n",
      "         0.0000e+00]], grad_fn=<AddBackward0>)\n",
      "nodeInsDel: tensor(0.0023, grad_fn=<SelectBackward>)\n",
      "edge_costs :\n",
      "tensor([[0.0000, 0.2952, 0.0058],\n",
      "        [0.2952, 0.0000, 0.1331],\n",
      "        [0.0058, 0.1331, 0.0000]], grad_fn=<AddBackward0>)\n",
      "edgeInsDel: tensor(0.2285, grad_fn=<SelectBackward>)\n",
      "min_loss =  0.5293187499046326\n",
      "iter_min_loss =  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min cost for nodeInsDel =  0.001308500417508185\n",
      " Min cost for edgeInsDel =  0.19402042031288147\n",
      " Min cost for nodeSub =  [2.14166837e-04 1.42646386e-04 1.48759311e-04 4.20803626e-05\n",
      " 6.08724775e-04 2.02249314e-04 1.56154172e-04 8.11594306e-04\n",
      " 5.74781501e-04 7.16024515e-05 8.14769955e-05 3.77772842e-04\n",
      " 3.77935445e-04 6.63441606e-04 1.24279963e-04 7.87247904e-04\n",
      " 1.83840268e-04 4.79858318e-05 7.10726250e-04 6.56033866e-04\n",
      " 9.53200448e-04 5.85842026e-05 2.69298092e-04 6.33396776e-05\n",
      " 1.74497996e-04 2.68958916e-04 8.02160997e-04 2.33936044e-05\n",
      " 6.54797477e-04 1.46858729e-04 9.40179103e-04 2.14547385e-04\n",
      " 1.24432408e-04 2.63999886e-04 3.53387906e-04 1.91810468e-04\n",
      " 8.85742716e-04 9.47525667e-04 3.56538862e-04 3.96826363e-05\n",
      " 4.33124806e-05 2.89492182e-05 8.18835179e-05 2.51449004e-04\n",
      " 4.80132730e-05 1.36234856e-04 7.56908848e-05 5.88864554e-04\n",
      " 3.08071139e-05 1.06299321e-05 3.86827363e-04 9.78986965e-04\n",
      " 1.20517594e-04 2.38640612e-04 9.40931714e-05 6.65831612e-05\n",
      " 4.31350549e-04 4.26053339e-05 4.91825049e-04 5.50294993e-04\n",
      " 6.19072991e-04 7.84995849e-04 4.43265162e-04 8.16837128e-05\n",
      " 6.21431915e-04 6.85630148e-05 1.58683702e-04 3.24994355e-04\n",
      " 8.74276971e-04 1.69657171e-04 6.66634005e-04 6.75652773e-05\n",
      " 1.01994711e-03 5.36497064e-05 3.94854083e-04 1.30873610e-04\n",
      " 9.18766542e-04 2.30799546e-04 8.09899066e-04 1.35937895e-04\n",
      " 4.13851114e-04 1.26102823e-04 4.39981959e-05 9.63435043e-04\n",
      " 1.02167181e-03 2.67270352e-05 9.70078763e-05 8.47770832e-04\n",
      " 4.20211618e-05 2.65498002e-05 1.62039258e-04 6.81441918e-04\n",
      " 4.24838108e-05 3.92791815e-04 6.77719945e-04 2.63007416e-04\n",
      " 3.79745441e-04 1.48984531e-04 3.33350006e-04 3.90554895e-04\n",
      " 5.37651249e-05 1.06661420e-04 8.45096016e-04 4.58080613e-05\n",
      " 1.76492744e-04 6.78772049e-04 7.78459420e-04 6.64286272e-05\n",
      " 6.98240256e-05 2.26792981e-04 4.57913673e-04 2.08539306e-04\n",
      " 5.62371220e-04 6.18786653e-05 1.23274702e-04 5.56283703e-05\n",
      " 8.45166651e-05 4.02589794e-05 5.78450446e-04 1.48955660e-04\n",
      " 5.09386518e-05 1.94963664e-04 9.97303054e-04 4.26467777e-05\n",
      " 1.47483413e-04 8.93706747e-05 1.76738278e-04 1.60677169e-04\n",
      " 2.23455900e-05 8.38650376e-05 5.90500887e-04 2.51257210e-04\n",
      " 7.11158791e-05 2.19611393e-04 3.78949102e-04 2.84134789e-04\n",
      " 6.35105418e-04 8.85660469e-04 2.14209853e-04 6.10440737e-04\n",
      " 1.82973545e-05 3.70859809e-04 7.57745875e-04 3.25693400e-04\n",
      " 1.13004397e-04 2.24272342e-04 2.04279713e-04 8.54940852e-04\n",
      " 4.81703784e-04 1.29825057e-05 7.24813959e-04 2.51917780e-04\n",
      " 9.81288147e-04 2.51143909e-04 7.51610787e-04 7.18256983e-04\n",
      " 7.24196434e-04 3.24226770e-04 8.24668619e-04 4.17014344e-05\n",
      " 1.59902032e-04 5.90117015e-05 1.33607246e-04 1.46035061e-04\n",
      " 4.08299275e-05 1.32529472e-04 7.04818696e-04 3.04866611e-04\n",
      " 9.08852031e-04 8.94172059e-04 1.43895755e-04]\n",
      " Min cost for edgeSub =  [0.37704509 0.00239323 0.36609864]\n"
     ]
    }
   ],
   "source": [
    "#if torch.cuda.device_count() > 1:\n",
    "#  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "#  model = nn.DataParallel(model)\n",
    "from triangular_losses import TriangularConstraint as triangular_constraint\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "def classification(model,data,yt,nb_iter):\n",
    "\n",
    "    min_loss,iter_min_loss=10,0\n",
    "    criterion = torch.nn.HingeEmbeddingLoss(margin=1.0)\n",
    "    criterionTri=triangular_constraint()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    print(device)\n",
    "\n",
    "#torch.cat((same_class[0:20],diff_class[0:20]),0).to(device)\n",
    "    input=data.to(device)\n",
    "    target=yt.to(device) \n",
    "#torch.ones(40,device=device)\n",
    "#target[20:]=-1.0\n",
    "#target=(yt[0:20]).to(device)\n",
    "    InsDel=np.empty((nb_iter,2))\n",
    "    node_costs,nodeInsDel,edge_costs,edgeInsDel=model.from_weighs_to_costs()\n",
    "    nodeSub=np.empty((nb_iter,int(node_costs.shape[0]*(node_costs.shape[0]-1)/2)))\n",
    "    edgeSub=np.empty((nb_iter,int(edge_costs.shape[0]*(edge_costs.shape[0]-1)/2)))\n",
    "    loss_plt=np.empty(nb_iter)\n",
    "    for t in range(nb_iter):    \n",
    "        # Forward pass: Compute predicted y by passing data to the model    \n",
    "\n",
    "\n",
    "        y_pred = model(input).to(device)\n",
    "    \n",
    "    \n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, target).to(device)    \n",
    "        node_costs,nodeInsDel,edge_costs,edgeInsDel=model.from_weighs_to_costs()\n",
    "        triangularInq=criterionTri(node_costs,nodeInsDel,edge_costs,edgeInsDel)\n",
    "        loss=loss*(1+triangularInq)\n",
    "        loss.to(device)\n",
    "        InsDel[t][0]=nodeInsDel.item()\n",
    "        InsDel[t][1]=edgeInsDel.item()\n",
    "        loss_plt[t]=loss.item()\n",
    "        if (loss.item()< min_loss):\n",
    "            min_loss = loss.item()\n",
    "            iter_min_loss=t\n",
    "        print(t, loss.item())  \n",
    "        print('min_loss = ', min_loss)\n",
    "        k=0\n",
    "        for p in range(node_costs.shape[0]):\n",
    "            for q in range(p+1,node_costs.shape[0]):\n",
    "                nodeSub[t][k]=node_costs[p][q]\n",
    "                k=k+1\n",
    "        k=0\n",
    "        for p in range(edge_costs.shape[0]):\n",
    "            for q in range(p+1,edge_costs.shape[0]):\n",
    "                edgeSub[t][k]=edge_costs[p][q]\n",
    "                k=k+1\n",
    "        if t==iter_min_loss: print('node_costs for min of the loss : ', node_costs)\n",
    "        if t % 100 == 99 or t==0:                         \n",
    "            print('Distances: ',y_pred)\n",
    "            print('Loss Triangular:',triangularInq.item())\n",
    "            print('node_costs :')\n",
    "            print(node_costs)\n",
    "            print('nodeInsDel:',nodeInsDel)\n",
    "            print('edge_costs :')\n",
    "            print(edge_costs)\n",
    "            print('edgeInsDel:',edgeInsDel)\n",
    "            print('min_loss = ', min_loss)\n",
    "            print('iter_min_loss = ', iter_min_loss)\n",
    "            \n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    nodeInsDel_min = InsDel[iter_min_loss][0]\n",
    "    edgeInsDel_min = InsDel[iter_min_loss][1]\n",
    "    nodeSub_min = nodeSub[iter_min_loss]\n",
    "    edgeSub_min = edgeSub[iter_min_loss]\n",
    "    print(' Min cost for nodeInsDel = ', nodeInsDel_min)\n",
    "    print(' Min cost for edgeInsDel = ', edgeInsDel_min)\n",
    "    print(' Min cost for nodeSub = ', nodeSub_min)\n",
    "    print(' Min cost for edgeSub = ', edgeSub_min)\n",
    "    return InsDel,nodeSub,edgeSub,loss_plt\n",
    "\n",
    "nb_iter=200\n",
    "InsDel, nodeSub,edgeSub,loss_plt=classification(model,data,yt,nb_iter)\n",
    "plt.figure(0)\n",
    "plt.plot(InsDel[0:nb_iter,0],label=\"node\")\n",
    "plt.plot(InsDel[0:nb_iter,1],label=\"edge\")\n",
    "plt.title('Node/Edge insertion/deletion costs')\n",
    "plt.legend()\n",
    "plt.figure(1)\n",
    "for k in range(nodeSub.shape[1]):\n",
    "    plt.plot(nodeSub[0:nb_iter,k])\n",
    "plt.title('Node Substitutions costs')\n",
    "plt.figure(2)\n",
    "for k in range(edgeSub.shape[1]):\n",
    "    plt.plot(edgeSub[0:nb_iter,k])\n",
    "plt.title('Edge Substitutions costs')\n",
    "plt.figure(3)\n",
    "plt.plot(loss_plt)\n",
    "plt.title('Evolution of the loss')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "A=torch.tensor(nx.to_scipy_sparse_matrix(Gs[0],dtype=int,weight='bond_type').todense(),dtype=torch.int) \n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.plot(InsDel[0:500,0],label=\"node\")\n",
    "plt.plot(InsDel[0:500,1],label=\"edge\")\n",
    "plt.title('Node/Edge insertion/deletion costs')\n",
    "plt.legend()\n",
    "plt.figure(1)\n",
    "for k in range(nodeSub.shape[1]):\n",
    "    plt.plot(nodeSub[0:500,k])\n",
    "plt.title('node Substitution costs')\n",
    "plt.figure(2)\n",
    "for k in range(edgeSub.shape[1]):\n",
    "    plt.plot(edgeSub[0:500,k])\n",
    "plt.title('edge Substitution costs')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
