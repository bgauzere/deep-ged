{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gklearn.utils.graphfiles import loadDataset\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge max label 1\n",
      "64.4 52.5\n",
      "{'atom': 'C', 'label': ['C'], 'attributes': ['0.0000', '0.0000', '0.0000'], 'extended_label': ['C_1C']}\n",
      "{'atom': 'C', 'label': ['C'], 'attributes': ['0.0000', '0.0000', '0.0000'], 'extended_label': ['C_1C']}\n",
      "{'atom': 'C', 'label': ['C'], 'attributes': ['0.0000', '0.0000', '0.0000'], 'extended_label': ['C_1O']}\n",
      "{'atom': 'C', 'label': ['C'], 'attributes': ['0.0000', '0.0000', '0.0000'], 'extended_label': ['C_1C1C1O']}\n",
      "{'atom': 'O', 'label': ['O'], 'attributes': ['0.0000', '0.0000', '0.0000'], 'extended_label': ['O_1C1C']}\n"
     ]
    }
   ],
   "source": [
    "def label_to_color(label):\n",
    "    if label == 'C':\n",
    "        return 0.1\n",
    "    elif label == 'O':\n",
    "        return 0.8\n",
    "    \n",
    "def nodes_to_color_sequence(G):\n",
    "    return [label_to_color(c[1]['label'][0]) for c in G.nodes(data=True)]\n",
    "\n",
    "#Gs,y = loadDataset('/home/luc/TRAVAIL/DeepGED/Acyclic/trainset_0.ds')\n",
    "Gs,y = loadDataset('../DeepGED/Acyclic/trainset_0.ds')\n",
    "\n",
    "#for e in Gs[13].edges():\n",
    "#    print(Gs[13][e[0]][e[1]]['bond_type'])\n",
    "print('edge max label',max(max([[G[e[0]][e[1]]['bond_type'] for e in G.edges()] for G in Gs])))\n",
    "G1 = Gs[1]\n",
    "G2 = Gs[9]\n",
    "print(y[13],y[23])\n",
    "nx.draw_networkx(G1,with_labels=True,node_color = nodes_to_color_sequence(G1),cmap='autumn')\n",
    "plt.figure()\n",
    "\n",
    "nx.draw_networkx(G2,with_labels=True,node_color = nodes_to_color_sequence(G2),cmap='autumn')\n",
    "\n",
    "import extended_label\n",
    "for g in Gs:\n",
    "    extended_label.compute_extended_labels(g)\n",
    "for v in Gs[10].nodes():\n",
    "        print(Gs[10].nodes[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import svd\n",
    "#from svd import iterated_power as compute_major_axis\n",
    "import rings\n",
    "compute_major_axis=svd.CustomMajorAxis.apply\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "        \n",
    "    def __init__(self,GraphList,normalize=False,node_label='label'):\n",
    "        super(Net, self).__init__()   \n",
    "        self.normalize=normalize\n",
    "        self.node_label=node_label\n",
    "        dict,self.nb_edge_labels=self.build_node_dictionnary(GraphList)\n",
    "        self.nb_labels=len(dict)\n",
    "        print('nb labels:',self.nb_labels,' ; nb_edge_labels:',self.nb_edge_labels)\n",
    "        self.device= 'cuda' if torch.cuda.is_available() else 'cpu'  #torch.device(\"cuda:0\")\n",
    "        nb_node_pair_label=self.nb_labels*(self.nb_labels-1)/2.0\n",
    "        nb_edge_pair_label=int(self.nb_edge_labels*(self.nb_edge_labels-1)/2)\n",
    "        self.node_weighs=nn.Parameter(torch.tensor(1.0/(nb_node_pair_label+nb_edge_pair_label+2))+(1e-3)*torch.rand(int(nb_node_pair_label+1),requires_grad=True,device=self.device)) # all substitution costs+ nodeIns/Del. old version: 0 node subs, 1 nodeIns/Del, 2 : edgeSubs, 3 edgeIns/Del        \n",
    "        self.edge_weighs=nn.Parameter(torch.tensor(1.0/(nb_node_pair_label+nb_edge_pair_label+2))+(1e-3)*torch.rand(nb_edge_pair_label+1,requires_grad=True,device=self.device)) #edgeIns/Del\n",
    "        #self.coef_dist=nn.Parameter(torch.tensor(1.0,requires_grad=True,device=self.device))\n",
    "        self.card=torch.tensor([G.order() for G in GraphList]).to(self.device)\n",
    "        card_max=self.card.max()\n",
    "        self.A=torch.empty((len(GraphList),card_max*card_max),dtype=torch.int,device=self.device)\n",
    "        self.labels=torch.empty((len(GraphList),card_max),dtype=torch.int,device=self.device)\n",
    "        print(self.A.shape)\n",
    "        for k in range(len(GraphList)):\n",
    "            A,l=self.from_networkx_to_tensor(GraphList[k],dict)             \n",
    "            self.A[k,0:A.shape[1]]=A[0]\n",
    "            self.labels[k,0:l.shape[0]]=l\n",
    "        print('adjacency matrices',self.A)\n",
    "        print('node labels',self.labels)\n",
    "        print('order of the graphs',self.card)\n",
    "        \n",
    "    def forward(self, input):        \n",
    "        ged=torch.zeros(len(input)).to(self.device) \n",
    "        node_costs,nodeInsDel,edge_costs,edgeInsDel=self.from_weighs_to_costs()\n",
    "        #alpha=self.coef_dist*self.coef_dist\n",
    "            \n",
    "        \n",
    "        #print('weighs:',self.weighs.device,'device:',self.device,'card:',self.card.device,'A:',self.A.device,'labels:',self.labels.device)\n",
    "        for k in range(len(input)):            \n",
    "            g1=input[k][0]\n",
    "            g2=input[k][1]\n",
    "            n=self.card[g1]\n",
    "            m=self.card[g2]\n",
    "            \n",
    "            #self.ring_g,self.ring_h = rings.build_rings(g1,edgeInsDel.size()), rings.build_rings(g2,edgeInsDel.size()) \n",
    "\n",
    "            C=self.construct_cost_matrix(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)      \n",
    "            \n",
    "            #S=self.mapping_from_similarity(C,n,m) # SVD or iterated power according to compute major axis\n",
    "            S=self.mapping_from_cost(C,n,m) # FW\n",
    "            #S=self.mapping_from_cost_sans_FW(n,m,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "            \n",
    "            v=torch.flatten(S)\n",
    "            \n",
    "            normalize_factor=1.0\n",
    "            if self.normalize:\n",
    "                nb_edge1=(self.A[g1][0:n*n] != torch.zeros(n*n,device=self.device)).int().sum()\n",
    "                nb_edge2=(self.A[g2][0:m*m] != torch.zeros(m*m,device=self.device)).int().sum()\n",
    "                normalize_factor=nodeInsDel*(n+m)+edgeInsDel*(nb_edge1 +nb_edge2)                                    \n",
    "            c=torch.diag(C)\n",
    "            D=C-torch.eye(C.shape[0],device=self.device)*c\n",
    "            ged[k]=(.5*v.T@D@v+c.T@v)/normalize_factor    \n",
    "        return ged\n",
    "    \n",
    "    def from_weighs_to_costs(self):\n",
    "        \n",
    "        #cn=torch.exp(self.node_weighs)\n",
    "        #ce=torch.exp(self.edge_weighs)\n",
    "        cn=self.node_weighs*self.node_weighs\n",
    "        ce=self.edge_weighs*self.edge_weighs\n",
    "        total_cost=cn.sum()+ce.sum()\n",
    "        cn=cn/total_cost\n",
    "        ce=ce/total_cost\n",
    "        edgeInsDel=ce[-1]\n",
    "\n",
    "        node_costs=torch.zeros((self.nb_labels,self.nb_labels),device=self.device)\n",
    "        upper_part=torch.triu_indices(node_costs.shape[0],node_costs.shape[1],offset=1,device=self.device)        \n",
    "        node_costs[upper_part[0],upper_part[1]]=cn[0:-1]\n",
    "        node_costs=node_costs+node_costs.T\n",
    "        if self.nb_edge_labels>1:\n",
    "            edge_costs=torch.zeros((self.nb_edge_labels,self.nb_edge_labels),device=self.device)\n",
    "            upper_part=torch.triu_indices(edge_costs.shape[0],edge_costs.shape[1],offset=1,device=self.device)        \n",
    "            edge_costs[upper_part[0],upper_part[1]]=ce[0:-1]\n",
    "            edge_costs=edge_costs+edge_costs.T\n",
    "        else:\n",
    "            edge_costs=torch.zeros(0,device=self.device)\n",
    "        \n",
    "        return node_costs,cn[-1],edge_costs,edgeInsDel\n",
    "    \n",
    "    def build_node_dictionnary(self,GraphList):\n",
    "        #extraction de tous les labels d'atomes\n",
    "        node_labels=[]\n",
    "        for G in Gs:\n",
    "            for v in nx.nodes(G):\n",
    "                if not G.nodes[v][self.node_label][0] in node_labels:\n",
    "                    node_labels.append(G.nodes[v][self.node_label][0])\n",
    "        node_labels.sort()\n",
    "        #extraction d'un dictionnaire permettant de numéroter chaque label par un numéro.\n",
    "        dict={}\n",
    "        k=0\n",
    "        for label in node_labels:\n",
    "            dict[label]=k\n",
    "            k=k+1\n",
    "        print(node_labels)\n",
    "        print(dict,len(dict))\n",
    "    \n",
    "        return dict,max(max([[int(G[e[0]][e[1]]['bond_type']) for e in G.edges()] for G in GraphList]))\n",
    "    \n",
    "    def from_networkx_to_tensor(self,G,dict):    \n",
    "        A=torch.tensor(nx.to_scipy_sparse_matrix(G,dtype=int,weight='bond_type').todense(),dtype=torch.int)        \n",
    "        lab=[dict[G.nodes[v][self.node_label][0]] for v in nx.nodes(G)]\n",
    "   \n",
    "        return (A.view(1,A.shape[0]*A.shape[1]),torch.tensor(lab))\n",
    "\n",
    "    def construct_cost_matrix(self,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel):\n",
    "        n = self.card[g1].item()\n",
    "        m = self.card[g2].item()\n",
    "        \n",
    "        A1=torch.zeros((n+1,n+1),dtype=torch.int,device=self.device)\n",
    "        A1[0:n,0:n]=self.A[g1][0:n*n].view(n,n)\n",
    "        A2=torch.zeros((m+1,m+1),dtype=torch.int,device=self.device)\n",
    "        A2[0:m,0:m]=self.A[g2][0:m*m].view(m,m)\n",
    "        \n",
    "        \n",
    "         # costs: 0 node subs, 1 nodeIns/Del, 2 : edgeSubs, 3 edgeIns/Del\n",
    "        \n",
    "        #C=cost[3]*torch.cat([torch.cat([C12[l][k] for k in range(n+1)],1) for l in range(n+1)])\n",
    "        #Pas bien sur mais cela semble fonctionner.\n",
    "        C=edgeInsDel*self.matrix_edgeInsDel(A1,A2)\n",
    "        if self.nb_edge_labels>1:\n",
    "            for k in range(self.nb_edge_labels):\n",
    "                for l in range(self.nb_edge_labels):\n",
    "                    if k != l:\n",
    "#                    C.add_(self.matrix_edgeSubst(A1,A2,k+1,l+1),alpha=edge_costs[k][l])\n",
    "                        C=C+edge_costs[k][l]*self.matrix_edgeSubst(A1,A2,k+1,l+1)\n",
    "        #C=cost[3]*torch.tensor(np.array([ [  k!=l and A1[k//(m+1),l//(m+1)]^A2[k%(m+1),l%(m+1)] for k in range((n+1)*(m+1))] for l in range((n+1)*(m+1))]),device=self.device)        \n",
    "\n",
    "        l1=self.labels[g1][0:n]\n",
    "        l2=self.labels[g2][0:m]\n",
    "        D=torch.zeros((n+1)*(m+1),device=self.device)\n",
    "        D[n*(m+1):]=nodeInsDel\n",
    "        D[n*(m+1)+m]=0\n",
    "        D[[i*(m+1)+m for i in range(n)]]=nodeInsDel\n",
    "        D[[k for k in range(n*(m+1)) if k%(m+1) != m]]=torch.tensor([node_costs[l1[k//(m+1)],l2[k%(m+1)]] for k in range(n*(m+1)) if k%(m+1) != m],device=self.device )\n",
    "        mask = torch.diag(torch.ones_like(D))\n",
    "        C=mask*torch.diag(D) + (1. - mask)*C\n",
    "        \n",
    "        #C[range(len(C)),range(len(C))]=D\n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        return C\n",
    "    def matrix_edgeInsDel(self,A1,A2):\n",
    "        Abin1=(A1!=torch.zeros((A1.shape[0],A1.shape[1]),device=self.device))\n",
    "        Abin2=(A2!=torch.zeros((A2.shape[0],A2.shape[1]),device=self.device))\n",
    "        C1=torch.einsum('ij,kl->ijkl',torch.logical_not(Abin1),Abin2)\n",
    "        C2=torch.einsum('ij,kl->ijkl',Abin1,torch.logical_not(Abin2))\n",
    "        C12=torch.logical_or(C1,C2).int()\n",
    "    \n",
    "        return torch.cat(torch.unbind(torch.cat(torch.unbind(C12,1),1),0),1)\n",
    "\n",
    "    def matrix_edgeSubst(self,A1,A2,lab1,lab2):\n",
    "        Abin1=(A1==lab1*torch.ones((A1.shape[0],A1.shape[1]),device=self.device)).int()\n",
    "        Abin2=(A2==lab2*torch.ones((A2.shape[0],A2.shape[1]),device=self.device)).int()\n",
    "        C=torch.einsum('ij,kl->ijkl',Abin1,Abin2)\n",
    "        \n",
    "        return torch.cat(torch.unbind(torch.cat(torch.unbind(C,1),1),0),1)\n",
    "    \n",
    "    def mapping_from_cost(self,C,n,m):\n",
    "        c=torch.diag(C)\n",
    "        D=C-torch.eye(C.shape[0],device=self.device)*c\n",
    "        x0=svd.eps_assigment_from_mapping(torch.exp(-2.0*c.view(n+1,m+1)),10).view((n+1)*(m+1),1) # a améliorer.\n",
    "        return svd.franck_wolfe(x0,D,c,5,10,n,m)\n",
    "    \n",
    "    def similarity_from_cost(self,C):\n",
    "        N=C.shape[0]\n",
    "             \n",
    "        return (C.max()*torch.eye(N,device=self.device) -C)\n",
    "\n",
    "    def lsape_populate_instance(self,first_graph,second_graph,average_node_cost, average_edge_cost,alpha,lbda):       #ring_g, ring_h come from global ring with all graphs in so ring_g = rings['g'] and ring_h = rings['h']\n",
    "        g,h = Gs[first_graph], Gs[second_graph]\n",
    "        self.average_cost =[average_node_cost, average_edge_cost]\n",
    "        self.first_graph, self.second_graph = first_graph,second_graph\n",
    "        \n",
    "        node_costs,nodeInsDel,edge_costs,edgeInsDel=self.from_weighs_to_costs()\n",
    "\n",
    "        lsape_instance = [[0 for _ in range(len(g) + 1)] for __ in range(len(h) + 1)]\n",
    "        for g_node_index in range(len(g) + 1):\n",
    "            for h_node_index in range(len(h) + 1):\n",
    "                lsape_instance[h_node_index][g_node_index] = rings.compute_ring_distance(g,h,self.ring_g,self.ring_h,g_node_index,h_node_index,alpha,lbda,node_costs,nodeInsDel,edge_costs,edgeInsDel,first_graph,second_graph)\n",
    "        for i in lsape_instance :\n",
    "            i = torch.as_tensor(i)\n",
    "        lsape_instance = torch.as_tensor(lsape_instance)\n",
    "        #print(type(lsape_instance))\n",
    "        return lsape_instance\n",
    "    \n",
    "  \n",
    "    def mapping_from_cost_sans_FW(self,n,m,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel): \n",
    "        c_0 =self.lsape_populate_instance(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "        x0=svd.eps_assigment_from_mapping(torch.exp(-c_0),10).view((n+1)*(m+1),1)\n",
    "        return x0\n",
    "    \n",
    "    def new_mapping_from_cost(self,C,n,m,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel): \n",
    "        c=torch.diag(C)       \n",
    "        c_0 =self.lsape_populate_instance(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)\n",
    "        D=C-torch.eye(C.shape[0],device=self.device)*c\n",
    "        x0=svd.eps_assigment_from_mapping(torch.exp(-c_0),10).view((n+1)*(m+1),1)\n",
    "        return svd.franck_wolfe(x0,D,c,5,15,n,m)\n",
    "    \n",
    "    def mapping_from_similarity(self,C,n,m):\n",
    "        M=self.similarity_from_cost(C)\n",
    "        first_ev=compute_major_axis(M)\n",
    "        #first_ev=self.iterated_power(M,inv=True)\n",
    "        if(first_ev.sum() <0):\n",
    "            first_ev=-first_ev\n",
    "        S=torch.exp(first_ev.view(n+1,m+1)) # enforce the difference, accelerate the convergence. \n",
    "        S=self.eps_assigment_from_mapping(S)\n",
    "        return  S\n",
    "        \n",
    "    def eps_assigment_from_mapping(self,S):\n",
    "        ones_n = torch.ones(S.shape[0],device=S.device)\n",
    "        ones_m = torch.ones(S.shape[1],device=S.device)\n",
    "    \n",
    "        Sk = S\n",
    "        for i in range(20):\n",
    "            D=torch.diag(1.0/(Sk@ones_m))\n",
    "            D[D.shape[0]-1,D.shape[1]-1]=1.0\n",
    "            Sk1 = D@Sk\n",
    "            D=torch.diag(1.0/(ones_n@Sk1))\n",
    "            D[D.shape[0]-1,D.shape[1]-1]=1.0\n",
    "            Sk = Sk1@D\n",
    "        \n",
    "        return Sk\n",
    "    \n",
    "            \n",
    "#print(model(input))\n",
    "#print(max([G.order() for G in Gs]),len(Gs))\n",
    "#print('toto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train graphs: tensor([ 39,  95,  51, 125,  79, 148,  87, 154, 153,  97,  18,  94,   6, 127,\n",
      "         60,  68, 150, 109, 113, 121,   8,  67,  19,  45, 123,  85,  34, 151,\n",
      "        136,  44,  12, 146,  76,  25, 116,  30,  52, 112,  56, 130,  81, 111,\n",
      "         50,  33,  98, 141,  35, 137,  11,  23,   9, 152,  22,  80, 107,  48,\n",
      "        131,  61, 159,  20, 114, 149, 157, 129,  91,   2, 156,   7,  27,  43])\n",
      "data= tensor([[114,  39],\n",
      "        [114,  95],\n",
      "        [114,  51],\n",
      "        ...,\n",
      "        [ 43,  61],\n",
      "        [ 43, 159],\n",
      "        [ 43,  20]], dtype=torch.int32) 600\n",
      "yt= tensor([ 92.3000, 145.0000,  96.0000, 195.0000,  91.5000, 218.0000, 124.0000,\n",
      "        173.2000, 162.0000, 138.0000, 156.0000, 155.0000,  66.6000, 201.0000,\n",
      "        134.2000, 181.0000, 235.0000, 106.0000, 109.5000, 148.5000, 148.5000,\n",
      "        177.2000, 166.0000,  93.0000, 177.0000, 114.0000, 118.5000, 186.5000,\n",
      "        173.0000,  91.5000,  53.5000, 159.0000, 102.5000,  59.5000, 158.0000,\n",
      "         92.0000, 112.0000, 128.5000, 145.0000, 165.5000, 101.0000, 151.0000,\n",
      "        103.5000, 112.5000, 142.0000, 126.0000, 101.5000, 159.5000,  63.0000,\n",
      "         52.5000,  34.6000, 156.5000,  63.6000,  87.6000, 121.0000,  82.0000,\n",
      "        157.0000, 137.0000, 188.5000, 183.0000, 126.0000, 250.0000, 187.0000,\n",
      "        151.5000, 141.0000, 109.7000, 173.0000, 135.0000,  83.0000,  91.2000])\n"
     ]
    }
   ],
   "source": [
    "from regression import KnnRegressFromGED as regress\n",
    "from regression import train_set_for_knnregression as create_dataset\n",
    "\n",
    "nb=len(Gs)\n",
    "#class1=torch.tensor([k for k in range(len(y)) if y[k]==1])\n",
    "#class2=torch.tensor([k for k in range(len(y)) if y[k]==0])\n",
    "\n",
    "train_size=70\n",
    "nb_test=10\n",
    "train_graphs=torch.randperm(nb)[0:train_size]\n",
    "print('train graphs:', train_graphs)\n",
    "\n",
    "\n",
    "\n",
    "#couples=[]\n",
    "#for k in range(nb_elt):\n",
    "#    if (y[data[k][0]]!=y[data[k][1]]):\n",
    "#        yt[k]=-1.0        \n",
    "#data,yt=train_set_for_kernel_ridge(train_graphs,y,train_size)\n",
    "data,yt=create_dataset(train_graphs,y,train_size,nb_test)\n",
    "print('data=',data,data.shape[0])\n",
    "print('yt=',yt)\n",
    "#print(couples[1:2])\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")          # a CUDA device object    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C_1C', 'C_1C1C', 'C_1C1C1C', 'C_1C1C1C1C', 'C_1C1C1C1O', 'C_1C1C1C1S', 'C_1C1C1O', 'C_1C1C1O1O', 'C_1C1C1S', 'C_1C1C1S1S', 'C_1C1O', 'C_1C1O1O', 'C_1C1S', 'C_1C1S1S', 'C_1O', 'C_1O1O', 'C_1S', 'C_1S1S', 'O_1C1C', 'O_1C1O', 'S_1C1C', 'S_1C1S']\n",
      "{'C_1C': 0, 'C_1C1C': 1, 'C_1C1C1C': 2, 'C_1C1C1C1C': 3, 'C_1C1C1C1O': 4, 'C_1C1C1C1S': 5, 'C_1C1C1O': 6, 'C_1C1C1O1O': 7, 'C_1C1C1S': 8, 'C_1C1C1S1S': 9, 'C_1C1O': 10, 'C_1C1O1O': 11, 'C_1C1S': 12, 'C_1C1S1S': 13, 'C_1O': 14, 'C_1O1O': 15, 'C_1S': 16, 'C_1S1S': 17, 'O_1C1C': 18, 'O_1C1O': 19, 'S_1C1C': 20, 'S_1C1S': 21} 22\n",
      "nb labels: 22  ; nb_edge_labels: 1\n",
      "torch.Size([164, 121])\n",
      "adjacency matrices tensor([[          0,           0,           1,  ...,       72769,\n",
      "                   0, -1579404256],\n",
      "        [          0,           0,           1,  ...,  1702051187,\n",
      "          1647208044,  1684826485],\n",
      "        [          0,           0,           1,  ...,   728524130,\n",
      "           724117810,   761606440],\n",
      "        ...,\n",
      "        [          0,           0,           1,  ...,           1,\n",
      "                   1,           0],\n",
      "        [          0,           0,           0,  ...,           0,\n",
      "                   0,           0],\n",
      "        [          0,           0,           1,  ...,           0,\n",
      "                   1,           0]], dtype=torch.int32)\n",
      "node labels tensor([[        14,         14,         19,  ...,  175399908, 1836020326,\n",
      "                  0],\n",
      "        [        16,         16,         20,  ..., 1147430258,  175399785,\n",
      "         1836020326],\n",
      "        [        16,         16,         21,  ..., 1918987381, 1936617283,\n",
      "         1767993972],\n",
      "        ...,\n",
      "        [         0,          0,          1,  ...,         12,         12,\n",
      "                 20],\n",
      "        [         0,          0,          0,  ...,          2,          2,\n",
      "                 20],\n",
      "        [         0,         16,          1,  ...,          1,         12,\n",
      "                 20]], dtype=torch.int32)\n",
      "order of the graphs tensor([ 4,  3,  4,  4,  5,  5,  4,  5,  5,  5,  5,  6,  6,  6,  6,  5,  5,  5,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  6,  6,  6,  6,  6,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,\n",
      "         8,  8,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9, 10, 10, 10, 10, 10,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11,\n",
      "        11, 11, 11, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11])\n",
      "Parameters:\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([232])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([])\n",
      "cpu\n",
      "0 23.241533866859452\n",
      "alpha= tensor(0.0100, grad_fn=<MulBackward0>)\n",
      "target= tensor([ 92.3000, 145.0000,  96.0000, 195.0000,  91.5000, 218.0000, 124.0000,\n",
      "        173.2000, 162.0000, 138.0000, 156.0000, 155.0000,  66.6000, 201.0000,\n",
      "        134.2000, 181.0000, 235.0000, 106.0000, 109.5000, 148.5000, 148.5000,\n",
      "        177.2000, 166.0000,  93.0000, 177.0000, 114.0000, 118.5000, 186.5000,\n",
      "        173.0000,  91.5000,  53.5000, 159.0000, 102.5000,  59.5000, 158.0000,\n",
      "         92.0000, 112.0000, 128.5000, 145.0000, 165.5000, 101.0000, 151.0000,\n",
      "        103.5000, 112.5000, 142.0000, 126.0000, 101.5000, 159.5000,  63.0000,\n",
      "         52.5000,  34.6000, 156.5000,  63.6000,  87.6000, 121.0000,  82.0000,\n",
      "        157.0000, 137.0000, 188.5000, 183.0000, 126.0000, 250.0000, 187.0000,\n",
      "        151.5000, 141.0000, 109.7000, 173.0000, 135.0000,  83.0000,  91.2000])\n",
      "y_pred= tensor([81.1290, 92.3792, 82.0793, 92.3781, 94.0778, 96.8195, 81.1294, 93.0682,\n",
      "        92.3781, 92.3778], grad_fn=<DivBackward0>)\n",
      "Loss Triangular: 0.0\n",
      "node_costs :\n",
      "tensor([[0.0000, 0.0038, 0.0036, 0.0040, 0.0039, 0.0048, 0.0041, 0.0052, 0.0044,\n",
      "         0.0043, 0.0050, 0.0046, 0.0039, 0.0040, 0.0048, 0.0044, 0.0039, 0.0042,\n",
      "         0.0047, 0.0052, 0.0040, 0.0046],\n",
      "        [0.0038, 0.0000, 0.0046, 0.0051, 0.0045, 0.0049, 0.0044, 0.0048, 0.0050,\n",
      "         0.0037, 0.0048, 0.0047, 0.0045, 0.0050, 0.0044, 0.0040, 0.0041, 0.0048,\n",
      "         0.0043, 0.0046, 0.0041, 0.0050],\n",
      "        [0.0036, 0.0046, 0.0000, 0.0045, 0.0049, 0.0039, 0.0051, 0.0048, 0.0038,\n",
      "         0.0036, 0.0039, 0.0037, 0.0037, 0.0039, 0.0046, 0.0048, 0.0038, 0.0039,\n",
      "         0.0039, 0.0050, 0.0040, 0.0035],\n",
      "        [0.0040, 0.0051, 0.0045, 0.0000, 0.0042, 0.0041, 0.0037, 0.0041, 0.0040,\n",
      "         0.0049, 0.0036, 0.0047, 0.0043, 0.0039, 0.0039, 0.0038, 0.0051, 0.0049,\n",
      "         0.0043, 0.0035, 0.0041, 0.0044],\n",
      "        [0.0039, 0.0045, 0.0049, 0.0042, 0.0000, 0.0049, 0.0044, 0.0038, 0.0048,\n",
      "         0.0046, 0.0040, 0.0047, 0.0043, 0.0036, 0.0038, 0.0036, 0.0051, 0.0042,\n",
      "         0.0048, 0.0047, 0.0047, 0.0050],\n",
      "        [0.0048, 0.0049, 0.0039, 0.0041, 0.0049, 0.0000, 0.0035, 0.0037, 0.0038,\n",
      "         0.0044, 0.0041, 0.0037, 0.0042, 0.0051, 0.0038, 0.0038, 0.0044, 0.0049,\n",
      "         0.0036, 0.0046, 0.0037, 0.0042],\n",
      "        [0.0041, 0.0044, 0.0051, 0.0037, 0.0044, 0.0035, 0.0000, 0.0046, 0.0036,\n",
      "         0.0051, 0.0042, 0.0043, 0.0043, 0.0039, 0.0045, 0.0039, 0.0044, 0.0046,\n",
      "         0.0048, 0.0052, 0.0048, 0.0036],\n",
      "        [0.0052, 0.0048, 0.0048, 0.0041, 0.0038, 0.0037, 0.0046, 0.0000, 0.0047,\n",
      "         0.0039, 0.0048, 0.0052, 0.0035, 0.0035, 0.0052, 0.0042, 0.0050, 0.0048,\n",
      "         0.0043, 0.0051, 0.0039, 0.0041],\n",
      "        [0.0044, 0.0050, 0.0038, 0.0040, 0.0048, 0.0038, 0.0036, 0.0047, 0.0000,\n",
      "         0.0045, 0.0040, 0.0042, 0.0047, 0.0049, 0.0044, 0.0043, 0.0048, 0.0035,\n",
      "         0.0045, 0.0045, 0.0042, 0.0035],\n",
      "        [0.0043, 0.0037, 0.0036, 0.0049, 0.0046, 0.0044, 0.0051, 0.0039, 0.0045,\n",
      "         0.0000, 0.0046, 0.0049, 0.0037, 0.0040, 0.0035, 0.0039, 0.0044, 0.0042,\n",
      "         0.0035, 0.0037, 0.0037, 0.0038],\n",
      "        [0.0050, 0.0048, 0.0039, 0.0036, 0.0040, 0.0041, 0.0042, 0.0048, 0.0040,\n",
      "         0.0046, 0.0000, 0.0037, 0.0042, 0.0052, 0.0038, 0.0036, 0.0051, 0.0034,\n",
      "         0.0051, 0.0051, 0.0036, 0.0037],\n",
      "        [0.0046, 0.0047, 0.0037, 0.0047, 0.0047, 0.0037, 0.0043, 0.0052, 0.0042,\n",
      "         0.0049, 0.0037, 0.0000, 0.0043, 0.0045, 0.0042, 0.0040, 0.0051, 0.0045,\n",
      "         0.0042, 0.0044, 0.0039, 0.0037],\n",
      "        [0.0039, 0.0045, 0.0037, 0.0043, 0.0043, 0.0042, 0.0043, 0.0035, 0.0047,\n",
      "         0.0037, 0.0042, 0.0043, 0.0000, 0.0035, 0.0038, 0.0041, 0.0044, 0.0035,\n",
      "         0.0036, 0.0038, 0.0051, 0.0048],\n",
      "        [0.0040, 0.0050, 0.0039, 0.0039, 0.0036, 0.0051, 0.0039, 0.0035, 0.0049,\n",
      "         0.0040, 0.0052, 0.0045, 0.0035, 0.0000, 0.0048, 0.0038, 0.0040, 0.0040,\n",
      "         0.0050, 0.0051, 0.0036, 0.0038],\n",
      "        [0.0048, 0.0044, 0.0046, 0.0039, 0.0038, 0.0038, 0.0045, 0.0052, 0.0044,\n",
      "         0.0035, 0.0038, 0.0042, 0.0038, 0.0048, 0.0000, 0.0052, 0.0036, 0.0044,\n",
      "         0.0041, 0.0046, 0.0037, 0.0038],\n",
      "        [0.0044, 0.0040, 0.0048, 0.0038, 0.0036, 0.0038, 0.0039, 0.0042, 0.0043,\n",
      "         0.0039, 0.0036, 0.0040, 0.0041, 0.0038, 0.0052, 0.0000, 0.0040, 0.0041,\n",
      "         0.0047, 0.0042, 0.0039, 0.0037],\n",
      "        [0.0039, 0.0041, 0.0038, 0.0051, 0.0051, 0.0044, 0.0044, 0.0050, 0.0048,\n",
      "         0.0044, 0.0051, 0.0051, 0.0044, 0.0040, 0.0036, 0.0040, 0.0000, 0.0047,\n",
      "         0.0043, 0.0041, 0.0052, 0.0040],\n",
      "        [0.0042, 0.0048, 0.0039, 0.0049, 0.0042, 0.0049, 0.0046, 0.0048, 0.0035,\n",
      "         0.0042, 0.0034, 0.0045, 0.0035, 0.0040, 0.0044, 0.0041, 0.0047, 0.0000,\n",
      "         0.0041, 0.0038, 0.0047, 0.0041],\n",
      "        [0.0047, 0.0043, 0.0039, 0.0043, 0.0048, 0.0036, 0.0048, 0.0043, 0.0045,\n",
      "         0.0035, 0.0051, 0.0042, 0.0036, 0.0050, 0.0041, 0.0047, 0.0043, 0.0041,\n",
      "         0.0000, 0.0048, 0.0050, 0.0038],\n",
      "        [0.0052, 0.0046, 0.0050, 0.0035, 0.0047, 0.0046, 0.0052, 0.0051, 0.0045,\n",
      "         0.0037, 0.0051, 0.0044, 0.0038, 0.0051, 0.0046, 0.0042, 0.0041, 0.0038,\n",
      "         0.0048, 0.0000, 0.0047, 0.0044],\n",
      "        [0.0040, 0.0041, 0.0040, 0.0041, 0.0047, 0.0037, 0.0048, 0.0039, 0.0042,\n",
      "         0.0037, 0.0036, 0.0039, 0.0051, 0.0036, 0.0037, 0.0039, 0.0052, 0.0047,\n",
      "         0.0050, 0.0047, 0.0000, 0.0052],\n",
      "        [0.0046, 0.0050, 0.0035, 0.0044, 0.0050, 0.0042, 0.0036, 0.0041, 0.0035,\n",
      "         0.0038, 0.0037, 0.0037, 0.0048, 0.0038, 0.0038, 0.0037, 0.0040, 0.0041,\n",
      "         0.0038, 0.0044, 0.0052, 0.0000]], grad_fn=<AddBackward0>)\n",
      "nodeInsDel: 0.004776287358254194\n",
      "edge_costs :\n",
      "tensor([])\n",
      "edgeInsDel: 0.004422774072736502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 22.499174247000155\n",
      "2 22.43566649019759\n",
      "3 22.56594502785115\n",
      "4 22.787809840872157\n",
      "5 21.473328978569555\n",
      "6 21.225880153276332\n",
      "7 21.215606357702814\n",
      "8 21.631631705314675\n",
      "9 21.89161199595064\n",
      "10 21.657699716988645\n",
      "11 21.657697462449697\n",
      "12 21.394866955212645\n",
      "13 21.63161251863231\n",
      "14 21.21557298564842\n",
      "15 21.2633471410459\n",
      "16 21.34365963560666\n",
      "17 21.209253213515087\n",
      "18 21.209253213515087\n",
      "19 21.209250911306366\n",
      "20 21.209253213515087\n",
      "alpha= tensor(0.0073, grad_fn=<MulBackward0>)\n",
      "target= tensor([ 92.3000, 145.0000,  96.0000, 195.0000,  91.5000, 218.0000, 124.0000,\n",
      "        173.2000, 162.0000, 138.0000, 156.0000, 155.0000,  66.6000, 201.0000,\n",
      "        134.2000, 181.0000, 235.0000, 106.0000, 109.5000, 148.5000, 148.5000,\n",
      "        177.2000, 166.0000,  93.0000, 177.0000, 114.0000, 118.5000, 186.5000,\n",
      "        173.0000,  91.5000,  53.5000, 159.0000, 102.5000,  59.5000, 158.0000,\n",
      "         92.0000, 112.0000, 128.5000, 145.0000, 165.5000, 101.0000, 151.0000,\n",
      "        103.5000, 112.5000, 142.0000, 126.0000, 101.5000, 159.5000,  63.0000,\n",
      "         52.5000,  34.6000, 156.5000,  63.6000,  87.6000, 121.0000,  82.0000,\n",
      "        157.0000, 137.0000, 188.5000, 183.0000, 126.0000, 250.0000, 187.0000,\n",
      "        151.5000, 141.0000, 109.7000, 173.0000, 135.0000,  83.0000,  91.2000])\n",
      "y_pred= tensor([104.3197,  92.3799, 105.4298, 114.6697, 114.6696,  75.5800, 104.3198,\n",
      "         75.5800, 114.6694, 114.6693], grad_fn=<DivBackward0>)\n",
      "Loss Triangular: 0.0\n",
      "node_costs :\n",
      "tensor([[0.0000, 0.0019, 0.0012, 0.0026, 0.0019, 0.0056, 0.0027, 0.0073, 0.0038,\n",
      "         0.0034, 0.0064, 0.0047, 0.0021, 0.0022, 0.0055, 0.0039, 0.0019, 0.0030,\n",
      "         0.0051, 0.0072, 0.0026, 0.0047],\n",
      "        [0.0019, 0.0000, 0.0049, 0.0066, 0.0043, 0.0061, 0.0041, 0.0056, 0.0065,\n",
      "         0.0012, 0.0055, 0.0050, 0.0043, 0.0065, 0.0041, 0.0025, 0.0026, 0.0056,\n",
      "         0.0035, 0.0048, 0.0028, 0.0062],\n",
      "        [0.0012, 0.0049, 0.0000, 0.0045, 0.0059, 0.0020, 0.0068, 0.0056, 0.0017,\n",
      "         0.0010, 0.0020, 0.0014, 0.0013, 0.0020, 0.0047, 0.0056, 0.0017, 0.0020,\n",
      "         0.0020, 0.0063, 0.0025, 0.0007],\n",
      "        [0.0026, 0.0066, 0.0045, 0.0000, 0.0030, 0.0027, 0.0015, 0.0027, 0.0024,\n",
      "         0.0059, 0.0012, 0.0053, 0.0037, 0.0021, 0.0020, 0.0017, 0.0070, 0.0060,\n",
      "         0.0034, 0.0008, 0.0029, 0.0041],\n",
      "        [0.0019, 0.0043, 0.0059, 0.0030, 0.0000, 0.0059, 0.0039, 0.0016, 0.0056,\n",
      "         0.0049, 0.0025, 0.0054, 0.0034, 0.0009, 0.0018, 0.0009, 0.0070, 0.0032,\n",
      "         0.0056, 0.0051, 0.0051, 0.0064],\n",
      "        [0.0056, 0.0061, 0.0020, 0.0027, 0.0059, 0.0000, 0.0007, 0.0012, 0.0017,\n",
      "         0.0041, 0.0027, 0.0015, 0.0031, 0.0069, 0.0017, 0.0016, 0.0039, 0.0061,\n",
      "         0.0012, 0.0048, 0.0012, 0.0030],\n",
      "        [0.0027, 0.0041, 0.0068, 0.0015, 0.0039, 0.0007, 0.0000, 0.0050, 0.0010,\n",
      "         0.0067, 0.0032, 0.0035, 0.0034, 0.0022, 0.0044, 0.0021, 0.0040, 0.0049,\n",
      "         0.0056, 0.0073, 0.0055, 0.0011],\n",
      "        [0.0073, 0.0056, 0.0056, 0.0027, 0.0016, 0.0012, 0.0050, 0.0000, 0.0052,\n",
      "         0.0021, 0.0056, 0.0072, 0.0009, 0.0007, 0.0072, 0.0030, 0.0065, 0.0057,\n",
      "         0.0036, 0.0068, 0.0019, 0.0028],\n",
      "        [0.0038, 0.0065, 0.0017, 0.0024, 0.0056, 0.0017, 0.0010, 0.0052, 0.0000,\n",
      "         0.0045, 0.0023, 0.0030, 0.0053, 0.0061, 0.0040, 0.0037, 0.0057, 0.0008,\n",
      "         0.0044, 0.0044, 0.0032, 0.0008],\n",
      "        [0.0034, 0.0012, 0.0010, 0.0059, 0.0049, 0.0041, 0.0067, 0.0021, 0.0045,\n",
      "         0.0000, 0.0050, 0.0061, 0.0013, 0.0023, 0.0008, 0.0019, 0.0039, 0.0030,\n",
      "         0.0009, 0.0015, 0.0013, 0.0017],\n",
      "        [0.0064, 0.0055, 0.0020, 0.0012, 0.0025, 0.0027, 0.0032, 0.0056, 0.0023,\n",
      "         0.0050, 0.0000, 0.0015, 0.0032, 0.0072, 0.0018, 0.0012, 0.0068, 0.0006,\n",
      "         0.0069, 0.0068, 0.0012, 0.0015],\n",
      "        [0.0047, 0.0050, 0.0014, 0.0053, 0.0054, 0.0015, 0.0035, 0.0072, 0.0030,\n",
      "         0.0061, 0.0015, 0.0000, 0.0035, 0.0046, 0.0032, 0.0025, 0.0067, 0.0044,\n",
      "         0.0031, 0.0039, 0.0022, 0.0013],\n",
      "        [0.0021, 0.0043, 0.0013, 0.0037, 0.0034, 0.0031, 0.0034, 0.0009, 0.0053,\n",
      "         0.0013, 0.0032, 0.0035, 0.0000, 0.0007, 0.0017, 0.0028, 0.0039, 0.0007,\n",
      "         0.0009, 0.0019, 0.0068, 0.0056],\n",
      "        [0.0022, 0.0065, 0.0020, 0.0021, 0.0009, 0.0069, 0.0022, 0.0007, 0.0061,\n",
      "         0.0023, 0.0072, 0.0046, 0.0007, 0.0000, 0.0054, 0.0016, 0.0024, 0.0023,\n",
      "         0.0063, 0.0068, 0.0012, 0.0016],\n",
      "        [0.0055, 0.0041, 0.0047, 0.0020, 0.0018, 0.0017, 0.0044, 0.0072, 0.0040,\n",
      "         0.0008, 0.0018, 0.0032, 0.0017, 0.0054, 0.0000, 0.0071, 0.0011, 0.0040,\n",
      "         0.0029, 0.0049, 0.0012, 0.0016],\n",
      "        [0.0039, 0.0025, 0.0056, 0.0017, 0.0009, 0.0016, 0.0021, 0.0030, 0.0037,\n",
      "         0.0019, 0.0012, 0.0025, 0.0028, 0.0016, 0.0071, 0.0000, 0.0026, 0.0029,\n",
      "         0.0050, 0.0032, 0.0020, 0.0015],\n",
      "        [0.0019, 0.0026, 0.0017, 0.0070, 0.0070, 0.0039, 0.0040, 0.0065, 0.0057,\n",
      "         0.0039, 0.0068, 0.0067, 0.0039, 0.0024, 0.0011, 0.0026, 0.0000, 0.0051,\n",
      "         0.0036, 0.0026, 0.0073, 0.0025],\n",
      "        [0.0030, 0.0056, 0.0020, 0.0060, 0.0032, 0.0061, 0.0049, 0.0057, 0.0008,\n",
      "         0.0030, 0.0006, 0.0044, 0.0007, 0.0023, 0.0040, 0.0029, 0.0051, 0.0000,\n",
      "         0.0028, 0.0017, 0.0051, 0.0028],\n",
      "        [0.0051, 0.0035, 0.0020, 0.0034, 0.0056, 0.0012, 0.0056, 0.0036, 0.0044,\n",
      "         0.0009, 0.0069, 0.0031, 0.0009, 0.0063, 0.0029, 0.0050, 0.0036, 0.0028,\n",
      "         0.0000, 0.0056, 0.0064, 0.0015],\n",
      "        [0.0072, 0.0048, 0.0063, 0.0008, 0.0051, 0.0048, 0.0073, 0.0068, 0.0044,\n",
      "         0.0015, 0.0068, 0.0039, 0.0019, 0.0068, 0.0049, 0.0032, 0.0026, 0.0017,\n",
      "         0.0056, 0.0000, 0.0053, 0.0039],\n",
      "        [0.0026, 0.0028, 0.0025, 0.0029, 0.0051, 0.0012, 0.0055, 0.0019, 0.0032,\n",
      "         0.0013, 0.0012, 0.0022, 0.0068, 0.0012, 0.0012, 0.0020, 0.0073, 0.0051,\n",
      "         0.0064, 0.0053, 0.0000, 0.0073],\n",
      "        [0.0047, 0.0062, 0.0007, 0.0041, 0.0064, 0.0030, 0.0011, 0.0028, 0.0008,\n",
      "         0.0017, 0.0015, 0.0013, 0.0056, 0.0016, 0.0016, 0.0015, 0.0025, 0.0028,\n",
      "         0.0015, 0.0039, 0.0073, 0.0000]], grad_fn=<AddBackward0>)\n",
      "nodeInsDel: 0.16362692415714264\n",
      "edge_costs :\n",
      "tensor([])\n",
      "edgeInsDel: 0.004504851996898651\n",
      "21 21.20925206241076\n",
      "22 21.209250911306366\n",
      "23 21.252185089861936\n",
      "24 21.252187387419678\n",
      "25 21.252182792303948\n",
      "26 21.25218164352486\n",
      "27 21.252182792303948\n",
      "28 20.871316806430183\n",
      "29 20.871310957717775\n",
      "30 20.871310957717775\n",
      "31 20.871310957717775\n",
      "32 20.871310957717775\n",
      "33 20.871310957717775\n",
      "34 20.553979285119585\n",
      "35 20.553978097317316\n",
      "36 20.592945024100487\n",
      "37 20.624372623033896\n",
      "38 20.541374025974992\n",
      "39 20.014024623763834\n",
      "40 20.31444101302999\n",
      "alpha= tensor(0.0063, grad_fn=<MulBackward0>)\n",
      "target= tensor([ 92.3000, 145.0000,  96.0000, 195.0000,  91.5000, 218.0000, 124.0000,\n",
      "        173.2000, 162.0000, 138.0000, 156.0000, 155.0000,  66.6000, 201.0000,\n",
      "        134.2000, 181.0000, 235.0000, 106.0000, 109.5000, 148.5000, 148.5000,\n",
      "        177.2000, 166.0000,  93.0000, 177.0000, 114.0000, 118.5000, 186.5000,\n",
      "        173.0000,  91.5000,  53.5000, 159.0000, 102.5000,  59.5000, 158.0000,\n",
      "         92.0000, 112.0000, 128.5000, 145.0000, 165.5000, 101.0000, 151.0000,\n",
      "        103.5000, 112.5000, 142.0000, 126.0000, 101.5000, 159.5000,  63.0000,\n",
      "         52.5000,  34.6000, 156.5000,  63.6000,  87.6000, 121.0000,  82.0000,\n",
      "        157.0000, 137.0000, 188.5000, 183.0000, 126.0000, 250.0000, 187.0000,\n",
      "        151.5000, 141.0000, 109.7000, 173.0000, 135.0000,  83.0000,  91.2000])\n",
      "y_pred= tensor([124.6300,  89.2000, 113.5700, 132.3800, 114.6700,  71.5800, 125.7100,\n",
      "         77.4799, 114.6700, 122.1400], grad_fn=<DivBackward0>)\n",
      "Loss Triangular: 0.0\n",
      "node_costs :\n",
      "tensor([[0.0000, 0.0008, 0.0004, 0.0013, 0.0008, 0.0044, 0.0014, 0.0064, 0.0024,\n",
      "         0.0020, 0.0054, 0.0033, 0.0009, 0.0010, 0.0042, 0.0025, 0.0008, 0.0017,\n",
      "         0.0038, 0.0064, 0.0013, 0.0034],\n",
      "        [0.0008, 0.0000, 0.0036, 0.0056, 0.0030, 0.0049, 0.0027, 0.0043, 0.0054,\n",
      "         0.0004, 0.0042, 0.0037, 0.0030, 0.0055, 0.0027, 0.0013, 0.0013, 0.0043,\n",
      "         0.0021, 0.0035, 0.0014, 0.0051],\n",
      "        [0.0004, 0.0036, 0.0000, 0.0031, 0.0047, 0.0009, 0.0059, 0.0043, 0.0006,\n",
      "         0.0003, 0.0008, 0.0005, 0.0004, 0.0009, 0.0033, 0.0043, 0.0006, 0.0008,\n",
      "         0.0009, 0.0053, 0.0013, 0.0001],\n",
      "        [0.0013, 0.0056, 0.0031, 0.0000, 0.0017, 0.0014, 0.0005, 0.0014, 0.0011,\n",
      "         0.0047, 0.0004, 0.0041, 0.0024, 0.0009, 0.0008, 0.0007, 0.0061, 0.0049,\n",
      "         0.0020, 0.0002, 0.0015, 0.0027],\n",
      "        [0.0008, 0.0030, 0.0047, 0.0017, 0.0000, 0.0047, 0.0025, 0.0006, 0.0044,\n",
      "         0.0036, 0.0013, 0.0041, 0.0021, 0.0002, 0.0008, 0.0002, 0.0061, 0.0018,\n",
      "         0.0044, 0.0038, 0.0037, 0.0053],\n",
      "        [0.0044, 0.0049, 0.0009, 0.0014, 0.0047, 0.0000, 0.0002, 0.0004, 0.0007,\n",
      "         0.0027, 0.0014, 0.0005, 0.0018, 0.0060, 0.0007, 0.0006, 0.0025, 0.0049,\n",
      "         0.0003, 0.0034, 0.0004, 0.0016],\n",
      "        [0.0014, 0.0027, 0.0059, 0.0005, 0.0025, 0.0002, 0.0000, 0.0036, 0.0003,\n",
      "         0.0057, 0.0018, 0.0021, 0.0020, 0.0010, 0.0030, 0.0010, 0.0026, 0.0035,\n",
      "         0.0043, 0.0065, 0.0043, 0.0003],\n",
      "        [0.0064, 0.0043, 0.0043, 0.0014, 0.0006, 0.0004, 0.0036, 0.0000, 0.0039,\n",
      "         0.0009, 0.0044, 0.0063, 0.0002, 0.0001, 0.0063, 0.0017, 0.0055, 0.0045,\n",
      "         0.0022, 0.0058, 0.0008, 0.0015],\n",
      "        [0.0024, 0.0054, 0.0006, 0.0011, 0.0044, 0.0007, 0.0003, 0.0039, 0.0000,\n",
      "         0.0032, 0.0011, 0.0017, 0.0040, 0.0049, 0.0026, 0.0023, 0.0044, 0.0002,\n",
      "         0.0030, 0.0031, 0.0019, 0.0002],\n",
      "        [0.0020, 0.0004, 0.0003, 0.0047, 0.0036, 0.0027, 0.0057, 0.0009, 0.0032,\n",
      "         0.0000, 0.0036, 0.0050, 0.0004, 0.0011, 0.0002, 0.0008, 0.0025, 0.0017,\n",
      "         0.0002, 0.0005, 0.0004, 0.0007],\n",
      "        [0.0054, 0.0042, 0.0008, 0.0004, 0.0013, 0.0014, 0.0018, 0.0044, 0.0011,\n",
      "         0.0036, 0.0000, 0.0005, 0.0019, 0.0063, 0.0007, 0.0004, 0.0058, 0.0001,\n",
      "         0.0060, 0.0058, 0.0004, 0.0005],\n",
      "        [0.0033, 0.0037, 0.0005, 0.0041, 0.0041, 0.0005, 0.0021, 0.0063, 0.0017,\n",
      "         0.0050, 0.0005, 0.0000, 0.0021, 0.0032, 0.0018, 0.0012, 0.0057, 0.0031,\n",
      "         0.0018, 0.0025, 0.0010, 0.0004],\n",
      "        [0.0009, 0.0030, 0.0004, 0.0024, 0.0021, 0.0018, 0.0020, 0.0002, 0.0040,\n",
      "         0.0004, 0.0019, 0.0021, 0.0000, 0.0002, 0.0006, 0.0015, 0.0025, 0.0002,\n",
      "         0.0002, 0.0008, 0.0058, 0.0044],\n",
      "        [0.0010, 0.0055, 0.0009, 0.0009, 0.0002, 0.0060, 0.0010, 0.0001, 0.0049,\n",
      "         0.0011, 0.0063, 0.0032, 0.0002, 0.0000, 0.0042, 0.0006, 0.0011, 0.0011,\n",
      "         0.0052, 0.0058, 0.0004, 0.0006],\n",
      "        [0.0042, 0.0027, 0.0033, 0.0008, 0.0008, 0.0007, 0.0030, 0.0063, 0.0026,\n",
      "         0.0002, 0.0007, 0.0018, 0.0006, 0.0042, 0.0000, 0.0062, 0.0003, 0.0026,\n",
      "         0.0015, 0.0035, 0.0004, 0.0006],\n",
      "        [0.0025, 0.0013, 0.0043, 0.0007, 0.0002, 0.0006, 0.0010, 0.0017, 0.0023,\n",
      "         0.0008, 0.0004, 0.0012, 0.0015, 0.0006, 0.0062, 0.0000, 0.0013, 0.0016,\n",
      "         0.0037, 0.0018, 0.0009, 0.0006],\n",
      "        [0.0008, 0.0013, 0.0006, 0.0061, 0.0061, 0.0025, 0.0026, 0.0055, 0.0044,\n",
      "         0.0025, 0.0058, 0.0057, 0.0025, 0.0011, 0.0003, 0.0013, 0.0000, 0.0038,\n",
      "         0.0022, 0.0014, 0.0065, 0.0012],\n",
      "        [0.0017, 0.0043, 0.0008, 0.0049, 0.0018, 0.0049, 0.0035, 0.0045, 0.0002,\n",
      "         0.0017, 0.0001, 0.0031, 0.0002, 0.0011, 0.0026, 0.0016, 0.0038, 0.0000,\n",
      "         0.0015, 0.0006, 0.0038, 0.0015],\n",
      "        [0.0038, 0.0021, 0.0009, 0.0020, 0.0044, 0.0003, 0.0043, 0.0022, 0.0030,\n",
      "         0.0002, 0.0060, 0.0018, 0.0002, 0.0052, 0.0015, 0.0037, 0.0022, 0.0015,\n",
      "         0.0000, 0.0044, 0.0054, 0.0006],\n",
      "        [0.0064, 0.0035, 0.0053, 0.0002, 0.0038, 0.0034, 0.0065, 0.0058, 0.0031,\n",
      "         0.0005, 0.0058, 0.0025, 0.0008, 0.0058, 0.0035, 0.0018, 0.0014, 0.0006,\n",
      "         0.0044, 0.0000, 0.0040, 0.0025],\n",
      "        [0.0013, 0.0014, 0.0013, 0.0015, 0.0037, 0.0004, 0.0043, 0.0008, 0.0019,\n",
      "         0.0004, 0.0004, 0.0010, 0.0058, 0.0004, 0.0004, 0.0009, 0.0065, 0.0038,\n",
      "         0.0054, 0.0040, 0.0000, 0.0065],\n",
      "        [0.0034, 0.0051, 0.0001, 0.0027, 0.0053, 0.0016, 0.0003, 0.0015, 0.0002,\n",
      "         0.0007, 0.0005, 0.0004, 0.0044, 0.0006, 0.0006, 0.0006, 0.0012, 0.0015,\n",
      "         0.0006, 0.0025, 0.0065, 0.0000]], grad_fn=<AddBackward0>)\n",
      "nodeInsDel: 0.4298136532306671\n",
      "edge_costs :\n",
      "tensor([])\n",
      "edgeInsDel: 0.0005690643447451293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 20.576455655524107\n",
      "42 20.61279586847997\n",
      "43 20.61279349965392\n",
      "44 20.70630400121241\n",
      "45 20.614796244900166\n",
      "46 21.599782080787296\n",
      "47 21.504845929173733\n",
      "48 21.53888085931753\n",
      "49 21.257252898275684\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from triangular_losses import TriangularConstraint as triangular_constraint\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "#  model = nn.DataParallel(model)\n",
    "#model.to(device)\n",
    "#regress.to(device)\n",
    "\n",
    "def regression(model,data,yt,nb_iter):\n",
    "\n",
    "    input=data.to(device)\n",
    "    target=yt.to(device) \n",
    "    \n",
    "    criterion = torch.nn.MSELoss()\n",
    "    criterionTri=triangular_constraint()\n",
    "    \n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    print(device)\n",
    "\n",
    "#torch.cat((same_class[0:20],diff_class[0:20]),0).to(device)\n",
    "    \n",
    "#torch.ones(40,device=device)\n",
    "#target[20:]=-1.0\n",
    "#target=(yt[0:20]).to(device)\n",
    "    InsDel=np.empty((nb_iter,2))\n",
    "    node_costs,nodeInsDel,edge_costs,edgeInsDel=model[0].from_weighs_to_costs()\n",
    "    nodeSub=np.empty((nb_iter,int(node_costs.shape[0]*(node_costs.shape[0]-1)/2)))\n",
    "    edgeSub=np.empty((nb_iter,int(edge_costs.shape[0]*(edge_costs.shape[0]-1)/2)))\n",
    "    loss_plt=np.empty(nb_iter)\n",
    "    #print('alpha=',regress.coef_dist*regress.coef_dist*10.0)\n",
    "    \n",
    "    \n",
    "    for t in range(nb_iter):    \n",
    "        # Forward pass: Compute predicted y by passing data to the model    \n",
    "        node_costs,nodeInsDel,edge_costs,edgeInsDel=model[0].from_weighs_to_costs()\n",
    "\n",
    "        y_pred = model(input).to(device)\n",
    "            \n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, target[-nb_test:]).to(device)                          \n",
    "        #loss = criterion(y_pred, target).to(device)                          \n",
    "        triangularInq=criterionTri(node_costs,nodeInsDel,edge_costs,edgeInsDel)\n",
    "        \n",
    "        loss=loss*(1+triangularInq)\n",
    "        loss.to(device)\n",
    "        InsDel[t][0]=nodeInsDel.item()\n",
    "        InsDel[t][1]=edgeInsDel.item()\n",
    "        rmse=np.sqrt(loss.item()/nb_test)\n",
    "        loss_plt[t]=rmse\n",
    "        print(t, rmse)   \n",
    "        k=0\n",
    "        for p in range(node_costs.shape[0]):\n",
    "            for q in range(p+1,node_costs.shape[0]):\n",
    "                nodeSub[t][k]=node_costs[p][q]\n",
    "                k=k+1\n",
    "        k=0\n",
    "        for p in range(edge_costs.shape[0]):\n",
    "            for q in range(p+1,edge_costs.shape[0]):\n",
    "                edgeSub[t][k]=edge_costs[p][q]\n",
    "                k=k+1\n",
    "        if t % 20 == 0 or t==0:                   \n",
    "            #print('Distances: ',y_pred)\n",
    "            print('alpha=',model[1].coef_dist*model[1].coef_dist)\n",
    "            #print('lambda=',model[1].regu*model[1].regu)\n",
    "            print('target=',target)\n",
    "            print('y_pred=',y_pred)\n",
    "            print('Loss Triangular:',triangularInq.item())\n",
    "            print('node_costs :')\n",
    "            print(node_costs)\n",
    "            print('nodeInsDel:',nodeInsDel.item())\n",
    "            print('edge_costs :')\n",
    "            print(edge_costs)\n",
    "            print('edgeInsDel:',edgeInsDel.item())\n",
    "        \n",
    "        \n",
    "            # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return InsDel,nodeSub,edgeSub,loss_plt\n",
    "\n",
    "\n",
    "\n",
    "model = nn.Sequential( OrderedDict([\n",
    "        ('ComputeDist',Net(Gs,normalize=True,node_label='extended_label')),('RegressFromDist',regress(yt.to(device),10,nb_test=nb_test,device=device,weights='distance'))\n",
    "#        ('RegressFromDist',RegressFromGED(yt.to(device),normalize='exp',nb_test=nb_test))\n",
    "        ])) \n",
    "print('Parameters:')\n",
    "for param in model.parameters():\n",
    "    print(type(param), param.size())\n",
    "    \n",
    "nb_iter=50  \n",
    "\n",
    "#with torch.autograd.profiler.profile(use_cuda=True) as prof:    \n",
    "InsDel, nodeSub,edgeSub,loss_plt=regression(model,data,yt,nb_iter)\n",
    "#print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n",
    "#print(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n",
    "plt.figure(0)\n",
    "plt.plot(InsDel[:,0],label=\"node\")\n",
    "plt.plot(InsDel[:,1],label=\"edge\")\n",
    "plt.title('Node/Edge insertion/deletion costs')\n",
    "plt.legend()\n",
    "plt.figure(1)\n",
    "for k in range(nodeSub.shape[1]):\n",
    "    plt.plot(nodeSub[:,k])\n",
    "plt.title('Node Substitutions costs')\n",
    "plt.figure(2)\n",
    "plt.plot(loss_plt[:])\n",
    "for k in range(edgeSub.shape[1]):\n",
    "    plt.plot(edgeSub[:,k])\n",
    "plt.title('Loss')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(loss_plt[0:160])\n",
    "#for k in range(edgeSub.shape[1]):\n",
    "#    plt.plot(edgeSub[0:500,k])\n",
    "#plt.title('Loss')\n",
    "#plt.show()\n",
    "#plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
