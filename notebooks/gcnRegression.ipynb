{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "from gklearn.utils.graphfiles import loadDataset\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge max label 1\n",
      "64.4 52.5\n"
     ]
    }
   ],
   "source": [
    "def label_to_color(label):\n",
    "    if label == 'C':\n",
    "        return 0.1\n",
    "    elif label == 'O':\n",
    "        return 0.8\n",
    "    \n",
    "def nodes_to_color_sequence(G):\n",
    "    return [label_to_color(c[1]['label'][0]) for c in G.nodes(data=True)]\n",
    "\n",
    "Gs,y = loadDataset('/home/luc/TRAVAIL/DeepGED/Acyclic/trainset_0.ds')\n",
    "    #'/data/chercheurs/brunl01/Acyclic/trainset_0.ds')\n",
    "#for e in Gs[13].edges():\n",
    "#    print(Gs[13][e[0]][e[1]]['bond_type'])\n",
    "print('edge max label',max(max([[G[e[0]][e[1]]['bond_type'] for e in G.edges()] for G in Gs])))\n",
    "G1 = Gs[13]\n",
    "G2 = Gs[23]\n",
    "print(y[13],y[23])\n",
    "nx.draw_networkx(G1,with_labels=True,node_color = nodes_to_color_sequence(G1),cmap='autumn')\n",
    "plt.figure()\n",
    "\n",
    "nx.draw_networkx(G2,with_labels=True,node_color = nodes_to_color_sequence(G2),cmap='autumn')\n",
    "\n",
    "\n",
    "#print(nx.to_dict_of_lists(Gs[13]))\n",
    "\n",
    "# A vérifier: L'ordre des sommets de numpy_matrix(G) est il le même que nx.nodes(G)\n",
    "def from_networkx_to_tensor(G,dict):\n",
    "    A=nx.to_numpy_matrix(G)\n",
    "    lab=[dict[G.nodes[v]['label'][0]] for v in nx.nodes(G)]\n",
    "    return (torch.tensor(A).view(1,A.shape[0]*A.shape[1]),torch.tensor(lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcn\n",
    "import svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import svd\n",
    "import gcn\n",
    "#from svd import iterated_power as compute_major_axis\n",
    "compute_major_axis=svd.CustomMajorAxis.apply\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "        \n",
    "    def __init__(self,GraphList,normalize=False,device=torch.device(\"cpu\")):\n",
    "        super(Net, self).__init__()   \n",
    "        self.normalize=normalize\n",
    "        self.total_nb_graphs=len(GraphList)\n",
    "        self.nb_feature=20\n",
    "        \n",
    "        dict,self.nb_edge_labels=self.build_node_dictionnary(GraphList)\n",
    "        self.nb_labels=len(dict)\n",
    "        print('nb_edge labels=',self.nb_edge_labels)\n",
    "        self.device=device\n",
    "        self.gcn=gcn.GCN2(self.nb_labels,self.nb_feature,dropout=0.1).to(self.device)               \n",
    "        nb_edge_pair_label=int(self.nb_edge_labels*(self.nb_edge_labels-1)/2)\n",
    "        \n",
    "        self.node_weighs=nn.Parameter(torch.tensor(1.0/(nb_edge_pair_label+2.0))+(1e-3)*torch.rand(2,requires_grad=True,device=self.device)) # all substitution costs+ nodeIns/Del. old version: 0 node subs, 1 nodeIns/Del, 2 : edgeSubs, 3 edgeIns/Del\n",
    "            \n",
    "        self.edge_weighs=nn.Parameter(torch.tensor(1.0/(nb_edge_pair_label+2.0))+(1e-3)*torch.rand(nb_edge_pair_label+1,requires_grad=True,device=self.device)) #edgeIns/Del\n",
    "        \n",
    "        self.card=torch.tensor([G.order() for G in GraphList]).to(self.device)\n",
    "        card_max=self.card.max()\n",
    "        self.A=torch.empty((len(GraphList),card_max*card_max),dtype=torch.float,device=self.device)\n",
    "        self.labels=torch.empty(self.total_nb_graphs,card_max,self.nb_labels,dtype=torch.float,device=self.device)\n",
    "        print(self.A.shape)\n",
    "        for k in range(len(GraphList)):\n",
    "            A,l=self.from_networkx_to_tensor(GraphList[k],dict,card_max)             \n",
    "            self.A[k,0:A.shape[1]]=A[0]\n",
    "            self.labels[k,:,:]=l\n",
    "        print('adjacency matrices',self.A)\n",
    "        print('node labels',self.labels)\n",
    "        print('order of the graphs',self.card)\n",
    "        print('nb_edge_pair_label,nb_edge_labels',nb_edge_pair_label,self.nb_edge_labels)\n",
    "        \n",
    "    def forward(self, input):        \n",
    "        ged=torch.zeros(len(input)).to(self.device) \n",
    "        node_subst,nodeInsDel,edge_costs,edgeInsDel=self.from_weighs_to_costs()\n",
    "        \n",
    "        f_computed= torch.zeros(self.total_nb_graphs).to(self.device)    \n",
    "        node_features=torch.zeros(self.total_nb_graphs,self.card.max(),self.nb_feature).to(self.device)    \n",
    "        #print('weighs:',self.weighs.device,'device:',self.device,'card:',self.card.device,'A:',self.A.device,'labels:',self.labels.device)\n",
    "        \n",
    "        for k in range(len(input)):            \n",
    "            g1=input[k][0]\n",
    "            g2=input[k][1]\n",
    "            \n",
    "            n=self.card[g1]\n",
    "            m=self.card[g2]\n",
    "            if not f_computed[g1]:\n",
    "                node_features[g1,0:n,:]=self.gcn(self.labels[g1][0:n,:],self.A[g1][0:n*n].view(n,n)+torch.eye(n,n,device=self.device))                \n",
    "                f_computed[g1]=1\n",
    "                #print('m1=',self.gcn(self.labels[g1][0:n,:],self.A[g1][0:n*n].view(n,n)+torch.eye(n,n,device=self.device)))\n",
    "            if not f_computed[g2]:\n",
    "                node_features[g2,0:m,:]=self.gcn(self.labels[g2][0:m,:],self.A[g2][0:m*m].view(m,m)+torch.eye(m,m,device=self.device))\n",
    "                f_computed[g2]=1\n",
    "                #print('m2=',self.gcn(self.labels[g2][0:m,:],self.A[g2][0:m*m].view(m,m)+torch.eye(m,m,device=self.device)))\n",
    "        \n",
    "        for k in range(len(input)):            \n",
    "            g1=input[k][0]\n",
    "            g2=input[k][1]\n",
    "            \n",
    "            n=self.card[g1]\n",
    "            m=self.card[g2]\n",
    "            m1=node_features[g1,0:n,:]\n",
    "            m2=node_features[g2,0:m,:]\n",
    "            C=self.construct_cost_matrix(g1,g2,m1,m2,node_subst,edge_costs,nodeInsDel,edgeInsDel)      \n",
    "            S=self.mapping_from_cost(C,n,m) # FW\n",
    "            #S=self.mapping_from_similarity(C,n,m) # SVD or iterated power.\n",
    "            #M=self.similarity_from_cost(C)\n",
    "            #S=self.mapping_from_similarity(M,n+1,m+1)\n",
    "            #S=torch.exp(S) # enforce the difference, accelerate the convergence. \n",
    "            #S=self.eps_assigment_from_mapping(S)\n",
    "            v=torch.flatten(S)\n",
    "            \n",
    "            normalize_factor=1.0\n",
    "            if self.normalize:\n",
    "                nb_edge1=(self.A[g1][0:n*n] != torch.zeros(n*n,device=self.device)).int().sum()\n",
    "                nb_edge2=(self.A[g2][0:m*m] != torch.zeros(m*m,device=self.device)).int().sum()\n",
    "                #normalize_factor=(nodeInsDel*n+edgeInsDel*nb_edge1)*(nodeInsDel*m+edgeInsDel*nb_edge2)                                    \n",
    "                normalize_factor=(nodeInsDel*(n+m)+edgeInsDel*(nb_edge1+nb_edge2))\n",
    "            ged[k]=.5*(v.t()@(C+torch.diag(C))@v)/normalize_factor    \n",
    "        return ged\n",
    "    \n",
    "    def from_weighs_to_costs(self):\n",
    "        \n",
    "        #cn=torch.exp(self.node_weighs)\n",
    "        #ce=torch.exp(self.edge_weighs)\n",
    "        cn=self.node_weighs*self.node_weighs\n",
    "        #cn=torch.where(x<1.0,x,torch.ones_like(x))\n",
    "        ce=self.edge_weighs*self.edge_weighs\n",
    "        #ce=torch.where(y<1.0,y,torch.ones_like(y))\n",
    "        total_cost=cn.sum()+ce.sum()\n",
    "        cn=cn/total_cost\n",
    "        ce=ce/total_cost\n",
    "        edgeInsDel=ce[-1]\n",
    "\n",
    "        #node_costs=torch.zeros((self.nb_labels,self.nb_labels),device=self.device)\n",
    "        #upper_part=torch.triu_indices(node_costs.shape[0],node_costs.shape[1],offset=1,device=self.device)        \n",
    "        #node_costs[upper_part[0],upper_part[1]]=cn[0:-1]\n",
    "        #node_costs=node_costs+node_costs.T\n",
    "\n",
    "        if self.nb_edge_labels>1:\n",
    "            edge_costs=torch.zeros((self.nb_edge_labels,self.nb_edge_labels),device=self.device)\n",
    "            upper_part=torch.triu_indices(edge_costs.shape[0],edge_costs.shape[1],offset=1,device=self.device)        \n",
    "            edge_costs[upper_part[0],upper_part[1]]=ce[0:-1]\n",
    "            edge_costs=edge_costs+edge_costs.T\n",
    "        else:\n",
    "            edge_costs=torch.zeros(0,device=self.device)\n",
    "        \n",
    "        return cn[0],cn[1],edge_costs,edgeInsDel\n",
    "    \n",
    "    def build_node_dictionnary(self,GraphList):\n",
    "        #extraction de tous les labels d'atomes\n",
    "        node_labels=[]\n",
    "        for G in Gs:\n",
    "            for v in nx.nodes(G):\n",
    "                if not G.nodes[v]['label'][0] in node_labels:\n",
    "                    node_labels.append(G.nodes[v]['label'][0])\n",
    "        node_labels.sort()\n",
    "        #extraction d'un dictionnaire permettant de numéroter chaque label par un numéro.\n",
    "        dict={}\n",
    "        k=0\n",
    "        for label in node_labels:\n",
    "            dict[label]=k\n",
    "            k=k+1\n",
    "        print(node_labels)\n",
    "        print(dict,len(dict))\n",
    "    \n",
    "        return dict,max(max([[int(G[e[0]][e[1]]['bond_type']) for e in G.edges()] for G in GraphList]))\n",
    "    \n",
    "    def from_networkx_to_tensor(self,G,dict,nb_max_vertices):    \n",
    "        A=torch.tensor(nx.to_scipy_sparse_matrix(G,dtype=float,weight='bond_type').todense(),dtype=torch.int)        \n",
    "        lab=torch.zeros(nb_max_vertices,self.nb_labels)\n",
    "        k=0\n",
    "        \n",
    "        for v in nx.nodes(G):\n",
    "            lab[k][dict[G.nodes[v]['label'][0]]]=1.0\n",
    "            k=k+1\n",
    "   \n",
    "        return (A.view(1,A.shape[0]*A.shape[1]),lab)\n",
    "\n",
    "    def construct_cost_matrix(self,g1,g2,m1,m2,node_subst,edge_costs,nodeInsDel,edgeInsDel):\n",
    "        n = self.card[g1].item()\n",
    "        m = self.card[g2].item()\n",
    "        \n",
    "        A1=torch.zeros((n+1,n+1),dtype=torch.int,device=self.device)\n",
    "        A1[0:n,0:n]=self.A[g1][0:n*n].view(n,n)\n",
    "        A2=torch.zeros((m+1,m+1),dtype=torch.int,device=self.device)\n",
    "        A2[0:m,0:m]=self.A[g2][0:m*m].view(m,m)\n",
    "        \n",
    "        \n",
    "         # costs: 0 node subs, 1 nodeIns/Del, 2 : edgeSubs, 3 edgeIns/Del\n",
    "        \n",
    "        #C=cost[3]*torch.cat([torch.cat([C12[l][k] for k in range(n+1)],1) for l in range(n+1)])\n",
    "        #Pas bien sur mais cela semble fonctionner.\n",
    "        C=edgeInsDel*self.matrix_edgeInsDel(A1,A2)\n",
    "        if self.nb_edge_labels>1:\n",
    "            for k in range(self.nb_edge_labels):\n",
    "                for l in range(self.nb_edge_labels):\n",
    "                    if k != l:\n",
    "#                    C.add_(self.matrix_edgeSubst(A1,A2,k+1,l+1),alpha=edge_costs[k][l])\n",
    "                        C=C+edge_costs[k][l]*self.matrix_edgeSubst(A1,A2,k+1,l+1)\n",
    "        #C=cost[3]*torch.tensor(np.array([ [  k!=l and A1[k//(m+1),l//(m+1)]^A2[k%(m+1),l%(m+1)] for k in range((n+1)*(m+1))] for l in range((n+1)*(m+1))]),device=self.device)        \n",
    "\n",
    "        #l1=self.labels[g1][0:n,:]\n",
    "        #l2=self.labels[g2][0:m,:]        \n",
    "        D=torch.zeros((n+1)*(m+1),device=self.device)\n",
    "        D[n*(m+1):]=nodeInsDel\n",
    "        D[n*(m+1)+m]=0\n",
    "        norm_l1=torch.einsum('i,j->ij',torch.diag(m1@m1.T),torch.ones(m,device=self.device))\n",
    "        norm_l2=torch.einsum('i,j->ij',torch.diag(m2@m2.T),torch.ones(n,device=self.device)).T\n",
    "        scalar=m1@m2.T\n",
    "        \n",
    "        d=torch.empty(n,m+1,device=self.device)\n",
    "        x=(norm_l1+norm_l2-2*scalar)/m1.shape[1]\n",
    "        eps=10**(-6)\n",
    "        d[:,0:m]=node_subst*torch.sqrt(torch.where(x>eps,x,eps*torch.ones(n,m,device=self.device)))       \n",
    "        d[:,-1]=nodeInsDel\n",
    "       # print('d=',d)\n",
    "        D[0:n*(m+1)]=d.view(1,d.shape[0]*d.shape[1])\n",
    "        #D[[i*(m+1)+m for i in range(n)]]=nodeInsDel\n",
    "        #pdist = nn.PairwiseDistance(p=2)\n",
    "        #D[[k for k in range(n*(m+1)) if k%(m+1) != m]]=torch.tensor([pdist(l1[k//(m+1),:],l2[k%(m+1),:]) for k in range(n*(m+1)) if k%(m+1) != m],device=self.device )\n",
    "        mask = torch.diag(torch.ones_like(D))\n",
    "        C=mask*torch.diag(D) + (1. - mask)*C\n",
    "        \n",
    "        #C[range(len(C)),range(len(C))]=D\n",
    "      \n",
    "        return C\n",
    "    def matrix_edgeInsDel(self,A1,A2):\n",
    "        Abin1=(A1!=torch.zeros((A1.shape[0],A1.shape[1]),device=self.device))\n",
    "        Abin2=(A2!=torch.zeros((A2.shape[0],A2.shape[1]),device=self.device))\n",
    "        C1=torch.einsum('ij,kl->ijkl',torch.logical_not(Abin1),Abin2)\n",
    "        C2=torch.einsum('ij,kl->ijkl',Abin1,torch.logical_not(Abin2))\n",
    "        C12=torch.logical_or(C1,C2).int()\n",
    "    \n",
    "        return torch.cat(torch.unbind(torch.cat(torch.unbind(C12,1),1),0),1)\n",
    "\n",
    "    def matrix_edgeSubst(self,A1,A2,lab1,lab2):\n",
    "        Abin1=(A1==lab1*torch.ones((A1.shape[0],A1.shape[1]),device=self.device)).int()\n",
    "        Abin2=(A2==lab2*torch.ones((A2.shape[0],A2.shape[1]),device=self.device)).int()\n",
    "        C=torch.einsum('ij,kl->ijkl',Abin1,Abin2)\n",
    "        \n",
    "        return torch.cat(torch.unbind(torch.cat(torch.unbind(C,1),1),0),1)\n",
    "    \n",
    "    def mapping_from_cost(self,C,n,m):\n",
    "        c=torch.diag(C)\n",
    "        D=C-torch.eye(C.shape[0],device=self.device)*c\n",
    "        x0=svd.eps_assigment_from_mapping(torch.exp(-c.view(n+1,m+1)),10).view((n+1)*(m+1),1)\n",
    "    \n",
    "        return svd.franck_wolfe(x0,D,c,2.0,10,n,m)\n",
    "    \n",
    "    def similarity_from_cost(self,C):\n",
    "        N=C.shape[0]\n",
    "        \n",
    "     \n",
    "        return (C.max()*torch.eye(N,device=self.device) -C)\n",
    "    \n",
    "    def mapping_from_similarity(self,C,n,m):\n",
    "        M=self.similarity_from_cost(C)\n",
    "        first_ev=compute_major_axis(M)\n",
    "        #first_ev=self.iterated_power(M,inv=True)\n",
    "        if(first_ev.sum() <0):\n",
    "            first_ev=-first_ev\n",
    "        S=torch.exp(first_ev.view(n+1,m+1)) # enforce the difference, accelerate the convergence. \n",
    "        S=self.eps_assigment_from_mapping(S)\n",
    "        return  S\n",
    "        \n",
    "    def eps_assigment_from_mapping(self,S):\n",
    "        ones_n = torch.ones(S.shape[0],device=S.device)\n",
    "        ones_m = torch.ones(S.shape[1],device=S.device)\n",
    "    \n",
    "        Sk = S\n",
    "        for i in range(20):\n",
    "            D=torch.diag(1.0/(Sk@ones_m))\n",
    "            D[D.shape[0]-1,D.shape[1]-1]=1.0\n",
    "            Sk1 = D@Sk\n",
    "            D=torch.diag(1.0/(ones_n@Sk1))\n",
    "            D[D.shape[0]-1,D.shape[1]-1]=1.0\n",
    "            Sk = Sk1@D\n",
    "        \n",
    "        return Sk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train graphs: tensor([ 42,  57, 121, 141,  59,  92, 143,  68, 142, 129,  65,   1,  35,  17,\n",
      "        152, 158, 111,  24, 154,   3,  89,   7,  18, 138, 132,  23,  28,  71,\n",
      "         30, 120, 148,  14,  33, 124,  15,  67,  19, 125,  63,  12, 100,  80,\n",
      "         49, 110, 151,  82, 131, 115,  21, 102, 156,  29, 106,   9,  53, 127,\n",
      "         87,  66,   6,  16,  13,  36,  47,  41,  81,  83,  69,  56, 144, 126])\n",
      "data= tensor([[ 13,  42],\n",
      "        [ 13,  57],\n",
      "        [ 13, 121],\n",
      "        ...,\n",
      "        [126,  66],\n",
      "        [126,   6],\n",
      "        [126,  16]], dtype=torch.int32) 600\n",
      "yt= tensor([ 82.0000, 144.2000, 148.5000, 126.0000, 132.0000, 171.0000, 163.0000,\n",
      "        181.0000, 164.0000, 151.5000, 137.0000,  37.3000, 101.5000,  84.4000,\n",
      "        156.5000, 174.0000, 151.0000,  59.0000, 173.2000,  10.8000, 157.5000,\n",
      "        135.0000, 156.0000, 159.5000, 139.0000,  52.5000, 104.5000, 186.0000,\n",
      "         92.0000, 178.0000, 218.0000,  84.7000, 112.5000, 167.0000,  95.5000,\n",
      "        177.2000, 166.0000, 195.0000, 120.4000,  53.5000, 229.5000,  87.6000,\n",
      "        103.0000, 114.5000, 186.5000,  99.3000, 157.0000, 147.0000,  70.3000,\n",
      "        125.0000, 173.0000, 102.0000, 122.0000,  34.6000, 104.0000, 201.0000,\n",
      "        124.0000, 195.8000,  66.6000,  92.0000,  64.4000, 165.5000,  86.3000,\n",
      "         80.2000, 101.0000,  90.0000, 185.9000, 145.0000, 146.0000, 215.0000])\n"
     ]
    }
   ],
   "source": [
    "from regression import KnnRegressFromGED as regress\n",
    "from regression import train_set_for_knnregression as create_dataset\n",
    "\n",
    "nb=len(Gs)\n",
    "#class1=torch.tensor([k for k in range(len(y)) if y[k]==1])\n",
    "#class2=torch.tensor([k for k in range(len(y)) if y[k]==0])\n",
    "\n",
    "train_size=70\n",
    "nb_test=10\n",
    "train_graphs=torch.randperm(nb)[0:train_size]\n",
    "print('train graphs:', train_graphs)\n",
    "\n",
    "\n",
    "\n",
    "#couples=[]\n",
    "#for k in range(nb_elt):\n",
    "#    if (y[data[k][0]]!=y[data[k][1]]):\n",
    "#        yt[k]=-1.0        \n",
    "#data,yt=train_set_for_kernel_ridge(train_graphs,y,train_size)\n",
    "data,yt=create_dataset(train_graphs,y,train_size,nb_test)\n",
    "print('data=',data,data.shape[0])\n",
    "print('yt=',yt)\n",
    "#print(couples[1:2])\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")          # a CUDA device object    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'O', 'S']\n",
      "{'C': 0, 'O': 1, 'S': 2} 3\n",
      "nb_edge labels= 1\n",
      "torch.Size([164, 121])\n",
      "adjacency matrices tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 1., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 1., 0.]], device='cuda:0')\n",
      "node labels tensor([[[1., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 0., 1.],\n",
      "         ...,\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 0., 1.],\n",
      "         ...,\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 0., 1.]]], device='cuda:0')\n",
      "order of the graphs tensor([ 4,  3,  4,  4,  5,  5,  4,  5,  5,  5,  5,  6,  6,  6,  6,  5,  5,  5,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  6,  6,  6,  6,  6,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,\n",
      "         8,  8,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9, 10, 10, 10, 10, 10,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11,\n",
      "        11, 11, 11, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11], device='cuda:0')\n",
      "nb_edge_pair_label,nb_edge_labels 0 1\n",
      "Parameters:\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2])\n",
      "Parameter containing:\n",
      "tensor([0.5004, 0.5005], device='cuda:0', requires_grad=True)\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1])\n",
      "Parameter containing:\n",
      "tensor([0.5005], device='cuda:0', requires_grad=True)\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3, 10])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0411,  0.2338, -0.1566, -0.1711,  0.2766,  0.1786,  0.1009,  0.0425,\n",
      "          0.0910, -0.0283],\n",
      "        [-0.1689, -0.0256,  0.2558, -0.0994,  0.2743, -0.2892, -0.2811, -0.2849,\n",
      "          0.1323, -0.0803],\n",
      "        [-0.2164,  0.2390, -0.0867, -0.2040, -0.2581, -0.0236, -0.1800,  0.1593,\n",
      "         -0.2144, -0.2353]], device='cuda:0', requires_grad=True)\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n",
      "Parameter containing:\n",
      "tensor([ 0.2236,  0.2933,  0.1657,  0.0071,  0.1429,  0.0802,  0.1600,  0.2747,\n",
      "         0.1670, -0.2602], device='cuda:0', requires_grad=True)\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 20])\n",
      "Parameter containing:\n",
      "tensor([[ 0.2080, -0.1014, -0.1262, -0.0774,  0.0775, -0.0243, -0.0365,  0.1680,\n",
      "         -0.2190,  0.0683, -0.1402, -0.1465,  0.0109, -0.0008, -0.2040, -0.0830,\n",
      "         -0.0357, -0.0612, -0.0597,  0.0836],\n",
      "        [-0.1584, -0.1986,  0.0811,  0.0220, -0.0646,  0.1161, -0.1376, -0.0268,\n",
      "         -0.0445, -0.2225, -0.0839,  0.1622,  0.1537, -0.0372, -0.1132, -0.1288,\n",
      "         -0.2061,  0.0582,  0.0145, -0.0487],\n",
      "        [-0.1593, -0.0407, -0.1329, -0.1324, -0.0079, -0.1202,  0.0029,  0.1049,\n",
      "         -0.0423,  0.1914,  0.0454, -0.0590,  0.2191,  0.1518, -0.2097,  0.2081,\n",
      "          0.0520,  0.1221, -0.0968, -0.0394],\n",
      "        [-0.1704, -0.1750, -0.1983,  0.1686,  0.1720, -0.2166,  0.2187, -0.1950,\n",
      "         -0.0591, -0.2164, -0.1927, -0.1612, -0.0669,  0.0707,  0.1744,  0.1327,\n",
      "         -0.0962,  0.2158, -0.1891, -0.1027],\n",
      "        [ 0.1558,  0.1082, -0.1466, -0.1110,  0.0152,  0.1767, -0.1736, -0.1775,\n",
      "         -0.1414,  0.0727,  0.1347,  0.0756, -0.1871,  0.1702, -0.0108, -0.1240,\n",
      "         -0.0769, -0.1275,  0.1669,  0.1496],\n",
      "        [-0.1451, -0.0611,  0.2218,  0.0231,  0.1676, -0.0326, -0.1172,  0.2080,\n",
      "         -0.0706,  0.1375, -0.1311, -0.0962,  0.1382,  0.0713,  0.0856, -0.1910,\n",
      "         -0.1926,  0.1376,  0.1110,  0.0253],\n",
      "        [-0.1206,  0.1501,  0.2127, -0.0071, -0.1715, -0.1020, -0.0206,  0.0297,\n",
      "         -0.1215, -0.1910,  0.0937, -0.1326,  0.0402,  0.1738, -0.1282, -0.0578,\n",
      "          0.1736, -0.1841,  0.0635, -0.1407],\n",
      "        [ 0.0120,  0.0615,  0.0853,  0.0765, -0.1454,  0.1800, -0.1308,  0.2195,\n",
      "         -0.0861,  0.1659,  0.1279,  0.0140, -0.0120,  0.2092, -0.1234,  0.0567,\n",
      "         -0.1868, -0.1340,  0.1568, -0.1083],\n",
      "        [ 0.1405,  0.0522,  0.1976, -0.0898, -0.1234,  0.0951, -0.1490, -0.1990,\n",
      "         -0.1697, -0.0658,  0.0435,  0.1508, -0.1159, -0.1191, -0.1211, -0.1588,\n",
      "         -0.1189, -0.1110, -0.1824, -0.1271],\n",
      "        [-0.2141,  0.0021, -0.1263, -0.1308,  0.1149, -0.1103, -0.0162,  0.1913,\n",
      "         -0.0419,  0.0584, -0.0009,  0.2205,  0.0842, -0.0765, -0.1782, -0.1960,\n",
      "          0.1100,  0.1534, -0.0156, -0.0274]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([20])\n",
      "Parameter containing:\n",
      "tensor([-0.1432,  0.0507, -0.2151, -0.2197,  0.1238, -0.1524, -0.2067, -0.1811,\n",
      "         0.0652,  0.0366,  0.0940,  0.0898,  0.0226, -0.0697, -0.0698,  0.1139,\n",
      "         0.0932, -0.1913,  0.0485, -0.1524], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([])\n",
      "Parameter containing:\n",
      "tensor(0.1000, device='cuda:0', requires_grad=True)\n",
      "cuda:0\n",
      "alpha= tensor(0.0100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "target= tensor([ 64.4000, 165.5000,  86.3000,  80.2000, 101.0000,  90.0000, 185.9000,\n",
      "        145.0000, 146.0000, 215.0000], device='cuda:0')\n",
      "y_pred= tensor([ 68.9218, 103.1379,  82.9837,  82.9093,  87.1899,  89.2278, 101.3300,\n",
      "         90.0816,  86.5977, 107.5831], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "node subst. cost : 0.33322766423225403\n",
      "nodeInsDel: 0.33339518308639526\n",
      "edgeInsDel: 0.33337709307670593\n",
      "0 17.13308930179953\n",
      "1 17.650877916152997\n",
      "2 14.910151644779221\n",
      "3 12.373023536136236\n",
      "4 14.04142865772568\n",
      "5 14.06802799332919\n",
      "6 14.482589055213419\n",
      "7 12.991365822633894\n",
      "8 14.844671846375133\n",
      "9 13.937771070093802\n",
      "10 13.112202186948089\n",
      "11 13.108101565831577\n",
      "12 12.192405362977244\n",
      "13 15.855636874724553\n",
      "14 13.651173166017408\n",
      "15 12.538075311607091\n",
      "16 12.315077458647997\n",
      "17 15.177864741952341\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3296fb62737c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m#with torch.autograd.profiler.profile(use_cuda=True) as prof:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mInsDel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodeSub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medgeSub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_plt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-3296fb62737c>\u001b[0m in \u001b[0;36mregression\u001b[0;34m(model, data, yt, nb_iter)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mnode_subst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnodeInsDel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_costs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medgeInsDel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_weighs_to_costs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Compute and print loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-70e1709c9b9d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mm2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_cost_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_subst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_costs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnodeInsDel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medgeInsDel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping_from_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# FW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;31m#S=self.mapping_from_similarity(C,n,m) # SVD or iterated power.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;31m#M=self.similarity_from_cost(C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-70e1709c9b9d>\u001b[0m in \u001b[0;36mmapping_from_cost\u001b[0;34m(self, C, n, m)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps_assigment_from_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfranck_wolfe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msimilarity_from_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TRAVAIL/DeepGED/deepged/svd.py\u001b[0m in \u001b[0;36mfranck_wolfe\u001b[0;34m(x0, D, c, offset, kmax, n, m)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;31m#        Cp=Cp-ones_n@minC.view(1,m+1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mnb_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_iter\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps_assigment_from_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mCp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TRAVAIL/DeepGED/deepged/svd.py\u001b[0m in \u001b[0;36meps_assigment_from_mapping\u001b[0;34m(S, nb_iter)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mSk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSk\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mones_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mSk1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mSk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.9/traceback.py\u001b[0m in \u001b[0;36mformat_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mformat_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.9/traceback.py\u001b[0m in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.9/traceback.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.9/traceback.py\u001b[0m in \u001b[0;36mline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from triangular_losses import ReducedTriangularConstraint as triangular_constraint\n",
    "\n",
    "def regression(model,data,yt,nb_iter):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    input=data.to(device)\n",
    "    target=yt.to(device) \n",
    "    \n",
    "    criterion = torch.nn.MSELoss()\n",
    "    criterionTri=triangular_constraint()\n",
    "    \n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "    print(device)\n",
    "\n",
    "#torch.cat((same_class[0:20],diff_class[0:20]),0).to(device)\n",
    "    \n",
    "#torch.ones(40,device=device)\n",
    "#target[20:]=-1.0\n",
    "#target=(yt[0:20]).to(device)\n",
    "    InsDel=np.empty((nb_iter,2))\n",
    "    nodeSub=np.empty(nb_iter)\n",
    "    node_subst,nodeInsDel,edge_costs,edgeInsDel=model[0].from_weighs_to_costs()\n",
    "    edgeSub=np.empty((nb_iter,int(edge_costs.shape[0]*(edge_costs.shape[0]-1)/2)))\n",
    "    loss_plt=np.empty(nb_iter)\n",
    "    #print('alpha=',regress.coef_dist*regress.coef_dist*10.0)\n",
    "    \n",
    "    \n",
    "    for t in range(nb_iter):  \n",
    "        \n",
    "        # Forward pass: Compute predicted y by passing data to the model    \n",
    "        node_subst,nodeInsDel,edge_costs,edgeInsDel=model[0].from_weighs_to_costs()\n",
    "\n",
    "        y_pred = model(input).to(device)\n",
    "            \n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, target[-nb_test:]).to(device)                                                           \n",
    "        triangularInq=criterionTri(node_subst,nodeInsDel,edge_costs,edgeInsDel)        \n",
    "        loss=loss*(1+triangularInq)\n",
    "        loss.to(device)\n",
    "        \n",
    "        InsDel[t][0]=nodeInsDel.item()\n",
    "        InsDel[t][1]=edgeInsDel.item()\n",
    "        rmse=np.sqrt(loss.item()/nb_test)\n",
    "        loss_plt[t]=rmse\n",
    "        nodeSub[t]=node_subst.item()\n",
    "        if edge_costs.shape[0] > 0:\n",
    "            k=0\n",
    "            for p in range(edge_costs.shape[0]):\n",
    "                for q in range(p+1,edge_costs.shape[0]):\n",
    "                    edgeSub[t][k]=edge_costs[p][q]\n",
    "                    k=k+1\n",
    "        if t % 20 == 0 or t==0:\n",
    "                            \n",
    "            #print('Distances: ',y_pred)\n",
    "            print('alpha=',model[1].coef_dist*model[1].coef_dist)\n",
    "            #print('lambda=',model[1].regu*model[1].regu)\n",
    "            print('target=',target[-nb_test:])\n",
    "            print('y_pred=',y_pred)\n",
    "            #print('Loss Triangular:',triangularInq.item())\n",
    "            print('node subst. cost :',node_subst.item())            \n",
    "            print('nodeInsDel:',nodeInsDel.item())\n",
    "            if edge_costs.shape[0]>0:\n",
    "                print('edge_costs :')\n",
    "                print(edge_costs)\n",
    "            print('edgeInsDel:',edgeInsDel.item())\n",
    "        \n",
    "        \n",
    "            # Zero gradients, perform a backward pass, and update the weights.\n",
    "        print(t, rmse)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    return InsDel,nodeSub,edgeSub,loss_plt\n",
    "\n",
    "nb_test=10\n",
    "model = nn.Sequential( OrderedDict([\n",
    "        ('ComputeDist',Net(Gs,normalize=True,device=device)),\n",
    "        ('RegressFromDist',regress(yt.to(device),10,nb_test=nb_test,device=device,weights='distance'))\n",
    "        ])) \n",
    "print('Parameters:')\n",
    "for param in model.parameters():\n",
    "    print(type(param), param.size())\n",
    "    print(param)\n",
    "    \n",
    "#with torch.autograd.profiler.profile(use_cuda=True) as prof:    \n",
    "InsDel, nodeSub,edgeSub,loss_plt=regression(model,data,yt,200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(0)\n",
    "plt.plot(InsDel[0:500,0],label=\"node\")\n",
    "plt.plot(InsDel[0:500,1],label=\"edge\")\n",
    "plt.title('Node/Edge insertion/deletion costs')\n",
    "plt.legend()\n",
    "plt.figure(1)\n",
    "for k in range(nodeSub.shape[1]):\n",
    "    plt.plot(nodeSub[0:500,k])\n",
    "plt.title('Node Substitutions costs')\n",
    "plt.figure(2)\n",
    "plt.plot(loss_plt[0:500])\n",
    "for k in range(edgeSub.shape[1]):\n",
    "    plt.plot(edgeSub[0:500,k])\n",
    "plt.title('Loss')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
