{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gklearn.utils.graphfiles import loadDataset\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge max label 1\n",
      "64.4 52.5\n",
      "{'atom': 'C', 'label': ['C'], 'attributes': ['0.0000', '0.0000', '0.0000'], 'extended_label': ['C_1C']}\n",
      "{'atom': 'C', 'label': ['C'], 'attributes': ['0.0000', '0.0000', '0.0000'], 'extended_label': ['C_1C']}\n",
      "{'atom': 'C', 'label': ['C'], 'attributes': ['0.0000', '0.0000', '0.0000'], 'extended_label': ['C_1O']}\n",
      "{'atom': 'C', 'label': ['C'], 'attributes': ['0.0000', '0.0000', '0.0000'], 'extended_label': ['C_1C1C1O']}\n",
      "{'atom': 'O', 'label': ['O'], 'attributes': ['0.0000', '0.0000', '0.0000'], 'extended_label': ['O_1C1C']}\n"
     ]
    }
   ],
   "source": [
    "def label_to_color(label):\n",
    "    if label == 'C':\n",
    "        return 0.1\n",
    "    elif label == 'O':\n",
    "        return 0.8\n",
    "    \n",
    "def nodes_to_color_sequence(G):\n",
    "    return [label_to_color(c[1]['label'][0]) for c in G.nodes(data=True)]\n",
    "\n",
    "Gs,y = loadDataset('/home/luc/TRAVAIL/DeepGED/Acyclic/trainset_0.ds')\n",
    "#for e in Gs[13].edges():\n",
    "#    print(Gs[13][e[0]][e[1]]['bond_type'])\n",
    "print('edge max label',max(max([[G[e[0]][e[1]]['bond_type'] for e in G.edges()] for G in Gs])))\n",
    "G1 = Gs[1]\n",
    "G2 = Gs[9]\n",
    "print(y[13],y[23])\n",
    "#nx.draw_networkx(G1,with_labels=True,node_color = nodes_to_color_sequence(G1),cmap='autumn')\n",
    "#plt.figure()\n",
    "\n",
    "#nx.draw_networkx(G2,with_labels=True,node_color = nodes_to_color_sequence(G2),cmap='autumn')\n",
    "\n",
    "import extended_label\n",
    "for g in Gs:\n",
    "    extended_label.compute_extended_labels(g)\n",
    "for v in Gs[10].nodes():\n",
    "        print(Gs[10].nodes[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import franck_wolfe\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "        \n",
    "    def __init__(self,GraphList,normalize=False,node_label='label'):\n",
    "        super(Net, self).__init__()   \n",
    "        self.normalize=normalize\n",
    "        self.node_label=node_label\n",
    "        dict,self.nb_edge_labels=self.build_node_dictionnary(GraphList)\n",
    "        self.nb_labels=len(dict)\n",
    "        print('nb labels:',self.nb_labels,' ; nb_edge_labels:',self.nb_edge_labels)\n",
    "        self.device=torch.device(\"cuda:0\")\n",
    "        nb_node_pair_label=self.nb_labels*(self.nb_labels-1)/2.0\n",
    "        nb_edge_pair_label=int(self.nb_edge_labels*(self.nb_edge_labels-1)/2)\n",
    "        self.node_weighs=nn.Parameter(torch.tensor(1.0/(nb_node_pair_label+nb_edge_pair_label+2))+(1e-3)*torch.rand(int(nb_node_pair_label+1),requires_grad=True,device=self.device)) # all substitution costs+ nodeIns/Del. old version: 0 node subs, 1 nodeIns/Del, 2 : edgeSubs, 3 edgeIns/Del        \n",
    "        self.edge_weighs=nn.Parameter(torch.tensor(1.0/(nb_node_pair_label+nb_edge_pair_label+2))+(1e-3)*torch.rand(nb_edge_pair_label+1,requires_grad=True,device=self.device)) #edgeIns/Del\n",
    "        #self.coef_dist=nn.Parameter(torch.tensor(1.0,requires_grad=True,device=self.device))\n",
    "        self.card=torch.tensor([G.order() for G in GraphList]).to(self.device)\n",
    "        card_max=self.card.max()\n",
    "        self.A=torch.empty((len(GraphList),card_max*card_max),dtype=torch.int,device=self.device)\n",
    "        self.labels=torch.empty((len(GraphList),card_max),dtype=torch.int,device=self.device)\n",
    "        print(self.A.shape)\n",
    "        for k in range(len(GraphList)):\n",
    "            A,l=self.from_networkx_to_tensor(GraphList[k],dict)             \n",
    "            self.A[k,0:A.shape[1]]=A[0]\n",
    "            self.labels[k,0:l.shape[0]]=l\n",
    "        print('adjacency matrices',self.A)\n",
    "        print('node labels',self.labels)\n",
    "        print('order of the graphs',self.card)\n",
    "        \n",
    "    def forward(self, input):        \n",
    "        ged=torch.zeros(len(input)).to(self.device) \n",
    "        node_costs,nodeInsDel,edge_costs,edgeInsDel=self.from_weighs_to_costs()\n",
    "        #alpha=self.coef_dist*self.coef_dist\n",
    "       \n",
    "        \n",
    "        #print('weighs:',self.weighs.device,'device:',self.device,'card:',self.card.device,'A:',self.A.device,'labels:',self.labels.device)\n",
    "        for k in range(len(input)):            \n",
    "            g1=input[k][0]\n",
    "            g2=input[k][1]\n",
    "            n=self.card[g1]\n",
    "            m=self.card[g2]\n",
    "            C=self.construct_cost_matrix(g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel)      \n",
    "            \n",
    "            #S=self.mapping_from_similarity(C,n,m) # SVD or iterated power according to compute major axis\n",
    "            S=self.mapping_from_cost(C,n,m) # FW\n",
    "            v=torch.flatten(S)\n",
    "            \n",
    "            normalize_factor=1.0\n",
    "            if self.normalize:\n",
    "                nb_edge1=(self.A[g1][0:n*n] != torch.zeros(n*n,device=self.device)).int().sum()\n",
    "                nb_edge2=(self.A[g2][0:m*m] != torch.zeros(m*m,device=self.device)).int().sum()\n",
    "                normalize_factor=nodeInsDel*(n+m)+edgeInsDel*(nb_edge1 +nb_edge2)                                    \n",
    "            c=torch.diag(C)\n",
    "            D=C-torch.eye(C.shape[0],device=self.device)*c\n",
    "            ged[k]=(.5*v.T@D@v+c.T@v)/normalize_factor\n",
    "       \n",
    "            \n",
    "        \n",
    "        return ged\n",
    "    \n",
    "    def from_weighs_to_costs(self):\n",
    "        \n",
    "        #cn=torch.exp(self.node_weighs)\n",
    "        #ce=torch.exp(self.edge_weighs)\n",
    "        cn=self.node_weighs*self.node_weighs\n",
    "        ce=self.edge_weighs*self.edge_weighs\n",
    "        total_cost=(cn.sum()+ce.sum())\n",
    "        cn=cn/total_cost\n",
    "        ce=ce/total_cost\n",
    "        edgeInsDel=ce[-1]\n",
    "\n",
    "        node_costs=torch.zeros((self.nb_labels,self.nb_labels),device=self.device)\n",
    "        upper_part=torch.triu_indices(node_costs.shape[0],node_costs.shape[1],offset=1,device=self.device)        \n",
    "        node_costs[upper_part[0],upper_part[1]]=cn[0:-1]\n",
    "        node_costs=node_costs+node_costs.T\n",
    "        if self.nb_edge_labels>1:\n",
    "            edge_costs=torch.zeros((self.nb_edge_labels,self.nb_edge_labels),device=self.device)\n",
    "            upper_part=torch.triu_indices(edge_costs.shape[0],edge_costs.shape[1],offset=1,device=self.device)        \n",
    "            edge_costs[upper_part[0],upper_part[1]]=ce[0:-1]\n",
    "            edge_costs=edge_costs+edge_costs.T\n",
    "        else:\n",
    "            edge_costs=torch.zeros(0,device=self.device)\n",
    "        \n",
    "        return node_costs,cn[-1],edge_costs,edgeInsDel\n",
    "    \n",
    "    def build_node_dictionnary(self,GraphList):\n",
    "        #extraction de tous les labels d'atomes\n",
    "        node_labels=[]\n",
    "        for G in Gs:\n",
    "            for v in nx.nodes(G):\n",
    "                if not G.nodes[v][self.node_label][0] in node_labels:\n",
    "                    node_labels.append(G.nodes[v][self.node_label][0])\n",
    "        node_labels.sort()\n",
    "        #extraction d'un dictionnaire permettant de numéroter chaque label par un numéro.\n",
    "        dict={}\n",
    "        k=0\n",
    "        for label in node_labels:\n",
    "            dict[label]=k\n",
    "            k=k+1\n",
    "        print(node_labels)\n",
    "        print(dict,len(dict))\n",
    "    \n",
    "        return dict,max(max([[int(G[e[0]][e[1]]['bond_type']) for e in G.edges()] for G in GraphList]))\n",
    "    \n",
    "    def from_networkx_to_tensor(self,G,dict):    \n",
    "        A=torch.tensor(nx.to_scipy_sparse_matrix(G,dtype=int,weight='bond_type').todense(),dtype=torch.int)        \n",
    "        lab=[dict[G.nodes[v][self.node_label][0]] for v in nx.nodes(G)]\n",
    "   \n",
    "        return (A.view(1,A.shape[0]*A.shape[1]),torch.tensor(lab))\n",
    "\n",
    "    def construct_cost_matrix(self,g1,g2,node_costs,edge_costs,nodeInsDel,edgeInsDel):\n",
    "        n = self.card[g1].item()\n",
    "        m = self.card[g2].item()\n",
    "        \n",
    "        A1=torch.zeros((n+1,n+1),dtype=torch.int,device=self.device)\n",
    "        A1[0:n,0:n]=self.A[g1][0:n*n].view(n,n)\n",
    "        A2=torch.zeros((m+1,m+1),dtype=torch.int,device=self.device)\n",
    "        A2[0:m,0:m]=self.A[g2][0:m*m].view(m,m)\n",
    "        \n",
    "        \n",
    "         # costs: 0 node subs, 1 nodeIns/Del, 2 : edgeSubs, 3 edgeIns/Del\n",
    "        \n",
    "        #C=cost[3]*torch.cat([torch.cat([C12[l][k] for k in range(n+1)],1) for l in range(n+1)])\n",
    "        #Pas bien sur mais cela semble fonctionner.\n",
    "        C=edgeInsDel*self.matrix_edgeInsDel(A1,A2)\n",
    "        if self.nb_edge_labels>1:\n",
    "            for k in range(self.nb_edge_labels):\n",
    "                for l in range(self.nb_edge_labels):\n",
    "                    if k != l:\n",
    "#                    C.add_(self.matrix_edgeSubst(A1,A2,k+1,l+1),alpha=edge_costs[k][l])\n",
    "                        C=C+edge_costs[k][l]*self.matrix_edgeSubst(A1,A2,k+1,l+1)\n",
    "        #C=cost[3]*torch.tensor(np.array([ [  k!=l and A1[k//(m+1),l//(m+1)]^A2[k%(m+1),l%(m+1)] for k in range((n+1)*(m+1))] for l in range((n+1)*(m+1))]),device=self.device)        \n",
    "\n",
    "        l1=self.labels[g1][0:n]\n",
    "        l2=self.labels[g2][0:m]\n",
    "        D=torch.zeros((n+1)*(m+1),device=self.device)\n",
    "        D[n*(m+1):]=nodeInsDel\n",
    "        D[n*(m+1)+m]=0\n",
    "        D[[i*(m+1)+m for i in range(n)]]=nodeInsDel\n",
    "        D[[k for k in range(n*(m+1)) if k%(m+1) != m]]=torch.tensor([node_costs[l1[k//(m+1)],l2[k%(m+1)]] for k in range(n*(m+1)) if k%(m+1) != m],device=self.device )\n",
    "        mask = torch.diag(torch.ones_like(D))\n",
    "        C=mask*torch.diag(D) + (1. - mask)*C\n",
    "        \n",
    "        #C[range(len(C)),range(len(C))]=D\n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        return C\n",
    "    def matrix_edgeInsDel(self,A1,A2):\n",
    "        Abin1=(A1!=torch.zeros((A1.shape[0],A1.shape[1]),device=self.device))\n",
    "        Abin2=(A2!=torch.zeros((A2.shape[0],A2.shape[1]),device=self.device))\n",
    "        C1=torch.einsum('ij,kl->ijkl',torch.logical_not(Abin1),Abin2)\n",
    "        C2=torch.einsum('ij,kl->ijkl',Abin1,torch.logical_not(Abin2))\n",
    "        C12=torch.logical_or(C1,C2).int()\n",
    "    \n",
    "        return torch.cat(torch.unbind(torch.cat(torch.unbind(C12,1),1),0),1)\n",
    "\n",
    "    def matrix_edgeSubst(self,A1,A2,lab1,lab2):\n",
    "        Abin1=(A1==lab1*torch.ones((A1.shape[0],A1.shape[1]),device=self.device)).int()\n",
    "        Abin2=(A2==lab2*torch.ones((A2.shape[0],A2.shape[1]),device=self.device)).int()\n",
    "        C=torch.einsum('ij,kl->ijkl',Abin1,Abin2)\n",
    "        \n",
    "        return torch.cat(torch.unbind(torch.cat(torch.unbind(C,1),1),0),1)\n",
    "    \n",
    "    def mapping_from_cost(self,C,n,m):        \n",
    "        c=torch.diag(C)\n",
    "        D=C-torch.eye(C.shape[0],device=self.device)*c\n",
    "        x0=franck_wolfe.lsape(c.view(n+1,m+1),0.5,10)\n",
    "        #x0=svd.eps_assigment_from_mapping(torch.exp(-0.5*c.view(n+1,m+1)),10).view((n+1)*(m+1),1) # a améliorer.\n",
    "        #Cred,delta=franck_wolfe.from_lsape_to_lsap(c.view(n+1,m+1))\n",
    "        #S=franck_wolfe.from_costs_to_similarities(Cred,-.5)\n",
    "        #S=torch.exp(-.5*Cred)\n",
    "        #s=franck_wolfe.sinkhorn(S,10)\n",
    "        #x0=franck_wolfe.lsape_recover_sol_from_lsap(s,delta).view((n+1)*(m+1),1)\n",
    "        x=franck_wolfe.franck_wolfe(x0,D,c,2,10,n,m)\n",
    "        def print_grad(grad):\n",
    "            if(grad.norm()!= 0.0):\n",
    "                print(grad)\n",
    "        \n",
    "       # x.register_hook(print_grad)\n",
    "        return x\n",
    "    \n",
    "      \n",
    " \n",
    "    \n",
    "            \n",
    "#print(model(input))\n",
    "#print(max([G.order() for G in Gs]),len(Gs))\n",
    "#print('toto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train graphs: tensor([ 44, 106,  57, 135,  55,  62,  56, 139, 117,  30, 113,  59, 156,  25,\n",
      "         54, 163, 159,  21,  10,  64,   4, 131,  47, 149,  18,  33,   7,  11,\n",
      "        125, 119, 143,  74,  34, 101, 126,   0,  75,  87, 137, 132,  85, 111,\n",
      "        104,  27,  38,  97,  42,  70,  84,  35,  81,  98, 100, 160,  16,  67,\n",
      "          9,   2, 121,  49, 162, 130,  76, 148,  50,  15,  80,  68, 140, 134])\n",
      "data= tensor([[162,  44],\n",
      "        [162, 106],\n",
      "        [162,  57],\n",
      "        ...,\n",
      "        [134,   2],\n",
      "        [134, 121],\n",
      "        [134,  49]], dtype=torch.int32) 600\n",
      "yt= tensor([ 91.5000, 122.0000, 144.2000, 162.0000, 120.3000, 139.0000, 145.0000,\n",
      "        155.5000, 165.0000,  92.0000, 109.5000, 132.0000, 173.0000,  59.5000,\n",
      "        123.5000, 240.0000, 188.5000,  70.3000,  32.0000, 120.0000,  39.0000,\n",
      "        157.0000,  86.3000, 250.0000, 156.0000, 112.5000, 135.0000,  63.0000,\n",
      "        195.0000, 170.0000, 163.0000, 117.1000, 118.5000, 142.0000, 215.0000,\n",
      "         14.0000, 107.0000, 124.0000, 159.5000, 139.0000, 114.0000, 151.0000,\n",
      "        130.5000,  83.0000,  99.5000, 138.0000,  82.0000, 175.7000, 137.0000,\n",
      "        101.5000, 101.0000, 142.0000, 229.5000, 199.0000,  92.0000, 177.2000,\n",
      "         34.6000, 109.7000, 148.5000, 103.0000, 216.0000, 165.5000, 102.5000,\n",
      "        218.0000, 103.5000,  95.5000,  87.6000, 181.0000, 141.0000, 153.5000])\n"
     ]
    }
   ],
   "source": [
    "from regression import KnnRegressFromGED as regress\n",
    "from regression import train_set_for_knnregression as create_dataset\n",
    "\n",
    "nb=len(Gs)\n",
    "#class1=torch.tensor([k for k in range(len(y)) if y[k]==1])\n",
    "#class2=torch.tensor([k for k in range(len(y)) if y[k]==0])\n",
    "\n",
    "train_size=70\n",
    "nb_test=10\n",
    "train_graphs=torch.randperm(nb)[0:train_size]\n",
    "print('train graphs:', train_graphs)\n",
    "\n",
    "\n",
    "\n",
    "#couples=[]\n",
    "#for k in range(nb_elt):\n",
    "#    if (y[data[k][0]]!=y[data[k][1]]):\n",
    "#        yt[k]=-1.0        \n",
    "#data,yt=train_set_for_kernel_ridge(train_graphs,y,train_size)\n",
    "data,yt=create_dataset(train_graphs,y,train_size,nb_test)\n",
    "print('data=',data,data.shape[0])\n",
    "print('yt=',yt)\n",
    "#print(couples[1:2])\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")          # a CUDA device object    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C_1C', 'C_1C1C', 'C_1C1C1C', 'C_1C1C1C1C', 'C_1C1C1C1O', 'C_1C1C1C1S', 'C_1C1C1O', 'C_1C1C1O1O', 'C_1C1C1S', 'C_1C1C1S1S', 'C_1C1O', 'C_1C1O1O', 'C_1C1S', 'C_1C1S1S', 'C_1O', 'C_1O1O', 'C_1S', 'C_1S1S', 'O_1C1C', 'O_1C1O', 'S_1C1C', 'S_1C1S']\n",
      "{'C_1C': 0, 'C_1C1C': 1, 'C_1C1C1C': 2, 'C_1C1C1C1C': 3, 'C_1C1C1C1O': 4, 'C_1C1C1C1S': 5, 'C_1C1C1O': 6, 'C_1C1C1O1O': 7, 'C_1C1C1S': 8, 'C_1C1C1S1S': 9, 'C_1C1O': 10, 'C_1C1O1O': 11, 'C_1C1S': 12, 'C_1C1S1S': 13, 'C_1O': 14, 'C_1O1O': 15, 'C_1S': 16, 'C_1S1S': 17, 'O_1C1C': 18, 'O_1C1O': 19, 'S_1C1C': 20, 'S_1C1S': 21} 22\n",
      "nb labels: 22  ; nb_edge_labels: 1\n",
      "torch.Size([164, 121])\n",
      "adjacency matrices tensor([[0, 0, 1,  ..., 0, 0, 0],\n",
      "        [0, 0, 1,  ..., 0, 0, 0],\n",
      "        [0, 0, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 1,  ..., 1, 1, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 1,  ..., 0, 1, 0]], device='cuda:0', dtype=torch.int32)\n",
      "node labels tensor([[14, 14, 19,  ...,  0,  0,  0],\n",
      "        [16, 16, 20,  ...,  0,  0,  0],\n",
      "        [16, 16, 21,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 0,  0,  1,  ..., 12, 12, 20],\n",
      "        [ 0,  0,  0,  ...,  2,  2, 20],\n",
      "        [ 0, 16,  1,  ...,  1, 12, 20]], device='cuda:0', dtype=torch.int32)\n",
      "order of the graphs tensor([ 4,  3,  4,  4,  5,  5,  4,  5,  5,  5,  5,  6,  6,  6,  6,  5,  5,  5,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  6,  6,  6,  6,  6,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,\n",
      "         8,  8,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9, 10, 10, 10, 10, 10,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11,\n",
      "        11, 11, 11, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11], device='cuda:0')\n",
      "Parameters:\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([232])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([])\n",
      "cuda:0\n",
      "alpha positif( 5 ) 4.290748620405793e-05 beta= -5.385134045354789e-06\n",
      "alpha positif( 7 ) 7.605158316437155e-05 beta= -1.2385508796342037e-07\n",
      "alpha positif( 5 ) 0.0002897742670029402 beta= -5.55196902496391e-06\n",
      "alpha positif( 10 ) 0.00022053302382119 beta= 6.6257803688074546e-09\n",
      "alpha positif( 7 ) 3.196409670636058e-05 beta= 7.176617145887576e-06\n",
      "alpha positif( 7 ) 4.580501627060585e-05 beta= 2.2537355093277256e-08\n",
      "alpha positif( 5 ) 0.000395768613088876 beta= -1.6429681636509486e-05\n",
      "alpha positif( 9 ) 4.1692219383548945e-06 beta= -4.02424049639194e-08\n",
      "alpha positif( 7 ) 6.236432091100141e-05 beta= 1.1429792223793811e-08\n",
      "alpha positif( 3 ) 0.0002104064915329218 beta= 0.0013509661657735705\n",
      "alpha positif( 8 ) 7.70557890064083e-05 beta= 3.85521445878112e-07\n",
      "alpha positif( 6 ) 4.637817619368434e-05 beta= 0.00017482116527389735\n",
      "alpha positif( 6 ) 0.00015549980162177235 beta= 0.00029683936736546457\n",
      "alpha positif( 4 ) 3.86550382245332e-05 beta= -1.4900344069701532e-07\n",
      "alpha positif( 6 ) 0.0004868695395998657 beta= -8.277706342596503e-07\n",
      "alpha positif( 7 ) 0.00015678652562201023 beta= 0.0006079075392335653\n",
      "alpha positif( 8 ) 1.3180020687286742e-05 beta= -6.550511670866399e-07\n",
      "alpha positif( 8 ) 0.0011401143856346607 beta= 1.876122405519709e-05\n",
      "alpha positif( 4 ) 0.0001207105306093581 beta= 5.381232040235773e-05\n",
      "alpha positif( 6 ) 1.357357541564852e-05 beta= 4.2849563897107146e-09\n",
      "alpha positif( 8 ) 0.00022531136346515268 beta= 9.610153938410804e-06\n",
      "alpha positif( 9 ) 5.251171387499198e-06 beta= 1.4939013581738436e-08\n",
      "alpha positif( 4 ) 0.0005639758892357349 beta= 0.0008404034888371825\n",
      "alpha positif( 9 ) 1.9263186914031394e-05 beta= -7.543187185987676e-10\n",
      "alpha positif( 10 ) 3.9303922676481307e-05 beta= -5.670862719853176e-06\n",
      "alpha positif( 9 ) 2.7645532099995762e-05 beta= 2.6054556290233677e-09\n",
      "alpha positif( 6 ) 3.502026811474934e-05 beta= 1.0273443876940291e-05\n",
      "alpha positif( 2 ) 8.753692964091897e-05 beta= -1.327406062046066e-05\n",
      "alpha positif( 9 ) 0.00028645439306274056 beta= -4.104339313926175e-05\n",
      "alpha positif( 10 ) 1.4116817510512192e-06 beta= -6.339625352458356e-11\n",
      "alpha positif( 6 ) 0.00011402923701098189 beta= -7.368807473540073e-06\n",
      "alpha positif( 6 ) 1.4551798813045025e-05 beta= 1.4695770005346276e-05\n",
      "alpha positif( 6 ) 4.86517819808796e-07 beta= 7.540150193108275e-08\n",
      "alpha positif( 5 ) 0.00022206702851690352 beta= 0.0001085968833649531\n",
      "alpha positif( 8 ) 4.5119842980057e-05 beta= 6.179931233418756e-09\n",
      "alpha positif( 8 ) 0.002808717079460621 beta= -2.7317717467667535e-05\n",
      "alpha positif( 7 ) 2.1062674932181835e-05 beta= -1.8051329320201148e-08\n",
      "alpha positif( 8 ) 2.097084143315442e-05 beta= 1.4253108915340817e-08\n",
      "alpha positif( 10 ) 0.006370184011757374 beta= -1.946359043358825e-05\n",
      "alpha positif( 7 ) 0.00027115532429888844 beta= 9.265486733056605e-05\n",
      "alpha positif( 5 ) 1.5910249203443527e-05 beta= 2.2093827283242717e-06\n",
      "alpha positif( 5 ) 0.00010500728967599571 beta= 1.7309565691903117e-06\n",
      "alpha positif( 8 ) 0.00012439611600711942 beta= -3.2544471650908235e-07\n",
      "alpha positif( 5 ) 0.00012757621880155057 beta= -7.828466550563462e-07\n",
      "alpha positif( 10 ) 7.911665306892246e-06 beta= -8.847908929965342e-07\n",
      "alpha positif( 6 ) 2.197416870330926e-05 beta= 2.5407755899209405e-08\n",
      "alpha positif( 4 ) 4.186948899587151e-06 beta= 1.12279565200879e-06\n",
      "alpha positif( 6 ) 2.4136574211297557e-05 beta= -2.48697844540402e-08\n",
      "alpha positif( 10 ) 2.8517908503999934e-05 beta= -2.5860892094442534e-08\n",
      "alpha positif( 5 ) 6.065675552235916e-05 beta= 1.947118107636925e-05\n",
      "alpha positif( 7 ) 1.191486808238551e-05 beta= 5.760869953519432e-06\n",
      "alpha positif( 8 ) 1.6391571989515796e-05 beta= -5.8139342229424074e-08\n",
      "alpha positif( 6 ) 2.6086247089551762e-05 beta= 1.7814212327493806e-09\n",
      "alpha positif( 6 ) 5.934991349931806e-05 beta= 7.669621481909417e-06\n",
      "alpha positif( 9 ) 2.5600334993214346e-05 beta= -5.8868600660844095e-08\n",
      "alpha positif( 8 ) 0.0002506648888811469 beta= -5.9106023400090635e-05\n",
      "alpha positif( 8 ) 5.5759075621608645e-05 beta= -1.4723392283144676e-08\n",
      "alpha positif( 8 ) 0.0006964188651181757 beta= 0.00022720845299772918\n",
      "alpha positif( 6 ) 0.00012886669719591737 beta= 3.2011648727348074e-06\n",
      "alpha positif( 7 ) 3.074518826906569e-05 beta= 1.295723563998763e-06\n",
      "alpha positif( 5 ) 0.00014679247396998107 beta= 2.367424478677549e-08\n",
      "alpha positif( 4 ) 0.00013012491399422288 beta= 1.9613688095887483e-07\n",
      "alpha positif( 9 ) 0.0003353330248501152 beta= 5.2454484830377623e-05\n",
      "alpha positif( 5 ) 0.00018479753634892404 beta= 7.834358370928385e-07\n",
      "alpha positif( 4 ) 0.0006106656510382891 beta= -3.1033363256938173e-07\n",
      "alpha positif( 5 ) 2.222025068476796e-05 beta= 5.323885034158593e-06\n",
      "alpha positif( 8 ) 4.216660454403609e-05 beta= 1.1200810945410922e-07\n",
      "alpha positif( 7 ) 0.00043788005132228136 beta= -0.0005294958245940506\n",
      "alpha positif( 6 ) 4.097420605830848e-05 beta= 6.842133734608069e-05\n",
      "alpha positif( 5 ) 0.00028042332269251347 beta= -5.206784408073872e-05\n",
      "alpha positif( 5 ) 0.002201006282120943 beta= 0.0007546594133600593\n",
      "alpha positif( 7 ) 6.5319472923874855e-06 beta= 0.00014736312732566148\n",
      "alpha positif( 6 ) 0.00027828855672851205 beta= -4.740754633303368e-08\n",
      "alpha positif( 5 ) 0.0006732200854457915 beta= 2.931485141743906e-05\n",
      "alpha positif( 6 ) 4.793398693436757e-05 beta= 6.219300185961174e-09\n",
      "alpha positif( 5 ) 0.0001052218212862499 beta= 1.304352622355509e-06\n",
      "alpha positif( 3 ) 0.00012009954662062228 beta= 6.687907443847507e-05\n",
      "alpha positif( 10 ) 2.8070597181795165e-05 beta= 1.4305682327631075e-07\n",
      "alpha positif( 7 ) 8.71084921527654e-05 beta= 5.425391123026202e-07\n",
      "alpha positif( 3 ) 0.000258282118011266 beta= 0.00019332702504470944\n",
      "alpha positif( 6 ) 0.00036926919710822403 beta= -6.4622308855177835e-06\n",
      "alpha positif( 3 ) 1.331343810306862e-05 beta= 2.137995522843994e-07\n",
      "alpha positif( 10 ) 0.0003118068561889231 beta= 2.0281609977246262e-05\n",
      "alpha positif( 5 ) 0.0006660367944277823 beta= -0.0007907371618784964\n",
      "alpha positif( 5 ) 2.54691403824836e-05 beta= -4.7633494659748976e-07\n",
      "alpha positif( 5 ) 2.1766085410490632e-05 beta= 0.000937925127800554\n",
      "alpha positif( 3 ) 0.0004358147270977497 beta= 0.0022635753266513348\n",
      "alpha positif( 7 ) 3.567146632121876e-05 beta= 1.3051638347860717e-07\n",
      "alpha positif( 4 ) 5.5913013056851923e-05 beta= -8.011249974515522e-07\n",
      "alpha positif( 6 ) 9.473369573242962e-06 beta= 5.286976261231757e-07\n",
      "alpha positif( 4 ) 1.703060115687549e-05 beta= -2.8518350063677644e-06\n",
      "alpha positif( 6 ) 1.1882525541295763e-06 beta= 6.943812191906318e-10\n",
      "alpha positif( 9 ) 0.0001132241595769301 beta= -7.540192914490262e-10\n",
      "alpha positif( 6 ) 5.3038740588817745e-05 beta= 6.395717718987726e-06\n",
      "alpha positif( 4 ) 6.334678619168699e-05 beta= 2.9855693810532102e-06\n",
      "alpha positif( 10 ) 6.178298644954339e-05 beta= -1.5316120594022209e-09\n",
      "alpha positif( 7 ) 0.00033959929714910686 beta= -0.00020720536122098565\n",
      "alpha positif( 5 ) 6.408973422367126e-05 beta= 6.678421300421178e-07\n",
      "alpha positif( 2 ) 0.00032004847889766097 beta= -1.1905786777788308e-05\n",
      "alpha positif( 7 ) 4.2671672417782247e-07 beta= 1.3358416254050098e-05\n",
      "alpha positif( 4 ) 8.131715003401041e-05 beta= -3.901129821315408e-05\n",
      "alpha positif( 7 ) 0.0025222771801054478 beta= -1.3143014712113654e-06\n",
      "alpha positif( 8 ) 5.160505679668859e-06 beta= -9.95946720649954e-07\n",
      "alpha positif( 7 ) 6.510890671052039e-08 beta= 1.2293086548709198e-08\n",
      "alpha positif( 8 ) 2.7598798624239862e-05 beta= 1.3801944476199424e-07\n",
      "alpha positif( 7 ) 5.895584763493389e-06 beta= 1.5934448356347275e-06\n",
      "alpha positif( 7 ) 8.823083771858364e-05 beta= 2.3388281533698319e-07\n",
      "alpha positif( 7 ) 0.00018163678760174662 beta= -2.5470295440754853e-05\n",
      "alpha positif( 4 ) 0.000685487175360322 beta= 0.0007785044726915658\n",
      "alpha positif( 5 ) 2.7857320674229413e-05 beta= -2.013357061514398e-06\n",
      "alpha positif( 8 ) 0.0005664362688548863 beta= -1.3551141819334589e-05\n",
      "alpha positif( 9 ) 0.0007841656915843487 beta= 2.8995755201322027e-05\n",
      "alpha positif( 5 ) 2.0468636648729444e-05 beta= 3.9040573028614745e-05\n",
      "alpha positif( 6 ) 0.0005011459579691291 beta= -2.9128398182365345e-06\n",
      "alpha positif( 9 ) 0.00016603185213170946 beta= 2.48144096985925e-05\n",
      "alpha positif( 10 ) 5.74158038944006e-05 beta= 0.0006817879620939493\n",
      "alpha positif( 8 ) 0.00026724347844719887 beta= 3.394805025891401e-05\n",
      "alpha positif( 8 ) 2.1256286345305853e-05 beta= -9.022477343023638e-08\n",
      "alpha positif( 9 ) 4.547050048131496e-05 beta= 2.4846806354617e-06\n",
      "alpha positif( 3 ) 0.0002981700235977769 beta= 2.9156275559216738e-05\n",
      "alpha positif( 4 ) 0.000190390957868658 beta= 1.3563576430897228e-05\n",
      "alpha positif( 9 ) 0.00030077312840148807 beta= -9.585426596459001e-06\n",
      "alpha positif( 9 ) 5.687313750968315e-05 beta= 1.4324871244753012e-07\n",
      "alpha positif( 6 ) 7.249793270602822e-06 beta= 1.4914845678504207e-06\n",
      "alpha positif( 6 ) 0.0013045195955783129 beta= 4.8012181650847197e-05\n",
      "alpha positif( 8 ) 0.00017761890194378793 beta= 0.0002750112907961011\n",
      "alpha positif( 7 ) 6.55624462524429e-05 beta= 2.974181916215457e-05\n",
      "alpha positif( 7 ) 0.0001505523396190256 beta= 3.666033165927729e-08\n",
      "alpha positif( 8 ) 0.0009027004707604647 beta= 0.0026224039029330015\n",
      "alpha positif( 10 ) 9.948615115717985e-06 beta= 2.2602302252039408e-08\n",
      "alpha positif( 8 ) 6.863031740067527e-05 beta= 0.00025526905665174127\n",
      "alpha positif( 9 ) 0.0015094336122274399 beta= -0.0002524063747841865\n",
      "alpha positif( 9 ) 4.285357135813683e-05 beta= 7.349628140218556e-05\n",
      "alpha positif( 8 ) 0.0002427063591312617 beta= 0.0003755368525162339\n",
      "alpha positif( 4 ) 0.00032375421142205596 beta= 7.523557724198326e-05\n",
      "alpha positif( 8 ) 8.512171916663647e-06 beta= 0.0017726453952491283\n",
      "alpha positif( 5 ) 2.1046034817118198e-05 beta= -6.261861926759593e-07\n",
      "alpha positif( 9 ) 8.171961235348135e-05 beta= -6.1520468079834245e-06\n",
      "alpha positif( 5 ) 0.00023549496836494654 beta= -8.76493913892773e-07\n",
      "alpha positif( 4 ) 6.044261681381613e-05 beta= 2.9797060051350854e-05\n",
      "alpha positif( 6 ) 6.246607517823577e-05 beta= 1.23177142086206e-05\n",
      "alpha positif( 5 ) 1.9917752069886774e-07 beta= 3.733147835305317e-08\n",
      "alpha positif( 6 ) 0.00010918774933088571 beta= 8.225689640539713e-08\n",
      "alpha positif( 4 ) 6.350934563670307e-05 beta= 1.857987263065297e-05\n",
      "alpha positif( 3 ) 0.00014224089682102203 beta= -0.000135163456434384\n",
      "alpha positif( 9 ) 3.2944371923804283e-06 beta= -1.5579806131427176e-05\n",
      "alpha positif( 6 ) 0.0005304018268361688 beta= -2.6977641027770005e-06\n",
      "alpha positif( 4 ) 3.299073068774305e-05 beta= -1.2829445950046647e-07\n",
      "alpha positif( 5 ) 0.00026496031205169857 beta= -1.4522123592541902e-06\n",
      "alpha positif( 4 ) 6.400940037565306e-06 beta= -4.245375180289557e-07\n",
      "alpha positif( 5 ) 0.00037648819852620363 beta= -1.402711291120795e-06\n",
      "alpha positif( 7 ) 0.00012408250768203288 beta= 4.740408030556864e-07\n",
      "alpha positif( 8 ) 0.00027338959625922143 beta= 4.391238690004684e-06\n",
      "alpha positif( 4 ) 1.941298796737101e-05 beta= 3.2571392694080714e-07\n",
      "alpha positif( 6 ) 0.00011355895549058914 beta= 2.772442940113251e-06\n",
      "alpha positif( 5 ) 3.7299294490367174e-05 beta= 7.733761776762549e-06\n",
      "alpha positif( 5 ) 8.913400233723223e-05 beta= 1.8897619156632572e-05\n",
      "alpha positif( 6 ) 0.00032443716190755367 beta= -8.32119767437689e-05\n",
      "alpha positif( 6 ) 7.408908277284354e-05 beta= -2.3548440708509588e-07\n",
      "alpha positif( 8 ) 4.69318256364204e-05 beta= 4.246275864261406e-07\n",
      "alpha positif( 4 ) 0.0008318910840898752 beta= 8.705741493031383e-05\n",
      "alpha positif( 10 ) 4.808363883057609e-06 beta= -1.828043565410553e-07\n",
      "alpha positif( 8 ) 2.5613604520913213e-05 beta= -2.0829102709285507e-07\n",
      "alpha positif( 4 ) 4.8000176320783794e-05 beta= 7.531203664257191e-06\n",
      "alpha positif( 7 ) 1.966242416528985e-05 beta= -1.4572364079867839e-06\n",
      "alpha positif( 5 ) 1.175233774119988e-05 beta= 5.08867242388078e-06\n",
      "alpha positif( 5 ) 0.003696220461279154 beta= -0.00013397636939771473\n",
      "alpha positif( 9 ) 5.595781658485066e-06 beta= 9.651159871282289e-08\n",
      "alpha positif( 5 ) 0.0002442368713673204 beta= -9.290462185163051e-05\n",
      "alpha positif( 4 ) 1.1798110790550709e-06 beta= 6.139098786661634e-06\n",
      "alpha positif( 7 ) 3.9689766708761454e-05 beta= -3.3525424214531085e-07\n",
      "alpha positif( 8 ) 8.54551763040945e-06 beta= 2.1405469396995613e-07\n",
      "alpha positif( 8 ) 3.1897565349936485e-05 beta= 8.123457519104704e-06\n",
      "alpha positif( 6 ) 0.00013874677824787796 beta= 1.4946213156008525e-08\n",
      "alpha positif( 2 ) 0.0005489356117323041 beta= 4.9088583182310686e-05\n",
      "alpha positif( 4 ) 0.00023674190742895007 beta= -5.67115739613655e-06\n",
      "alpha positif( 5 ) 0.00018259364878758788 beta= 1.1271661151113221e-06\n",
      "alpha positif( 4 ) 9.296671487390995e-05 beta= -6.076759007100918e-08\n",
      "alpha positif( 7 ) 2.2013700800016522e-06 beta= -1.0939979944168954e-07\n",
      "alpha positif( 4 ) 0.0005032484186813235 beta= -2.173750544898212e-05\n",
      "alpha positif( 4 ) 0.0005488387541845441 beta= -7.024634396657348e-05\n",
      "alpha positif( 4 ) 0.00047445172094739974 beta= -7.102276526893547e-07\n",
      "alpha positif( 3 ) 5.8519926824374124e-05 beta= -1.578671060542547e-08\n",
      "alpha positif( 6 ) 1.3259693332656752e-05 beta= -3.2505717562081315e-10\n",
      "alpha positif( 4 ) 1.880564377643168e-05 beta= 1.6866147234395612e-06\n",
      "alpha positif( 6 ) 6.524613127112389e-05 beta= -5.772984877694398e-06\n",
      "alpha positif( 3 ) 0.00010996608762070537 beta= -0.00022672733757644892\n",
      "alpha positif( 4 ) 0.00014545432350132614 beta= -8.926143379994755e-08\n",
      "alpha positif( 4 ) 8.201276796171442e-05 beta= 1.0842386473086663e-06\n",
      "alpha positif( 3 ) 4.7264609747799113e-05 beta= 3.7641459016413137e-07\n",
      "alpha positif( 4 ) 7.895064300100785e-06 beta= -3.0317615085095895e-08\n",
      "alpha positif( 7 ) 6.319861131487414e-05 beta= -1.5440689367096638e-06\n",
      "alpha positif( 3 ) 0.00014741305494681 beta= -0.00018203187210019678\n",
      "alpha positif( 2 ) 5.571049405261874e-05 beta= -2.3902402972453274e-06\n",
      "alpha positif( 5 ) 0.00035313115222379565 beta= -5.701308964489726e-06\n",
      "alpha positif( 4 ) 0.00016442006744910032 beta= -3.773870105305832e-11\n",
      "alpha positif( 2 ) 6.950757233425975e-05 beta= -5.032816261518747e-07\n",
      "alpha positif( 4 ) 0.0002537569962441921 beta= 9.540758583170827e-06\n",
      "alpha positif( 6 ) 0.00020407179545145482 beta= 1.0938583727693185e-05\n",
      "alpha positif( 5 ) 0.00011257208097958937 beta= 5.2967814553994685e-05\n",
      "alpha positif( 5 ) 2.5582266971468925e-08 beta= 1.7453551492963015e-08\n",
      "alpha positif( 5 ) 3.7042533222120255e-05 beta= 1.648714800239759e-07\n",
      "alpha positif( 5 ) 0.00013788293290417641 beta= 1.5967373201419832e-06\n",
      "alpha positif( 8 ) 0.00040420916047878563 beta= -0.00015051748778205365\n",
      "alpha positif( 2 ) 7.503712549805641e-05 beta= 1.8997536244569346e-05\n",
      "alpha positif( 7 ) 2.7576629690884147e-07 beta= -1.213405678018864e-11\n",
      "alpha positif( 5 ) 0.00026576186064630747 beta= 4.967387781107391e-07\n",
      "alpha positif( 4 ) 0.00011512864148244262 beta= -6.693794421153143e-05\n",
      "alpha positif( 3 ) 6.75426417728886e-05 beta= -5.985754825132972e-08\n",
      "alpha positif( 6 ) 1.2958927982253954e-05 beta= 9.292840559282922e-07\n",
      "alpha positif( 8 ) 1.0017625754699111e-05 beta= -6.193225488004828e-08\n",
      "alpha positif( 3 ) 7.330731023102999e-05 beta= -4.798359043434175e-08\n",
      "alpha positif( 4 ) 0.00012195322779007256 beta= -2.571975130649662e-07\n",
      "alpha positif( 8 ) 0.00013414154818747193 beta= 4.821016045752913e-05\n",
      "alpha positif( 5 ) 7.991567690623924e-05 beta= -1.1684645073728461e-07\n",
      "alpha positif( 4 ) 0.0001514824980404228 beta= 4.290302604204044e-05\n",
      "alpha positif( 8 ) 9.929580119205639e-05 beta= -1.3931857445470541e-08\n",
      "alpha positif( 5 ) 6.1178816395113245e-06 beta= 2.2327835413893382e-10\n",
      "alpha positif( 6 ) 0.0032581372652202845 beta= 0.0002884210553020239\n",
      "alpha positif( 6 ) 0.0003494173288345337 beta= 0.0008097538375295699\n",
      "alpha positif( 5 ) 0.004907740280032158 beta= 0.0004706577747128904\n",
      "alpha positif( 4 ) 1.8907070625573397e-05 beta= -3.347542815390625e-06\n",
      "alpha positif( 4 ) 0.00020208432397339493 beta= -5.536496246349998e-06\n",
      "alpha positif( 3 ) 0.01778964325785637 beta= 0.0035612741485238075\n",
      "alpha positif( 8 ) 0.0009539192542433739 beta= 1.8119026208296418e-05\n",
      "alpha positif( 5 ) 0.0011228733928874135 beta= -4.7325571017609036e-07\n",
      "alpha positif( 7 ) 0.00012739081284962595 beta= 1.530777993252741e-08\n",
      "alpha positif( 5 ) 0.00011832430027425289 beta= 0.00035039379145018756\n",
      "alpha positif( 2 ) 0.00012087452341802418 beta= 2.049715112661943e-05\n",
      "alpha positif( 4 ) 0.0003885925398208201 beta= -4.147726485825842e-06\n",
      "alpha positif( 5 ) 0.0001287901250179857 beta= -7.203919405451842e-11\n",
      "alpha positif( 6 ) 1.9580016669351608e-05 beta= 1.3187074765497186e-09\n",
      "alpha positif( 6 ) 1.9830622477456927e-05 beta= 1.145236936395122e-07\n",
      "alpha positif( 9 ) 1.1784228263422847e-05 beta= 6.164578536527188e-08\n",
      "alpha positif( 6 ) 0.00010660804400686175 beta= -1.0985664822271701e-08\n",
      "alpha positif( 6 ) 0.0003767528978642076 beta= -5.850690598663277e-09\n",
      "alpha positif( 5 ) 0.0003082087205257267 beta= 4.5562268496723846e-05\n",
      "alpha positif( 5 ) 7.080280920490623e-05 beta= -1.495383685323759e-06\n",
      "alpha positif( 6 ) 0.00018819548131432384 beta= -9.166299150820123e-07\n",
      "alpha positif( 6 ) 4.213750798953697e-06 beta= 2.494362547622586e-07\n",
      "alpha positif( 6 ) 0.00010691781062632799 beta= -8.773869922151789e-05\n",
      "alpha positif( 4 ) 2.7207774110138416e-05 beta= -6.978973488003248e-06\n",
      "alpha positif( 6 ) 9.474769467487931e-05 beta= 2.227288314315956e-05\n",
      "alpha positif( 3 ) 1.433130819350481e-06 beta= -6.578258307854412e-06\n",
      "alpha positif( 6 ) 1.4291908883024007e-06 beta= 1.890491887479584e-07\n",
      "alpha positif( 5 ) 7.787839422235265e-06 beta= 5.1665185907268096e-08\n",
      "alpha positif( 7 ) 1.2322061593295075e-06 beta= 2.829864675923943e-10\n",
      "alpha positif( 7 ) 3.093948180321604e-06 beta= 2.037828892298421e-07\n",
      "alpha positif( 8 ) 0.00012111863179598004 beta= 4.2761149643411045e-07\n",
      "alpha positif( 6 ) 0.00017140065028797835 beta= -1.501843627238486e-07\n",
      "alpha positif( 7 ) 0.00039423693669959903 beta= -6.65295374346897e-07\n",
      "alpha positif( 4 ) 0.00021496042609214783 beta= 5.502219937625341e-05\n",
      "alpha positif( 7 ) 3.9107282646000385e-05 beta= -0.00010994336480507627\n",
      "alpha positif( 4 ) 4.1797233279794455e-05 beta= 0.0001239624834852293\n",
      "alpha positif( 6 ) 0.00012958049774169922 beta= -1.677468026173301e-05\n",
      "alpha positif( 8 ) 0.00019909796537831426 beta= 2.899570006320573e-07\n",
      "alpha positif( 4 ) 0.00013837614096701145 beta= 7.426643833241542e-08\n",
      "alpha positif( 10 ) 0.0004374900017865002 beta= 1.549028638692107e-05\n",
      "alpha positif( 8 ) 5.6404664064757526e-05 beta= -1.637682167654475e-08\n",
      "alpha positif( 7 ) 1.1012427421519533e-05 beta= -1.772059050608732e-07\n",
      "alpha positif( 6 ) 4.368135705590248e-06 beta= 1.6779134739408619e-06\n",
      "alpha positif( 8 ) 0.00022804216132499278 beta= 4.333536480771727e-07\n",
      "alpha positif( 6 ) 6.047698116162792e-05 beta= -1.9427918829251212e-08\n",
      "alpha positif( 4 ) 0.00024210455012507737 beta= 1.9650490230560536e-06\n",
      "alpha positif( 7 ) 8.52211524033919e-05 beta= 7.058557116579323e-07\n",
      "alpha positif( 10 ) 6.241015216801316e-05 beta= -5.142366603649862e-07\n",
      "alpha positif( 10 ) 1.3796220628137235e-05 beta= -4.184761337455711e-08\n",
      "alpha positif( 4 ) 9.812123607844114e-05 beta= 0.0001004644509521313\n",
      "alpha positif( 6 ) 1.8859311239793897e-05 beta= -3.2257571547233965e-06\n",
      "alpha positif( 9 ) 6.244692485779524e-06 beta= 5.090445120004006e-05\n",
      "alpha positif( 5 ) 0.0001039941271301359 beta= 1.8122103938367218e-05\n",
      "alpha positif( 4 ) 7.010312401689589e-06 beta= 1.0288035809935536e-06\n",
      "alpha positif( 5 ) 2.5533605366945267e-05 beta= 6.55029907647986e-06\n",
      "alpha positif( 6 ) 0.00045124307507649064 beta= -1.3788688193017151e-05\n",
      "alpha positif( 8 ) 0.0001494355092290789 beta= 6.396123808372067e-06\n",
      "alpha positif( 5 ) 2.9657268896698952e-05 beta= 0.0004047948168590665\n",
      "alpha positif( 6 ) 1.776730641722679e-05 beta= 7.498444574594032e-06\n",
      "alpha positif( 4 ) 3.317636583233252e-05 beta= -5.054036137153162e-06\n",
      "alpha positif( 5 ) 5.9613652410916984e-05 beta= 6.253432366065681e-05\n",
      "alpha positif( 7 ) 0.0004299526335671544 beta= 2.8616100600231675e-09\n",
      "alpha positif( 6 ) 6.788471364416182e-05 beta= -1.762742385835736e-06\n",
      "alpha positif( 7 ) 0.0003677962813526392 beta= 2.855259917389219e-10\n",
      "alpha positif( 9 ) 0.0024490770883858204 beta= 0.00047653462388552725\n",
      "alpha positif( 7 ) 0.00245920498855412 beta= 0.0009493861580267549\n",
      "alpha positif( 7 ) 0.00028330215718597174 beta= 0.0023248542565852404\n",
      "alpha positif( 10 ) 0.0006489221705123782 beta= 0.0014256233116611838\n",
      "alpha positif( 7 ) 0.0005297400057315826 beta= 2.4119608497130685e-06\n",
      "alpha positif( 5 ) 5.040796895627864e-05 beta= 2.293289824706335e-08\n",
      "alpha positif( 10 ) 0.00021049031056463718 beta= -2.704086909943726e-07\n",
      "alpha positif( 6 ) 2.999424032168463e-05 beta= -8.907637960575698e-10\n",
      "alpha positif( 5 ) 0.00044716912088915706 beta= -1.2625603176275035e-06\n",
      "alpha positif( 4 ) 1.900149800349027e-05 beta= -1.2025847695440461e-07\n",
      "alpha positif( 4 ) 1.2866761608165689e-05 beta= -3.005852988735569e-08\n",
      "alpha positif( 8 ) 0.00019342874293215573 beta= 8.679638085595798e-06\n",
      "alpha positif( 7 ) 0.00013226908049546182 beta= -6.348641363729257e-06\n",
      "alpha positif( 7 ) 2.376539123360999e-05 beta= 5.233679445382222e-08\n",
      "alpha positif( 6 ) 0.0002228727680630982 beta= 5.942019498661466e-08\n",
      "alpha positif( 9 ) 1.3927147847425658e-05 beta= 3.160388928336033e-08\n",
      "alpha positif( 6 ) 7.671743514947593e-05 beta= -1.5091099157871213e-05\n",
      "alpha positif( 3 ) 0.00010245852172374725 beta= 1.637518778352387e-07\n",
      "alpha positif( 9 ) 2.3967619199538603e-05 beta= 3.0760737956825324e-08\n",
      "alpha positif( 4 ) 1.477771729696542e-05 beta= 2.689712891879026e-05\n",
      "alpha positif( 8 ) 4.233780055074021e-05 beta= 9.831003922045056e-08\n",
      "alpha positif( 8 ) 8.646820060675964e-05 beta= 7.279728486686565e-10\n",
      "alpha positif( 9 ) 3.907565042027272e-05 beta= -2.6984606549262935e-08\n",
      "alpha positif( 6 ) 4.90728416480124e-06 beta= 1.1608255590545014e-05\n",
      "alpha positif( 7 ) 5.4618780268356204e-05 beta= -1.0930385485607985e-08\n",
      "alpha positif( 6 ) 8.04349547252059e-05 beta= -4.717588986125065e-09\n",
      "alpha positif( 6 ) 0.00028715861844830215 beta= 0.00015074868861120194\n",
      "alpha positif( 6 ) 1.2418406186043285e-05 beta= 1.6758152924012393e-05\n",
      "alpha positif( 6 ) 1.2166405213065445e-05 beta= -8.673503026912499e-10\n",
      "alpha positif( 6 ) 5.6444492656737566e-05 beta= 9.369959298055619e-05\n",
      "alpha positif( 3 ) 0.002902701497077942 beta= -0.00032335176365450025\n",
      "alpha positif( 7 ) 2.8944497898919508e-05 beta= -5.227034094446026e-08\n",
      "alpha positif( 8 ) 5.7106859458144754e-05 beta= 4.825637223149215e-09\n",
      "alpha positif( 4 ) 0.0005117867258377373 beta= -5.662428884534165e-05\n",
      "alpha positif( 4 ) 6.539936293847859e-05 beta= -4.2065568806037845e-08\n",
      "alpha positif( 4 ) 0.0002871826000045985 beta= 0.00013883695646654814\n",
      "alpha positif( 6 ) 4.137657379033044e-05 beta= 2.0167776426660566e-07\n",
      "alpha positif( 10 ) 0.0002231829275842756 beta= -9.386178135173395e-06\n",
      "alpha positif( 6 ) 1.8142300177714787e-05 beta= -2.958283573661902e-07\n",
      "alpha positif( 10 ) 0.00016054041043389589 beta= 8.976129173277059e-09\n",
      "alpha positif( 10 ) 2.0723449779325165e-05 beta= -5.546668901956764e-08\n",
      "alpha positif( 9 ) 0.00010335089609725401 beta= -3.1433054914487e-07\n",
      "alpha positif( 6 ) 5.984641029499471e-05 beta= 8.709917892701924e-06\n",
      "alpha positif( 7 ) 0.00016220530960708857 beta= 0.00020584450976457447\n",
      "alpha positif( 7 ) 0.00013314580428414047 beta= 1.0138153356820112e-06\n",
      "alpha positif( 7 ) 0.00020063304691575468 beta= -1.8809646462614182e-07\n",
      "alpha positif( 6 ) 1.9313614757265896e-05 beta= -6.989414913505243e-08\n",
      "alpha positif( 7 ) 0.00014876495697535574 beta= 2.918392601714004e-05\n",
      "alpha positif( 8 ) 4.860276021645404e-07 beta= 1.7747730396422412e-08\n",
      "alpha positif( 5 ) 0.0001884255325421691 beta= -1.0843982636288274e-06\n",
      "alpha positif( 9 ) 0.00021642076899297535 beta= -7.589808319607982e-06\n",
      "alpha positif( 4 ) 0.0001343277981504798 beta= -7.300117431441322e-06\n",
      "alpha positif( 7 ) 0.00013437129382509738 beta= 4.5441156544256955e-05\n",
      "alpha positif( 5 ) 0.00016084319213405252 beta= -3.391870632185601e-05\n",
      "alpha= tensor(0.7225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "0 9.158748725817095\n",
      "alpha= tensor(0.7225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "target= tensor([ 91.5000, 122.0000, 144.2000, 162.0000, 120.3000, 139.0000, 145.0000,\n",
      "        155.5000, 165.0000,  92.0000, 109.5000, 132.0000, 173.0000,  59.5000,\n",
      "        123.5000, 240.0000, 188.5000,  70.3000,  32.0000, 120.0000,  39.0000,\n",
      "        157.0000,  86.3000, 250.0000, 156.0000, 112.5000, 135.0000,  63.0000,\n",
      "        195.0000, 170.0000, 163.0000, 117.1000, 118.5000, 142.0000, 215.0000,\n",
      "         14.0000, 107.0000, 124.0000, 159.5000, 139.0000, 114.0000, 151.0000,\n",
      "        130.5000,  83.0000,  99.5000, 138.0000,  82.0000, 175.7000, 137.0000,\n",
      "        101.5000, 101.0000, 142.0000, 229.5000, 199.0000,  92.0000, 177.2000,\n",
      "         34.6000, 109.7000, 148.5000, 103.0000, 216.0000, 165.5000, 102.5000,\n",
      "        218.0000, 103.5000,  95.5000,  87.6000, 181.0000, 141.0000, 153.5000],\n",
      "       device='cuda:0')\n",
      "y_pred= tensor([162.9558, 155.7776, 113.9882, 170.1735, 101.9240,  97.3962, 115.1580,\n",
      "        133.7936, 135.9441, 147.0833], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss Triangular: 0.0\n",
      "node_costs :\n",
      "tensor([[0.0000, 0.0039, 0.0049, 0.0046, 0.0037, 0.0042, 0.0048, 0.0043, 0.0050,\n",
      "         0.0047, 0.0051, 0.0037, 0.0037, 0.0042, 0.0045, 0.0048, 0.0045, 0.0046,\n",
      "         0.0044, 0.0036, 0.0051, 0.0039],\n",
      "        [0.0039, 0.0000, 0.0044, 0.0036, 0.0052, 0.0045, 0.0037, 0.0040, 0.0052,\n",
      "         0.0042, 0.0051, 0.0050, 0.0046, 0.0041, 0.0050, 0.0037, 0.0040, 0.0037,\n",
      "         0.0035, 0.0044, 0.0050, 0.0041],\n",
      "        [0.0049, 0.0044, 0.0000, 0.0044, 0.0037, 0.0051, 0.0048, 0.0050, 0.0035,\n",
      "         0.0038, 0.0039, 0.0035, 0.0035, 0.0034, 0.0047, 0.0049, 0.0050, 0.0038,\n",
      "         0.0042, 0.0048, 0.0037, 0.0042],\n",
      "        [0.0046, 0.0036, 0.0044, 0.0000, 0.0052, 0.0042, 0.0049, 0.0045, 0.0044,\n",
      "         0.0049, 0.0046, 0.0040, 0.0046, 0.0044, 0.0048, 0.0046, 0.0037, 0.0042,\n",
      "         0.0040, 0.0038, 0.0036, 0.0045],\n",
      "        [0.0037, 0.0052, 0.0037, 0.0052, 0.0000, 0.0036, 0.0039, 0.0046, 0.0050,\n",
      "         0.0043, 0.0041, 0.0050, 0.0049, 0.0038, 0.0052, 0.0046, 0.0036, 0.0035,\n",
      "         0.0037, 0.0037, 0.0037, 0.0052],\n",
      "        [0.0042, 0.0045, 0.0051, 0.0042, 0.0036, 0.0000, 0.0039, 0.0045, 0.0036,\n",
      "         0.0044, 0.0043, 0.0039, 0.0048, 0.0036, 0.0042, 0.0043, 0.0046, 0.0048,\n",
      "         0.0035, 0.0041, 0.0050, 0.0045],\n",
      "        [0.0048, 0.0037, 0.0048, 0.0049, 0.0039, 0.0039, 0.0000, 0.0043, 0.0043,\n",
      "         0.0044, 0.0042, 0.0043, 0.0035, 0.0040, 0.0049, 0.0035, 0.0046, 0.0050,\n",
      "         0.0036, 0.0041, 0.0038, 0.0047],\n",
      "        [0.0043, 0.0040, 0.0050, 0.0045, 0.0046, 0.0045, 0.0043, 0.0000, 0.0041,\n",
      "         0.0040, 0.0044, 0.0046, 0.0037, 0.0043, 0.0035, 0.0043, 0.0044, 0.0042,\n",
      "         0.0038, 0.0044, 0.0036, 0.0047],\n",
      "        [0.0050, 0.0052, 0.0035, 0.0044, 0.0050, 0.0036, 0.0043, 0.0041, 0.0000,\n",
      "         0.0042, 0.0043, 0.0038, 0.0038, 0.0036, 0.0040, 0.0050, 0.0051, 0.0045,\n",
      "         0.0037, 0.0051, 0.0038, 0.0041],\n",
      "        [0.0047, 0.0042, 0.0038, 0.0049, 0.0043, 0.0044, 0.0044, 0.0040, 0.0042,\n",
      "         0.0000, 0.0043, 0.0037, 0.0038, 0.0046, 0.0038, 0.0034, 0.0045, 0.0050,\n",
      "         0.0037, 0.0047, 0.0047, 0.0048],\n",
      "        [0.0051, 0.0051, 0.0039, 0.0046, 0.0041, 0.0043, 0.0042, 0.0044, 0.0043,\n",
      "         0.0043, 0.0000, 0.0049, 0.0035, 0.0036, 0.0038, 0.0041, 0.0049, 0.0049,\n",
      "         0.0037, 0.0039, 0.0043, 0.0042],\n",
      "        [0.0037, 0.0050, 0.0035, 0.0040, 0.0050, 0.0039, 0.0043, 0.0046, 0.0038,\n",
      "         0.0037, 0.0049, 0.0000, 0.0037, 0.0051, 0.0050, 0.0046, 0.0047, 0.0038,\n",
      "         0.0043, 0.0052, 0.0044, 0.0049],\n",
      "        [0.0037, 0.0046, 0.0035, 0.0046, 0.0049, 0.0048, 0.0035, 0.0037, 0.0038,\n",
      "         0.0038, 0.0035, 0.0037, 0.0000, 0.0047, 0.0043, 0.0048, 0.0048, 0.0048,\n",
      "         0.0035, 0.0040, 0.0046, 0.0047],\n",
      "        [0.0042, 0.0041, 0.0034, 0.0044, 0.0038, 0.0036, 0.0040, 0.0043, 0.0036,\n",
      "         0.0046, 0.0036, 0.0051, 0.0047, 0.0000, 0.0051, 0.0041, 0.0039, 0.0047,\n",
      "         0.0042, 0.0040, 0.0046, 0.0038],\n",
      "        [0.0045, 0.0050, 0.0047, 0.0048, 0.0052, 0.0042, 0.0049, 0.0035, 0.0040,\n",
      "         0.0038, 0.0038, 0.0050, 0.0043, 0.0051, 0.0000, 0.0036, 0.0044, 0.0040,\n",
      "         0.0048, 0.0038, 0.0037, 0.0035],\n",
      "        [0.0048, 0.0037, 0.0049, 0.0046, 0.0046, 0.0043, 0.0035, 0.0043, 0.0050,\n",
      "         0.0034, 0.0041, 0.0046, 0.0048, 0.0041, 0.0036, 0.0000, 0.0044, 0.0046,\n",
      "         0.0046, 0.0045, 0.0040, 0.0038],\n",
      "        [0.0045, 0.0040, 0.0050, 0.0037, 0.0036, 0.0046, 0.0046, 0.0044, 0.0051,\n",
      "         0.0045, 0.0049, 0.0047, 0.0048, 0.0039, 0.0044, 0.0044, 0.0000, 0.0045,\n",
      "         0.0049, 0.0050, 0.0043, 0.0044],\n",
      "        [0.0046, 0.0037, 0.0038, 0.0042, 0.0035, 0.0048, 0.0050, 0.0042, 0.0045,\n",
      "         0.0050, 0.0049, 0.0038, 0.0048, 0.0047, 0.0040, 0.0046, 0.0045, 0.0000,\n",
      "         0.0052, 0.0040, 0.0045, 0.0046],\n",
      "        [0.0044, 0.0035, 0.0042, 0.0040, 0.0037, 0.0035, 0.0036, 0.0038, 0.0037,\n",
      "         0.0037, 0.0037, 0.0043, 0.0035, 0.0042, 0.0048, 0.0046, 0.0049, 0.0052,\n",
      "         0.0000, 0.0047, 0.0040, 0.0040],\n",
      "        [0.0036, 0.0044, 0.0048, 0.0038, 0.0037, 0.0041, 0.0041, 0.0044, 0.0051,\n",
      "         0.0047, 0.0039, 0.0052, 0.0040, 0.0040, 0.0038, 0.0045, 0.0050, 0.0040,\n",
      "         0.0047, 0.0000, 0.0034, 0.0042],\n",
      "        [0.0051, 0.0050, 0.0037, 0.0036, 0.0037, 0.0050, 0.0038, 0.0036, 0.0038,\n",
      "         0.0047, 0.0043, 0.0044, 0.0046, 0.0046, 0.0037, 0.0040, 0.0043, 0.0045,\n",
      "         0.0040, 0.0034, 0.0000, 0.0042],\n",
      "        [0.0039, 0.0041, 0.0042, 0.0045, 0.0052, 0.0045, 0.0047, 0.0047, 0.0041,\n",
      "         0.0048, 0.0042, 0.0049, 0.0047, 0.0038, 0.0035, 0.0038, 0.0044, 0.0046,\n",
      "         0.0040, 0.0042, 0.0042, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "nodeInsDel: 0.005148860160261393\n",
      "edge_costs :\n",
      "tensor([], device='cuda:0')\n",
      "edgeInsDel: 0.003453990677371621\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "from triangular_losses import TriangularConstraint as triangular_constraint\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "#  model = nn.DataParallel(model)\n",
    "#model.to(device)\n",
    "#regress.to(device)\n",
    "def regression(model,data,yt,nb_iter):\n",
    "\n",
    "    input=data.to(device)\n",
    "    target=yt.to(device) \n",
    "    \n",
    "    criterion = torch.nn.MSELoss()\n",
    "    criterionTri=triangular_constraint()\n",
    "    \n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "    print(device)\n",
    "\n",
    "#torch.cat((same_class[0:20],diff_class[0:20]),0).to(device)\n",
    "    \n",
    "#torch.ones(40,device=device)\n",
    "#target[20:]=-1.0\n",
    "#target=(yt[0:20]).to(device)\n",
    "    InsDel=np.empty((nb_iter,2))\n",
    "    node_costs,nodeInsDel,edge_costs,edgeInsDel=model[0].from_weighs_to_costs()\n",
    "    nodeSub=np.empty((nb_iter,int(node_costs.shape[0]*(node_costs.shape[0]-1)/2)))\n",
    "    edgeSub=np.empty((nb_iter,int(edge_costs.shape[0]*(edge_costs.shape[0]-1)/2)))\n",
    "    loss_plt=np.empty(nb_iter)\n",
    "    #print('alpha=',regress.coef_dist*regress.coef_dist*10.0)\n",
    "    \n",
    "    \n",
    "    for t in range(nb_iter):    \n",
    "        # Forward pass: Compute predicted y by passing data to the model    \n",
    "        node_costs,nodeInsDel,edge_costs,edgeInsDel=model[0].from_weighs_to_costs()\n",
    "\n",
    "        y_pred = model(input).to(device)\n",
    "            \n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, target[-nb_test:]).to(device)                          \n",
    "        #loss = criterion(y_pred, target).to(device)                          \n",
    "        triangularInq=criterionTri(node_costs,nodeInsDel,edge_costs,edgeInsDel)\n",
    "        \n",
    "        loss=loss*(1+triangularInq)\n",
    "        loss.to(device)\n",
    "        InsDel[t][0]=nodeInsDel.item()\n",
    "        InsDel[t][1]=edgeInsDel.item()\n",
    "        rmse=np.sqrt(loss.item()/nb_test)\n",
    "        loss_plt[t]=rmse\n",
    "        print(t, rmse)   \n",
    "        k=0\n",
    "        for p in range(node_costs.shape[0]):\n",
    "            for q in range(p+1,node_costs.shape[0]):\n",
    "                nodeSub[t][k]=node_costs[p][q]\n",
    "                k=k+1\n",
    "        k=0\n",
    "        for p in range(edge_costs.shape[0]):\n",
    "            for q in range(p+1,edge_costs.shape[0]):\n",
    "                edgeSub[t][k]=edge_costs[p][q]\n",
    "                k=k+1\n",
    "        if t % 20 == 0 or t==0:                         \n",
    "            #print('Distances: ',y_pred)\n",
    "            print('alpha=',model[1].coef_dist*model[1].coef_dist)\n",
    "            #print('lambda=',model[1].regu*model[1].regu)\n",
    "            print('target=',target)\n",
    "            print('y_pred=',y_pred)\n",
    "            print('Loss Triangular:',triangularInq.item())\n",
    "            print('node_costs :')\n",
    "            print(node_costs)\n",
    "            print('nodeInsDel:',nodeInsDel.item())\n",
    "            print('edge_costs :')\n",
    "            print(edge_costs)\n",
    "            print('edgeInsDel:',edgeInsDel.item())\n",
    "        \n",
    "        \n",
    "            # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return InsDel,nodeSub,edgeSub,loss_plt\n",
    "\n",
    "\n",
    "\n",
    "model = nn.Sequential( OrderedDict([\n",
    "        ('ComputeDist',Net(Gs,normalize=False,node_label='extended_label')),('RegressFromDist',regress(yt.to(device),20,nb_test=nb_test,device=device,weights='distance'))\n",
    "#        ('RegressFromDist',RegressFromGED(yt.to(device),normalize='exp',nb_test=nb_test))\n",
    "        ])) \n",
    "print('Parameters:')\n",
    "for param in model.parameters():\n",
    "    print(type(param), param.size())\n",
    "nb_iter=40   \n",
    "#with torch.autograd.profiler.profile(use_cuda=True) as prof:    \n",
    "InsDel, nodeSub,edgeSub,loss_plt=regression(model,data,yt,nb_iter)\n",
    "#print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n",
    "#print(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n",
    "num_fig=0\n",
    "plt.figure(num_fig)\n",
    "plt.plot(InsDel[:,0],label=\"node\")\n",
    "plt.plot(InsDel[:,1],label=\"edge\")\n",
    "plt.title('Node/Edge insertion/deletion costs')\n",
    "num_fig=num_fig+1\n",
    "plt.legend()\n",
    "plt.figure(num_fig)\n",
    "for k in range(nodeSub.shape[1]):\n",
    "    plt.plot(nodeSub[:,k])\n",
    "plt.title('Node Substitutions costs')\n",
    "num_fig=num_fig+1\n",
    "if edgeSub.shape[1] != 0:\n",
    "    plt.figure(num_fig)\n",
    "    for k in range(edgeSub.shape[1]):\n",
    "        plt.plot(edgeSub[:,k])\n",
    "    plt.title('Edge Substitutions costs')\n",
    "    num_fig=num_fig+1\n",
    "plt.figure(num_fig)\n",
    "plt.plot(loss_plt[:])\n",
    "plt.title('Loss')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_plt[0:160])\n",
    "for k in range(edgeSub.shape[1]):\n",
    "    plt.plot(edgeSub[0:500,k])\n",
    "plt.title('Loss')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(nodeSub[:,25])\n",
    "plt.figure(0)\n",
    "for k in range(nodeSub.shape[1]):    \n",
    "    plt.plot(nodeSub[:,k])\n",
    "plt.title('Node Substitutions costs')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(edgeSub.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
